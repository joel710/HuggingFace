{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j7ubkCSIf6LM",
        "_K5-IyiL6zp8",
        "eDUx8I92Z96a"
      ],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJ454rgiA1NIvNAagl0KaX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa9e58e43528405c986c72899203cfec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a3f55dc6cb840ed89ba1a1e5f513ba3",
              "IPY_MODEL_1d0c21ea29e44fbb8602679bcde85e65",
              "IPY_MODEL_41ee4ece6eb04a27b900655f600f27b1",
              "IPY_MODEL_9d8f69b3eddd4c03a23f3d99747e1213"
            ],
            "layout": "IPY_MODEL_bc0862611cdb4cbf93c362888bd36563"
          }
        },
        "b5fe63ee6da442baaa6fd3fbcf4db428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633430202d6745478caaa1ff114f7b2e",
            "placeholder": "​",
            "style": "IPY_MODEL_0136fbaa677543f29b2d98d347a707dd",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "330aeedc1d2d48409cc7b85d9be070b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c309fa2db0ce4b5aa62d2da79e2d788f",
            "placeholder": "​",
            "style": "IPY_MODEL_9f845cb0986245038bd1a9c62965bb4f",
            "value": ""
          }
        },
        "34411f8e65da4c3689738acafcf210e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_9e8664c705034e64837b1bc5e2ff313e",
            "style": "IPY_MODEL_3eb85ffaf1654998991c2cfbf1c2899d",
            "value": true
          }
        },
        "b5152ba1d2b34ddf8c8facd2f1ebdf93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_39fc6d875c764bc2994e7af87a31e731",
            "style": "IPY_MODEL_158e1e731c8a4017bed6f3fe5bde9e3b",
            "tooltip": ""
          }
        },
        "cbf916f831f7472ca5f222ba0d814c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_998b51e2bb904fe8960083d97c0332e5",
            "placeholder": "​",
            "style": "IPY_MODEL_69ee0b6470454a0d9b7f2e820ed8425a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "bc0862611cdb4cbf93c362888bd36563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "633430202d6745478caaa1ff114f7b2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0136fbaa677543f29b2d98d347a707dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c309fa2db0ce4b5aa62d2da79e2d788f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f845cb0986245038bd1a9c62965bb4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e8664c705034e64837b1bc5e2ff313e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb85ffaf1654998991c2cfbf1c2899d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39fc6d875c764bc2994e7af87a31e731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158e1e731c8a4017bed6f3fe5bde9e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "998b51e2bb904fe8960083d97c0332e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69ee0b6470454a0d9b7f2e820ed8425a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30716ca2945f4d1a929dc65e3651a4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86f507528cb847ffb346eaa5ea85f871",
            "placeholder": "​",
            "style": "IPY_MODEL_d065a34cc36b42ffa93dc40d759686c6",
            "value": "Connecting..."
          }
        },
        "86f507528cb847ffb346eaa5ea85f871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d065a34cc36b42ffa93dc40d759686c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a3f55dc6cb840ed89ba1a1e5f513ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7a09edc11b4ebdabb0f1d69fb3f902",
            "placeholder": "​",
            "style": "IPY_MODEL_8020ab7b1b3741bd998cba67cf05b4a7",
            "value": "Token is valid (permission: write)."
          }
        },
        "1d0c21ea29e44fbb8602679bcde85e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3bb1c95333041538813df9a210842a5",
            "placeholder": "​",
            "style": "IPY_MODEL_86bc3818f6c44d14ac8b385f8d5c9c41",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "41ee4ece6eb04a27b900655f600f27b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83432cd04d7a4d3c90f9a9505e8d86d2",
            "placeholder": "​",
            "style": "IPY_MODEL_a7716629f4d34c52a790fe9ceef59411",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "9d8f69b3eddd4c03a23f3d99747e1213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47815241f6dc4b9985666f56cd0ee7d2",
            "placeholder": "​",
            "style": "IPY_MODEL_3813fca1e07d47088dadc4e09b17d63a",
            "value": "Login successful"
          }
        },
        "0d7a09edc11b4ebdabb0f1d69fb3f902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8020ab7b1b3741bd998cba67cf05b4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3bb1c95333041538813df9a210842a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86bc3818f6c44d14ac8b385f8d5c9c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83432cd04d7a4d3c90f9a9505e8d86d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7716629f4d34c52a790fe9ceef59411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47815241f6dc4b9985666f56cd0ee7d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3813fca1e07d47088dadc4e09b17d63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ffc54133f24550b855ce22dab2f2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e5d3328cfbd42619e52ab7a757d33fc",
              "IPY_MODEL_5c1fe490c41043a689a0f224d6d0163b",
              "IPY_MODEL_44d460beada142c6a07ab07f9859f993"
            ],
            "layout": "IPY_MODEL_6bf0acb374f2473dac349f95cbf16a3f"
          }
        },
        "7e5d3328cfbd42619e52ab7a757d33fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a8b99eb7b1480caf16457395c02082",
            "placeholder": "​",
            "style": "IPY_MODEL_264c05d47d094d0f9a49309de1bc55bd",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5c1fe490c41043a689a0f224d6d0163b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b52a39963db42fcb9d53160c81be996",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20c53a54020c4afe920e2f0b4d324fc3",
            "value": 10
          }
        },
        "44d460beada142c6a07ab07f9859f993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df92777cdd54f03be8bb4474665bb0f",
            "placeholder": "​",
            "style": "IPY_MODEL_bd8317ef67db421d87729af94e1cc8f1",
            "value": " 10/10 [02:02&lt;00:00, 10.03s/it]"
          }
        },
        "6bf0acb374f2473dac349f95cbf16a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a8b99eb7b1480caf16457395c02082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "264c05d47d094d0f9a49309de1bc55bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b52a39963db42fcb9d53160c81be996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c53a54020c4afe920e2f0b4d324fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4df92777cdd54f03be8bb4474665bb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8317ef67db421d87729af94e1cc8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/HuggingFace/blob/main/dataset_generate_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=z2QE12p3kMM\n"
      ],
      "metadata": {
        "id": "kL538n6stVYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "SlVX0spoxofJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPBQMglBvRMw",
        "outputId": "e25f436b-5a74-4f06-9348-d6503ee34d34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDogIZ67j2Gl",
        "outputId": "44fb20cd-24db-4cc0-92e6-b5d8d3a47e72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting from Google drive the llm fine-tuned\n",
        "!unzip /content/drive/MyDrive/llm_tuning/llama2-MJ-prompts.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W_PuzGKxP5y",
        "outputId": "2a11a59d-57cc-4591-9ec3-6e1aa43c393f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/llm_tuning/llama2-MJ-prompts.zip\n",
            "   creating: content/llama2-MJ-prompts/\n",
            " extracting: content/llama2-MJ-prompts/added_tokens.json  \n",
            "  inflating: content/llama2-MJ-prompts/adapter_model.bin  \n",
            "  inflating: content/llama2-MJ-prompts/tokenizer.model  \n",
            "  inflating: content/llama2-MJ-prompts/special_tokens_map.json  \n",
            "   creating: content/llama2-MJ-prompts/checkpoint-7/\n",
            " extracting: content/llama2-MJ-prompts/checkpoint-7/added_tokens.json  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/adapter_model.bin  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/tokenizer.model  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/trainer_state.json  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/special_tokens_map.json  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/rng_state.pth  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/pytorch_model.bin  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/README.md  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/training_args.bin  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/tokenizer.json  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/tokenizer_config.json  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/adapter_config.json  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/optimizer.pt  \n",
            "  inflating: content/llama2-MJ-prompts/checkpoint-7/scheduler.pt  \n",
            "  inflating: content/llama2-MJ-prompts/training_params.json  \n",
            "  inflating: content/llama2-MJ-prompts/README.md  \n",
            "   creating: content/llama2-MJ-prompts/runs/\n",
            "   creating: content/llama2-MJ-prompts/runs/Oct21_09-22-30_f5ea7e9d9d97/\n",
            "  inflating: content/llama2-MJ-prompts/runs/Oct21_09-22-30_f5ea7e9d9d97/events.out.tfevents.1697880151.f5ea7e9d9d97.2610.0  \n",
            "  inflating: content/llama2-MJ-prompts/training_args.bin  \n",
            "  inflating: content/llama2-MJ-prompts/tokenizer.json  \n",
            "  inflating: content/llama2-MJ-prompts/tokenizer_config.json  \n",
            "  inflating: content/llama2-MJ-prompts/adapter_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why LLM Fine-Tuning?\n",
        "\n",
        "Fine-tuning of LLMs is the conventional method that retrains all model parameters for a specific task or domain. Fine-tuning a Large Language Model (LLM) is beneficial for several reasons:\n",
        "\n",
        "- **Domain Specificity**: General-purpose language models are trained on a wide variety of data and are not specialized in any particular domain. Fine-tuning allows you to adapt the model to specific industries, topics, or types of language, such as medical terminology, legal jargon, or technical language.\n",
        "\n",
        "- **Improved Accuracy**: Fine-tuning on a specific dataset can improve the model’s performance on tasks related to that data. This could mean more accurate classifications, better sentiment analysis, or more relevant generated text.\n",
        "\n",
        "- **Resource Efficiency**: Fine-tuning only a subset of the model’s parameters can be more computationally efficient than training a new model from scratch. This can be particularly important when computational resources are limited.\n",
        "\n",
        "- **Data Privacy**: If you have sensitive or proprietary data, fine-tuning a pre-trained model on your own infrastructure allows you to benefit from the capabilities of large language models without sharing your data externally.\n",
        "\n",
        "- **Task Adaptation**: General-purpose language models are not optimized for specific tasks like question-answering, summarization, or translation. Fine-tuning can adapt the model for these specialized tasks.\n",
        "\n",
        "- **Contextual Understanding**: Fine-tuning can help the model better understand the context in which it will be used, making it more effective at generating appropriate and useful responses.\n",
        "\n",
        "- **Reduced Training Time**: Starting with a pre-trained model and fine-tuning it for a specific task can be much faster than training a model from scratch.\n",
        "\n",
        "- **Avoid Overfitting**: When you have a small dataset, training a large model from scratch can lead to overfitting. Fine-tuning can mitigate this risk, as the model has already learned general language features from a large dataset and only needs to adapt to the specificities of the new data.\n",
        "\n",
        "- **Leverage Pre-trained Features**: Large language models trained on extensive datasets have already learned a wide array of features, from basic syntax and grammar to high-level semantic understanding. Fine-tuning allows you to leverage these features for your specific application.\n",
        "\n",
        "- **Customization**: Fine-tuning allows you to tailor the model’s behavior to specific requirements, such as generating text in a particular style, tone, or format.\n",
        "\n",
        "In summary, fine-tuning a large language model allows you to customize its capabilities for specific tasks, domains, or datasets, improving its performance and making it more applicable to your particular needs."
      ],
      "metadata": {
        "id": "MOvusDXvmqIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT4 - Code interpreter - Dataset creation\n",
        "\n",
        "https://chat.openai.com/share/5380107c-821d-4849-993b-938fc8545268\n",
        "\n",
        "The goal of the dataset we are going to create is:\n",
        "- the user provide a concept and\n",
        "- the model is going to produce a description associated to the concept.\n",
        "So initially we have two fields:\n",
        "- concept\n",
        "- description\n",
        "\n",
        "You need to generate at least 300 rows so that the model can learn.\n",
        "\n",
        "Then, you need to add an additional column called `text` that will have a specific format for the LLM with the tokens ###Human and ###Assistant:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "###Human: generate a midjourney prompt for A sunset over the mountains ###Assistant: The sun is setting behind jagged mountain peaks. The sky is filled with shades of orange, pink, and purple, casting a warm glow on the mountains. Clouds lightly scattered, allowing the colors to shine through.\n",
        "```\n",
        "\n",
        "The `text` column will hold the concept and description, with the tokens identified as ### and the model fine-tuning will be based on this column `text`.\n"
      ],
      "metadata": {
        "id": "Z8bZNWVcxzO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some considerations\n",
        "- Make the dataset large enough so that the model can learn from this dataset.\n",
        "- Make sure to have an end of sentence <eos> token so that when the model encounters that token, it will stop generating a new word; remember we are working on a CausalLM predicting the next word.\n",
        "- A new column called `text` must be present that has the following structure:\n",
        "\n",
        "\n",
        "```\n",
        "text = f\"###Human:\\n\\ngenerate a midjourney prompt for {concept}\\n\\n####Assistant:\\n{description}\"\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "j7ubkCSIf6LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate a datasets on medical terms  structured with 2 columns:\n",
        "concept: indicating the medical term, and description: giving a description regarding the medical term.\n",
        "Create a pandas dataframe for 200 rows and save it to a csv file named train.csv"
      ],
      "metadata": {
        "id": "LxTOSpnnO5yF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "vv create a dataset that contains concept-prompt pair. For each of the concepts like \"A person walking in the rain\" create a detailed description that can be used by an AI image generator to create images."
      ],
      "metadata": {
        "id": "a4vdxwCecXOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lNeI61jXYTd",
        "outputId": "f2a6ef6a-cfb5-4b00-8b5c-ab9baa51f3c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'concept': 'A person walking in the rain',\n",
              "  'description': 'A silhouette of an adult person holding a black umbrella, walking on a wet city street. The sky is dark and cloudy, filled with raindrops. Streetlights cast soft glows, reflecting on the puddles on the ground.'},\n",
              " {'concept': 'A sunset over the ocean',\n",
              "  'description': 'The sky is ablaze with shades of orange, pink, and purple, as the sun sinks below the horizon. The ocean waves gently lap the shore, reflecting the colors of the sky. A small sailboat is in the distance.'},\n",
              " {'concept': 'A snowy mountain range',\n",
              "  'description': 'Tall, rugged mountains covered in pristine white snow under a clear blue sky. Pine trees are scattered at the lower elevations. A lone eagle soars high above the peaks.'},\n",
              " {'concept': 'A bustling city market',\n",
              "  'description': 'A crowded marketplace filled with vendors selling fruits, vegetables, and spices. People are haggling, children are running around, and the air is filled with the aroma of freshly cooked food. Colorful fabric canopies provide shade.'},\n",
              " {'concept': 'A tranquil Japanese garden',\n",
              "  'description': 'A peaceful garden featuring a koi pond surrounded by meticulously pruned bonsai trees. A wooden bridge arches over the pond. Cherry blossoms are in full bloom, and a traditional stone lantern stands off to one side.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Generating a dataset of concept-prompt pairs for AI image generation\n",
        "concept_prompts = [\n",
        "    {\n",
        "        \"concept\": \"A person walking in the rain\",\n",
        "        \"description\": \"A silhouette of an adult person holding a black umbrella, walking on a wet city street. The sky is dark and cloudy, filled with raindrops. Streetlights cast soft glows, reflecting on the puddles on the ground.\"\n",
        "    },\n",
        "    {\n",
        "        \"concept\": \"A sunset over the ocean\",\n",
        "        \"description\": \"The sky is ablaze with shades of orange, pink, and purple, as the sun sinks below the horizon. The ocean waves gently lap the shore, reflecting the colors of the sky. A small sailboat is in the distance.\"\n",
        "    },\n",
        "    {\n",
        "        \"concept\": \"A snowy mountain range\",\n",
        "        \"description\": \"Tall, rugged mountains covered in pristine white snow under a clear blue sky. Pine trees are scattered at the lower elevations. A lone eagle soars high above the peaks.\"\n",
        "    },\n",
        "    {\n",
        "        \"concept\": \"A bustling city market\",\n",
        "        \"description\": \"A crowded marketplace filled with vendors selling fruits, vegetables, and spices. People are haggling, children are running around, and the air is filled with the aroma of freshly cooked food. Colorful fabric canopies provide shade.\"\n",
        "    },\n",
        "    {\n",
        "        \"concept\": \"A tranquil Japanese garden\",\n",
        "        \"description\": \"A peaceful garden featuring a koi pond surrounded by meticulously pruned bonsai trees. A wooden bridge arches over the pond. Cherry blossoms are in full bloom, and a traditional stone lantern stands off to one side.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "concept_prompts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vv create a pandas dataframe with concept and description,  include  25 unique pair of the concept and description pairs"
      ],
      "metadata": {
        "id": "BKqGD4r8ckMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Extending the concept-prompts dataset to include 25 unique pairs\n",
        "extended_concept_prompts = [\n",
        "    {\"concept\": \"A person walking in the rain\", \"description\": \"A silhouette of an adult person holding a black umbrella, walking on a wet city street. The sky is dark and cloudy, filled with raindrops. Streetlights cast soft glows, reflecting on the puddles on the ground.\"},\n",
        "    {\"concept\": \"A sunset over the ocean\", \"description\": \"The sky is ablaze with shades of orange, pink, and purple, as the sun sinks below the horizon. The ocean waves gently lap the shore, reflecting the colors of the sky. A small sailboat is in the distance.\"},\n",
        "    {\"concept\": \"A snowy mountain range\", \"description\": \"Tall, rugged mountains covered in pristine white snow under a clear blue sky. Pine trees are scattered at the lower elevations. A lone eagle soars high above the peaks.\"},\n",
        "    {\"concept\": \"A bustling city market\", \"description\": \"A crowded marketplace filled with vendors selling fruits, vegetables, and spices. People are haggling, children are running around, and the air is filled with the aroma of freshly cooked food. Colorful fabric canopies provide shade.\"},\n",
        "    {\"concept\": \"A tranquil Japanese garden\", \"description\": \"A peaceful garden featuring a koi pond surrounded by meticulously pruned bonsai trees. A wooden bridge arches over the pond. Cherry blossoms are in full bloom, and a traditional stone lantern stands off to one side.\"},\n",
        "    {\"concept\": \"A futuristic cityscape\", \"description\": \"Skyscrapers with neon lights and flying cars zipping between them. The sky is dark but filled with the glow of billboards and digital screens.\"},\n",
        "    {\"concept\": \"A medieval castle\", \"description\": \"A stone castle with turrets and a moat, set against a forest. Flags are flying, and knights are patrolling the walls.\"},\n",
        "    {\"concept\": \"A desert oasis\", \"description\": \"Golden sand dunes surrounding a small body of clear water with palm trees. Camels are resting nearby.\"},\n",
        "    {\"concept\": \"An autumn forest\", \"description\": \"Trees with leaves in shades of red, orange, and yellow. The ground is covered with fallen leaves, and a stream flows gently.\"},\n",
        "    {\"concept\": \"A tropical beach\", \"description\": \"White sand, turquoise water, and palm trees. A hammock is strung between two trees, and the sun is shining brightly.\"},\n",
        "    {\"concept\": \"A galaxy\", \"description\": \"A swirling mass of stars, gas, and dust. Bright clusters and dark voids make up a celestial tapestry.\"},\n",
        "    {\"concept\": \"A Victorian mansion\", \"description\": \"A grand house with intricate wooden details, a large porch, and tall windows. The garden is well-kept, with blooming flowers.\"},\n",
        "    {\"concept\": \"A jazz band\", \"description\": \"Musicians in a dimly lit room, playing saxophones, trumpets, and drums. The atmosphere is energetic and the crowd is engaged.\"},\n",
        "    {\"concept\": \"A wild west town\", \"description\": \"Wooden buildings line a dusty street. Horses are tied to posts, and cowboys walk with spurs jingling.\"},\n",
        "    {\"concept\": \"A coral reef\", \"description\": \"Colorful corals and fish in clear, shallow waters. Sunlight filters through, creating a mosaic of light and shadow.\"},\n",
        "    {\"concept\": \"A space station\", \"description\": \"A complex structure orbiting Earth, with solar panels and modules connected by tunnels. Astronauts are conducting experiments.\"},\n",
        "    {\"concept\": \"A vineyard\", \"description\": \"Rows of grapevines on rolling hills. A farmhouse and barrels are in the background, under a clear, sunny sky.\"},\n",
        "    {\"concept\": \"A safari\", \"description\": \"A savannah with acacia trees, where elephants, zebras, and lions roam. A jeep is parked in the distance, observing the wildlife.\"},\n",
        "    {\"concept\": \"A lighthouse on a cliff\", \"description\": \"A tall lighthouse stands on a rocky cliff, overlooking a stormy sea. Waves crash against the rocks, and the light is on.\"},\n",
        "    {\"concept\": \"A haunted house\", \"description\": \"An old, dilapidated house with broken windows and overgrown weeds. It's night, and an eerie glow emanates from within.\"},\n",
        "    {\"concept\": \"A dense jungle\", \"description\": \"Tall trees, vines, and lush foliage. Exotic birds and animals can be seen and heard, creating a cacophony of sounds.\"},\n",
        "    {\"concept\": \"A modern art gallery\", \"description\": \"White walls adorned with abstract paintings and sculptures. Visitors are contemplating the art, and the atmosphere is quiet.\"},\n",
        "    {\"concept\": \"A skate park\", \"description\": \"Concrete ramps, rails, and half-pipes, with skaters performing tricks. Graffiti decorates the surfaces, adding to the urban vibe.\"},\n",
        "    {\"concept\": \"A glacier\", \"description\": \"A massive sheet of ice moving slowly through a mountain valley. The surface is jagged, and crevasses are visible.\"},\n",
        "    {\"concept\": \"A battlefield\", \"description\": \"Soldiers in camouflage with tanks and artillery, engaged in combat. The sky is filled with smoke and explosions.\"}\n",
        "]\n",
        "\n",
        "# Creating a pandas DataFrame\n",
        "df_concept_prompts = pd.DataFrame(extended_concept_prompts)\n",
        "df_concept_prompts.head(25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "2N8MOcZGZNOQ",
        "outputId": "6cfe0fc3-3847-487f-9766-6a9226509558"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         concept  \\\n",
              "0   A person walking in the rain   \n",
              "1        A sunset over the ocean   \n",
              "2         A snowy mountain range   \n",
              "3         A bustling city market   \n",
              "4     A tranquil Japanese garden   \n",
              "5         A futuristic cityscape   \n",
              "6              A medieval castle   \n",
              "7                 A desert oasis   \n",
              "8               An autumn forest   \n",
              "9               A tropical beach   \n",
              "10                      A galaxy   \n",
              "11           A Victorian mansion   \n",
              "12                   A jazz band   \n",
              "13              A wild west town   \n",
              "14                  A coral reef   \n",
              "15               A space station   \n",
              "16                    A vineyard   \n",
              "17                      A safari   \n",
              "18       A lighthouse on a cliff   \n",
              "19               A haunted house   \n",
              "20                A dense jungle   \n",
              "21          A modern art gallery   \n",
              "22                  A skate park   \n",
              "23                     A glacier   \n",
              "24                 A battlefield   \n",
              "\n",
              "                                          description  \n",
              "0   A silhouette of an adult person holding a blac...  \n",
              "1   The sky is ablaze with shades of orange, pink,...  \n",
              "2   Tall, rugged mountains covered in pristine whi...  \n",
              "3   A crowded marketplace filled with vendors sell...  \n",
              "4   A peaceful garden featuring a koi pond surroun...  \n",
              "5   Skyscrapers with neon lights and flying cars z...  \n",
              "6   A stone castle with turrets and a moat, set ag...  \n",
              "7   Golden sand dunes surrounding a small body of ...  \n",
              "8   Trees with leaves in shades of red, orange, an...  \n",
              "9   White sand, turquoise water, and palm trees. A...  \n",
              "10  A swirling mass of stars, gas, and dust. Brigh...  \n",
              "11  A grand house with intricate wooden details, a...  \n",
              "12  Musicians in a dimly lit room, playing saxopho...  \n",
              "13  Wooden buildings line a dusty street. Horses a...  \n",
              "14  Colorful corals and fish in clear, shallow wat...  \n",
              "15  A complex structure orbiting Earth, with solar...  \n",
              "16  Rows of grapevines on rolling hills. A farmhou...  \n",
              "17  A savannah with acacia trees, where elephants,...  \n",
              "18  A tall lighthouse stands on a rocky cliff, ove...  \n",
              "19  An old, dilapidated house with broken windows ...  \n",
              "20  Tall trees, vines, and lush foliage. Exotic bi...  \n",
              "21  White walls adorned with abstract paintings an...  \n",
              "22  Concrete ramps, rails, and half-pipes, with sk...  \n",
              "23  A massive sheet of ice moving slowly through a...  \n",
              "24  Soldiers in camouflage with tanks and artiller...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2459d67f-c24a-4693-8ec5-9c963681fcff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concept</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A person walking in the rain</td>\n",
              "      <td>A silhouette of an adult person holding a blac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A sunset over the ocean</td>\n",
              "      <td>The sky is ablaze with shades of orange, pink,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A snowy mountain range</td>\n",
              "      <td>Tall, rugged mountains covered in pristine whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A bustling city market</td>\n",
              "      <td>A crowded marketplace filled with vendors sell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A tranquil Japanese garden</td>\n",
              "      <td>A peaceful garden featuring a koi pond surroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A futuristic cityscape</td>\n",
              "      <td>Skyscrapers with neon lights and flying cars z...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A medieval castle</td>\n",
              "      <td>A stone castle with turrets and a moat, set ag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>A desert oasis</td>\n",
              "      <td>Golden sand dunes surrounding a small body of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>An autumn forest</td>\n",
              "      <td>Trees with leaves in shades of red, orange, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A tropical beach</td>\n",
              "      <td>White sand, turquoise water, and palm trees. A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>A galaxy</td>\n",
              "      <td>A swirling mass of stars, gas, and dust. Brigh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>A Victorian mansion</td>\n",
              "      <td>A grand house with intricate wooden details, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>A jazz band</td>\n",
              "      <td>Musicians in a dimly lit room, playing saxopho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>A wild west town</td>\n",
              "      <td>Wooden buildings line a dusty street. Horses a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>A coral reef</td>\n",
              "      <td>Colorful corals and fish in clear, shallow wat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>A space station</td>\n",
              "      <td>A complex structure orbiting Earth, with solar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>A vineyard</td>\n",
              "      <td>Rows of grapevines on rolling hills. A farmhou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>A safari</td>\n",
              "      <td>A savannah with acacia trees, where elephants,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>A lighthouse on a cliff</td>\n",
              "      <td>A tall lighthouse stands on a rocky cliff, ove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>A haunted house</td>\n",
              "      <td>An old, dilapidated house with broken windows ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>A dense jungle</td>\n",
              "      <td>Tall trees, vines, and lush foliage. Exotic bi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>A modern art gallery</td>\n",
              "      <td>White walls adorned with abstract paintings an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>A skate park</td>\n",
              "      <td>Concrete ramps, rails, and half-pipes, with sk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>A glacier</td>\n",
              "      <td>A massive sheet of ice moving slowly through a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>A battlefield</td>\n",
              "      <td>Soldiers in camouflage with tanks and artiller...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2459d67f-c24a-4693-8ec5-9c963681fcff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2459d67f-c24a-4693-8ec5-9c963681fcff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2459d67f-c24a-4693-8ec5-9c963681fcff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe527a88-4278-45e3-a880-a5f97be6c7f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe527a88-4278-45e3-a880-a5f97be6c7f0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe527a88-4278-45e3-a880-a5f97be6c7f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_concept_prompts )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcG5UR2MZXPT",
        "outputId": "f410c088-815e-4739-f691-22a620147db6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create a csv file from the above dataframe"
      ],
      "metadata": {
        "id": "lZP7OlOicxOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the dataframe to a csv file\n",
        "df_concept_prompts.to_csv('train.csv', index=False)"
      ],
      "metadata": {
        "id": "t3MW-iZKZ6Uj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vv create another unique 25 concept-description pairs and write them to another csv file. Repeat the same process 4 times. Do not include the iteration number in the concept column, only strings allowed."
      ],
      "metadata": {
        "id": "CreBgFA-c3Nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ok now combine all the csv files into a single dataframe and create a new csv file called train.csv"
      ],
      "metadata": {
        "id": "VtTPNsHhjd0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, create another column called text with the following format structure:\n",
        "text=f\"###Human:\\nGenerate a medical term prompt for {concept}\\n\\n###Assistant:\\n{description}\""
      ],
      "metadata": {
        "id": "KVxw6S7O0bcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: the train.csv file has now 100 rows in total. It is a simple dataset, the goal is to show you how to create a dataset with code interpretor  and train it with a llama2 model for fine-tuning, then for inference as a last stage."
      ],
      "metadata": {
        "id": "oVm9-SNbj5su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "8SFSjvG1kdju"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "9BcQoqAVk9U0",
        "outputId": "9bdfc8cd-c7c3-465a-a0d1-0a63760bb9d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               concept  \\\n",
              "0         A person walking in the rain   \n",
              "1          A sunset over the mountains   \n",
              "2      A bustling city street at night   \n",
              "3    A serene lake surrounded by trees   \n",
              "4  A snowy landscape with a lone cabin   \n",
              "\n",
              "                                         description  \\\n",
              "0  A young adult wearing a navy-blue raincoat and...   \n",
              "1  The sun is setting behind jagged mountain peak...   \n",
              "2  A city street bustling with activity at night....   \n",
              "3  A peaceful lake encircled by dense trees. The ...   \n",
              "4  A snowy landscape featuring a single wooden ca...   \n",
              "\n",
              "                                                text  \n",
              "0  ###Human:\\ngenerate a midjourney prompt for A ...  \n",
              "1  ###Human:\\ngenerate a midjourney prompt for A ...  \n",
              "2  ###Human:\\ngenerate a midjourney prompt for A ...  \n",
              "3  ###Human:\\ngenerate a midjourney prompt for A ...  \n",
              "4  ###Human:\\ngenerate a midjourney prompt for A ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d14e04ea-5415-4939-a38b-25e26b358875\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concept</th>\n",
              "      <th>description</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A person walking in the rain</td>\n",
              "      <td>A young adult wearing a navy-blue raincoat and...</td>\n",
              "      <td>###Human:\\ngenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A sunset over the mountains</td>\n",
              "      <td>The sun is setting behind jagged mountain peak...</td>\n",
              "      <td>###Human:\\ngenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A bustling city street at night</td>\n",
              "      <td>A city street bustling with activity at night....</td>\n",
              "      <td>###Human:\\ngenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A serene lake surrounded by trees</td>\n",
              "      <td>A peaceful lake encircled by dense trees. The ...</td>\n",
              "      <td>###Human:\\ngenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A snowy landscape with a lone cabin</td>\n",
              "      <td>A snowy landscape featuring a single wooden ca...</td>\n",
              "      <td>###Human:\\ngenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d14e04ea-5415-4939-a38b-25e26b358875')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d14e04ea-5415-4939-a38b-25e26b358875 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d14e04ea-5415-4939-a38b-25e26b358875');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9f5097d-f003-4e0e-810a-372573e39c83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9f5097d-f003-4e0e-810a-372573e39c83')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9f5097d-f003-4e0e-810a-372573e39c83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcyXSDJ7lDu3",
        "outputId": "4fe677cf-0643-40e2-f8a6-12cc55a5ba27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Human:\n",
            "generate a midjourney prompt for A person walking in the rain\n",
            "\n",
            "###Assistant:\n",
            "A young adult wearing a navy-blue raincoat and matching rain boots walks on a wet cobblestone street. Raindrops create ripples in the puddles. They hold a red umbrella that shields them from the pouring rain. Their face is relaxed, enjoying the rainfall.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Le terme 'auto-train' d'HF réfère à diverses techniques en apprentissage automatique et en intelligence artificielle où le processus d'entraînement d'un modèle est automatisé dans une certaine mesure. L'objectif est de simplifier les étapes souvent complexes et chronophages impliquées dans la préparation des données, la sélection des caractéristiques, la sélection du modèle, le réglage des hyperparamètres et l'évaluation."
      ],
      "metadata": {
        "id": "tEjCd13uu614"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autotrain-advanced\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DcPCIwccoelz",
        "outputId": "68403e06-f70a-4a6e-802c-df9506381567"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autotrain-advanced\n",
            "  Downloading autotrain_advanced-0.6.37-py3-none-any.whl (130 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m112.6/130.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.3.1)\n",
            "Collecting codecarbon==2.2.3 (from autotrain-advanced)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.14.0 (from autotrain-advanced)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==3.0.2 (from autotrain-advanced)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Collecting joblib==1.3.1 (from autotrain-advanced)\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.5.3)\n",
            "Collecting optuna==3.3.0 (from autotrain-advanced)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.0.0 (from autotrain-advanced)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.4 (from autotrain-advanced)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.11 (from autotrain-advanced)\n",
            "  Downloading pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from autotrain-advanced)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.3.0 (from autotrain-advanced)\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m126.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99 (from autotrain-advanced)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from autotrain-advanced)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==2.3.6 (from autotrain-advanced)\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.6 (from autotrain-advanced)\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.16.4 (from autotrain-advanced)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.31.0)\n",
            "Collecting gradio==3.41.0 (from autotrain-advanced)\n",
            "  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from autotrain-advanced)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark==0.2.0 (from autotrain-advanced)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from autotrain-advanced)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.13.0)\n",
            "Collecting peft (from autotrain-advanced)\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl (from autotrain-advanced)\n",
            "  Downloading trl-0.7.2-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from autotrain-advanced)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from autotrain-advanced)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from autotrain-advanced)\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.21.4 (from autotrain-advanced)\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from autotrain-advanced)\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (1.11.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (4.8.1.78)\n",
            "Collecting arrow (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced) (3.12.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced) (6.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced) (2023.6.3)\n",
            "Collecting safetensors>=0.3.1 (from diffusers==0.21.4->autotrain-advanced)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m780.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (1.4.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (2.1.0+cu118)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer==3.0.2->autotrain-advanced)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced) (2.0.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->autotrain-advanced) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (3.8.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (3.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.41.2)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers->autotrain-advanced)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tyro>=0.5.7 (from trl->autotrain-advanced)\n",
            "  Downloading tyro-0.5.10-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.5.0->optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (2023.9.26)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.3.0->autotrain-advanced) (3.0.0)\n",
            "Collecting huggingface-hub>=0.16.4 (from autotrain-advanced)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced) (2.1.0)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.7->trl->autotrain-advanced)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl->autotrain-advanced) (13.6.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.7->trl->autotrain-advanced)\n",
            "  Downloading shtab-1.6.4-py3-none-any.whl (13 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow->codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.41.0->autotrain-advanced) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.4->autotrain-advanced) (3.17.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio==3.41.0->autotrain-advanced) (1.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.10.6)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl->autotrain-advanced) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl->autotrain-advanced) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible-watermark==0.2.0->autotrain-advanced) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl->autotrain-advanced) (0.1.2)\n",
            "Building wheels for collected packages: ipadic, sacremoses, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=94924e751e194b1e279197b026281e5238715ee19f5c6ae9fa28cb9dc3875d66\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=f6f87c3b0ad09aacca652498e2308ebf39e343c68fbe583ba6f2a10696d3f9fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=7fd071b7c00ff5b933e2b7da0ae1f8792e0c104bae635ad70146770cd0bfa4b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ipadic sacremoses ffmpy\n",
            "Installing collected packages: types-python-dateutil, sentencepiece, pydub, ipadic, fuzzywuzzy, ffmpy, bitsandbytes, werkzeug, websockets, typing-extensions, tqdm, shtab, semantic-version, safetensors, rapidfuzz, python-multipart, pynvml, protobuf, Pillow, packaging, orjson, Mako, loguru, joblib, h11, einops, docstring-parser, dill, colorlog, cmaes, aiofiles, xgboost, uvicorn, tiktoken, starlette, scikit-learn, sacremoses, responses, pydantic, multiprocess, jiwer, huggingface-hub, httpcore, arrow, tyro, tokenizers, invisible-watermark, httpx, fastapi, diffusers, codecarbon, alembic, accelerate, transformers, optuna, gradio-client, datasets, trl, peft, gradio, evaluate, autotrain-advanced\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.0\n",
            "    Uninstalling Werkzeug-3.0.0:\n",
            "      Successfully uninstalled Werkzeug-3.0.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.0\n",
            "    Uninstalling xgboost-2.0.0:\n",
            "      Successfully uninstalled xgboost-2.0.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.4 Pillow-10.0.0 accelerate-0.23.0 aiofiles-23.2.1 alembic-1.12.0 arrow-1.3.0 autotrain-advanced-0.6.37 bitsandbytes-0.41.1 cmaes-0.10.0 codecarbon-2.2.3 colorlog-6.7.0 datasets-2.14.5 diffusers-0.21.4 dill-0.3.7 docstring-parser-0.15 einops-0.6.1 evaluate-0.3.0 fastapi-0.104.0 ffmpy-0.3.1 fuzzywuzzy-0.18.0 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-3.0.2 joblib-1.3.1 loguru-0.7.0 multiprocess-0.70.15 optuna-3.3.0 orjson-3.9.9 packaging-23.1 peft-0.5.0 protobuf-4.23.4 pydantic-1.10.11 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.6 rapidfuzz-2.13.7 responses-0.18.0 sacremoses-0.0.53 safetensors-0.4.0 scikit-learn-1.3.0 semantic-version-2.10.0 sentencepiece-0.1.99 shtab-1.6.4 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.14.1 tqdm-4.65.0 transformers-4.34.1 trl-0.7.2 types-python-dateutil-2.8.19.14 typing-extensions-4.8.0 tyro-0.5.10 uvicorn-0.23.2 websockets-11.0.3 werkzeug-2.3.6 xgboost-1.7.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: WARNING restart the runtime."
      ],
      "metadata": {
        "id": "3XkxVtsmo8hI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #autotrain help\n",
        "# !autotrain llm --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7C0pCNEwfr7",
        "outputId": "bbebcf76-5a9a-404c-84d9-191e0b93cedb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: autotrain <command> [<args>] llm [-h] [--train] [--deploy] [--inference]\n",
            "                                        [--data_path DATA_PATH] [--train_split TRAIN_SPLIT]\n",
            "                                        [--valid_split VALID_SPLIT] [--text_column TEXT_COLUMN]\n",
            "                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n",
            "                                        [--model MODEL] [--learning_rate LEARNING_RATE]\n",
            "                                        [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                                        [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                                        [--warmup_ratio WARMUP_RATIO]\n",
            "                                        [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n",
            "                                        [--weight_decay WEIGHT_DECAY]\n",
            "                                        [--max_grad_norm MAX_GRAD_NORM] [--seed SEED]\n",
            "                                        [--add_eos_token] [--block_size BLOCK_SIZE] [--use_peft]\n",
            "                                        [--lora_r LORA_R] [--lora_alpha LORA_ALPHA]\n",
            "                                        [--lora_dropout LORA_DROPOUT]\n",
            "                                        [--logging_steps LOGGING_STEPS]\n",
            "                                        [--project_name PROJECT_NAME]\n",
            "                                        [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                                        [--save_strategy SAVE_STRATEGY] [--auto_find_batch_size]\n",
            "                                        [--fp16] [--push_to_hub] [--use_int8]\n",
            "                                        [--model_max_length MODEL_MAX_LENGTH] [--repo_id REPO_ID]\n",
            "                                        [--use_int4] [--trainer TRAINER]\n",
            "                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n",
            "                                        [--token TOKEN] [--backend BACKEND] [--username USERNAME]\n",
            "                                        [--use_flash_attention_2]\n",
            "                                        [--disable_gradient_checkpointing]\n",
            "\n",
            "✨ Run AutoTrain LLM\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --train               Train the model\n",
            "  --deploy              Deploy the model\n",
            "  --inference           Run inference\n",
            "  --data_path DATA_PATH, --data-path DATA_PATH\n",
            "                        Train dataset to use\n",
            "  --train_split TRAIN_SPLIT, --train-split TRAIN_SPLIT\n",
            "                        Test dataset split to use\n",
            "  --valid_split VALID_SPLIT, --valid-split VALID_SPLIT\n",
            "                        Validation dataset split to use\n",
            "  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n",
            "                        Text column to use\n",
            "  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n",
            "                        Rejected text column to use\n",
            "  --model MODEL         Model to use\n",
            "  --learning_rate LEARNING_RATE, --lr LEARNING_RATE, --learning-rate LEARNING_RATE\n",
            "                        Learning rate to use\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS, --epochs NUM_TRAIN_EPOCHS\n",
            "                        Number of training epochs to use\n",
            "  --train_batch_size TRAIN_BATCH_SIZE, --train-batch-size TRAIN_BATCH_SIZE, --batch-size TRAIN_BATCH_SIZE\n",
            "                        Training batch size to use\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Warmup proportion to use\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS, --gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS, --gradient-accumulation GRADIENT_ACCUMULATION_STEPS\n",
            "                        Gradient accumulation steps to use\n",
            "  --optimizer OPTIMIZER\n",
            "                        Optimizer to use\n",
            "  --scheduler SCHEDULER\n",
            "                        Scheduler to use\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay to use\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm to use\n",
            "  --seed SEED           Seed to use\n",
            "  --add_eos_token, --add-eos-token\n",
            "                        Add EOS token to use\n",
            "  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n",
            "                        Block size to use\n",
            "  --use_peft, --use-peft\n",
            "                        Use PEFT to use\n",
            "  --lora_r LORA_R, --lora-r LORA_R\n",
            "                        Lora r to use\n",
            "  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n",
            "                        Lora alpha to use\n",
            "  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n",
            "                        Lora dropout to use\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Logging steps to use\n",
            "  --project_name PROJECT_NAME, --project-name PROJECT_NAME\n",
            "                        Output directory\n",
            "  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n",
            "                        Evaluation strategy to use\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        Save total limit to use\n",
            "  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n",
            "                        Save strategy to use\n",
            "  --auto_find_batch_size, --auto-find-batch-size\n",
            "                        Auto find batch size True/False\n",
            "  --fp16                FP16 True/False\n",
            "  --push_to_hub, --push-to-hub\n",
            "                        Push to hub True/False. In case you want to push the trained model to\n",
            "                        huggingface hub\n",
            "  --use_int8, --use-int8\n",
            "                        Use int8 True/False\n",
            "  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n",
            "                        Model max length to use\n",
            "  --repo_id REPO_ID, --repo-id REPO_ID\n",
            "                        Repo id for hugging face hub. Format is username/repo_name\n",
            "  --use_int4, --use-int4\n",
            "                        Use int4 True/False\n",
            "  --trainer TRAINER     Trainer type to use\n",
            "  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n",
            "                        Target modules to use\n",
            "  --merge_adapter, --merge-adapter\n",
            "                        Use this flag to merge PEFT adapter with the model\n",
            "  --token TOKEN         Hugingface token to use\n",
            "  --backend BACKEND     Backend to use: default or spaces. Spaces backend requires push_to_hub and\n",
            "                        repo_id\n",
            "  --username USERNAME   Huggingface username to use\n",
            "  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n",
            "                        Use flash attention 2\n",
            "  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n",
            "                        Disable gradient checkpointing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain setup --update-torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyfE8-aQwft0",
        "outputId": "8724f30e-bce2-4192-c546-4d661780b13f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest transformers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest transformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest peft@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest peft\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest diffusers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest diffusers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest trl@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest trl\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging to the HF hub to get access to the authentication token\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "aa9e58e43528405c986c72899203cfec",
            "b5fe63ee6da442baaa6fd3fbcf4db428",
            "330aeedc1d2d48409cc7b85d9be070b0",
            "34411f8e65da4c3689738acafcf210e0",
            "b5152ba1d2b34ddf8c8facd2f1ebdf93",
            "cbf916f831f7472ca5f222ba0d814c17",
            "bc0862611cdb4cbf93c362888bd36563",
            "633430202d6745478caaa1ff114f7b2e",
            "0136fbaa677543f29b2d98d347a707dd",
            "c309fa2db0ce4b5aa62d2da79e2d788f",
            "9f845cb0986245038bd1a9c62965bb4f",
            "9e8664c705034e64837b1bc5e2ff313e",
            "3eb85ffaf1654998991c2cfbf1c2899d",
            "39fc6d875c764bc2994e7af87a31e731",
            "158e1e731c8a4017bed6f3fe5bde9e3b",
            "998b51e2bb904fe8960083d97c0332e5",
            "69ee0b6470454a0d9b7f2e820ed8425a",
            "30716ca2945f4d1a929dc65e3651a4ae",
            "86f507528cb847ffb346eaa5ea85f871",
            "d065a34cc36b42ffa93dc40d759686c6",
            "2a3f55dc6cb840ed89ba1a1e5f513ba3",
            "1d0c21ea29e44fbb8602679bcde85e65",
            "41ee4ece6eb04a27b900655f600f27b1",
            "9d8f69b3eddd4c03a23f3d99747e1213",
            "0d7a09edc11b4ebdabb0f1d69fb3f902",
            "8020ab7b1b3741bd998cba67cf05b4a7",
            "b3bb1c95333041538813df9a210842a5",
            "86bc3818f6c44d14ac8b385f8d5c9c41",
            "83432cd04d7a4d3c90f9a9505e8d86d2",
            "a7716629f4d34c52a790fe9ceef59411",
            "47815241f6dc4b9985666f56cd0ee7d2",
            "3813fca1e07d47088dadc4e09b17d63a"
          ]
        },
        "id": "aIrhKEsTyurv",
        "outputId": "c3260ed0-4e5c-4cf5-8e75-91da6b2bb37f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa9e58e43528405c986c72899203cfec"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ3oKWwd7mwL",
        "outputId": "0d31a6bb-1ab3-4fc0-f22d-1be26d371e68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.22.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tune LLM\n",
        "!autotrain llm --train   \\\n",
        "--project_name 'llama2-MJ-prompts' \\\n",
        "--model 'abhishek/llama-2-7b-hf-small-shards' \\\n",
        "--text_column text \\\n",
        "--data_path .  \\\n",
        "--use_peft  \\\n",
        "--use_int4 \\\n",
        "--use_fp16 = True \\\n",
        "--learning_rate 2e-4  \\\n",
        "--train_batch_size 4 \\\n",
        "--num_train_epochs 9 \\\n",
        "--trainer sft  \\\n",
        "--model_max_length 2048  \\\n",
        "--push_to_hub  \\\n",
        "--token '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' \\\n",
        "--repo_id royam0820/llama2-MJ-prompts  \\\n",
        "--block_size 1024 > training.log &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGgkAckcjh6a",
        "outputId": "90e618bf-d277-4182-c720-e96c1019defe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
            "    Python  3.10.13 (you have 3.10.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, train=True, deploy=False, inference=False, data_path='.', train_split='train', valid_split=None, text_column='text', rejected_text_column='rejected', model='abhishek/llama-2-7b-hf-small-shards', learning_rate=3e-05, num_train_epochs=1, train_batch_size=2, warmup_ratio=0.1, gradient_accumulation_steps=1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, seed=42, add_eos_token=False, block_size=-1, use_peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, project_name='llama2-MJ-prompts', evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, fp16=False, push_to_hub=False, use_int8=False, model_max_length=1024, repo_id=None, use_int4=True, trainer='default', target_modules=None, merge_adapter=False, token=None, backend='default', username=None, use_flash_attention_2=False, disable_gradient_checkpointing=False, func=<function run_llm_command_factory at 0x7ba0dba763b0>)\u001b[0m\n",
            "> \u001b[1mINFO    loading dataset from csv\u001b[0m\n",
            "Downloading (…)okenizer_config.json: 100% 746/746 [00:00<00:00, 3.10MB/s]\n",
            "Downloading tokenizer.model: 100% 500k/500k [00:00<00:00, 44.1MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 2.57MB/s]\n",
            "Downloading (…)in/added_tokens.json: 100% 21.0/21.0 [00:00<00:00, 146kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 435/435 [00:00<00:00, 2.61MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 625/625 [00:00<00:00, 2.98MB/s]\n",
            "Downloading (…)model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 103MB/s]\n",
            "Downloading shards:   0% 0/10 [00:00<?, ?it/s]\n",
            "Downloading (…)l-00001-of-00010.bin:   0% 0.00/2.95G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   1% 31.5M/2.95G [00:00<00:10, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   2% 62.9M/2.95G [00:00<00:13, 213MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   3% 94.4M/2.95G [00:00<00:11, 243MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   4% 126M/2.95G [00:00<00:11, 242MB/s] \u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   5% 157M/2.95G [00:00<00:12, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   6% 189M/2.95G [00:00<00:11, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   7% 220M/2.95G [00:00<00:10, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:   9% 252M/2.95G [00:01<00:11, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  10% 283M/2.95G [00:01<00:11, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  11% 315M/2.95G [00:01<00:10, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  12% 346M/2.95G [00:01<00:11, 222MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  13% 377M/2.95G [00:01<00:11, 228MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  14% 409M/2.95G [00:01<00:10, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  15% 451M/2.95G [00:01<00:08, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  17% 503M/2.95G [00:01<00:07, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  18% 545M/2.95G [00:02<00:08, 292MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  20% 577M/2.95G [00:02<00:09, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  21% 608M/2.95G [00:02<00:08, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  22% 640M/2.95G [00:02<00:09, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  23% 671M/2.95G [00:02<00:08, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  24% 713M/2.95G [00:02<00:07, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  25% 744M/2.95G [00:02<00:07, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  26% 776M/2.95G [00:02<00:07, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  28% 818M/2.95G [00:03<00:06, 310MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  29% 849M/2.95G [00:03<00:07, 297MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  30% 881M/2.95G [00:03<00:07, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  31% 912M/2.95G [00:03<00:08, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  32% 944M/2.95G [00:03<00:07, 254MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  33% 986M/2.95G [00:03<00:07, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  34% 1.02G/2.95G [00:03<00:07, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  36% 1.06G/2.95G [00:03<00:06, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  37% 1.10G/2.95G [00:04<00:05, 320MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  39% 1.14G/2.95G [00:04<00:05, 341MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  40% 1.18G/2.95G [00:04<00:05, 321MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  42% 1.23G/2.95G [00:04<00:05, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  43% 1.27G/2.95G [00:04<00:05, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  44% 1.31G/2.95G [00:04<00:05, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  46% 1.35G/2.95G [00:04<00:05, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  47% 1.38G/2.95G [00:05<00:06, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  48% 1.43G/2.95G [00:05<00:05, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  49% 1.46G/2.95G [00:05<00:05, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  51% 1.51G/2.95G [00:05<00:04, 302MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  52% 1.54G/2.95G [00:05<00:05, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  53% 1.57G/2.95G [00:05<00:05, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  54% 1.60G/2.95G [00:05<00:05, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  55% 1.64G/2.95G [00:06<00:04, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  57% 1.68G/2.95G [00:06<00:04, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  58% 1.72G/2.95G [00:06<00:04, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  59% 1.75G/2.95G [00:06<00:04, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  60% 1.78G/2.95G [00:06<00:04, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  61% 1.81G/2.95G [00:06<00:06, 187MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  62% 1.85G/2.95G [00:07<00:05, 209MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  64% 1.88G/2.95G [00:07<00:05, 211MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  65% 1.91G/2.95G [00:07<00:04, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  66% 1.94G/2.95G [00:07<00:04, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  67% 1.98G/2.95G [00:07<00:03, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  68% 2.01G/2.95G [00:07<00:03, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  70% 2.06G/2.95G [00:07<00:03, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  71% 2.09G/2.95G [00:07<00:03, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  72% 2.13G/2.95G [00:08<00:02, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  74% 2.17G/2.95G [00:08<00:02, 313MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  75% 2.21G/2.95G [00:08<00:02, 328MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  76% 2.25G/2.95G [00:08<00:02, 332MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  78% 2.30G/2.95G [00:08<00:01, 335MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  79% 2.34G/2.95G [00:08<00:01, 327MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  81% 2.38G/2.95G [00:08<00:01, 324MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  82% 2.42G/2.95G [00:08<00:01, 342MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  83% 2.46G/2.95G [00:09<00:01, 330MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  85% 2.51G/2.95G [00:09<00:01, 324MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  86% 2.55G/2.95G [00:09<00:01, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  87% 2.58G/2.95G [00:09<00:01, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  89% 2.62G/2.95G [00:09<00:01, 306MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  90% 2.66G/2.95G [00:09<00:00, 334MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  92% 2.71G/2.95G [00:09<00:00, 319MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  93% 2.75G/2.95G [00:09<00:00, 312MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  94% 2.79G/2.95G [00:10<00:00, 323MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  96% 2.83G/2.95G [00:10<00:00, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  97% 2.86G/2.95G [00:10<00:00, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin:  98% 2.89G/2.95G [00:10<00:00, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00010.bin: 100% 2.95G/2.95G [00:10<00:00, 277MB/s]\n",
            "Downloading shards:  10% 1/10 [00:10<01:38, 10.96s/it]\n",
            "Downloading (…)l-00002-of-00010.bin:   0% 0.00/2.88G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:   1% 31.5M/2.88G [00:00<00:09, 303MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:   3% 73.4M/2.88G [00:00<00:07, 361MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:   4% 115M/2.88G [00:00<00:07, 375MB/s] \u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:   5% 157M/2.88G [00:00<00:07, 371MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:   7% 199M/2.88G [00:00<00:08, 315MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:   8% 241M/2.88G [00:00<00:08, 311MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  10% 283M/2.88G [00:00<00:08, 290MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  11% 315M/2.88G [00:01<00:08, 292MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  12% 346M/2.88G [00:01<00:14, 170MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  13% 377M/2.88G [00:01<00:16, 151MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  14% 398M/2.88G [00:01<00:15, 159MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  15% 419M/2.88G [00:01<00:17, 143MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  15% 440M/2.88G [00:02<00:15, 153MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  16% 461M/2.88G [00:02<00:14, 163MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  17% 493M/2.88G [00:02<00:13, 181MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  18% 524M/2.88G [00:02<00:11, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  20% 566M/2.88G [00:02<00:09, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  21% 598M/2.88G [00:02<00:09, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  22% 629M/2.88G [00:02<00:08, 253MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  23% 671M/2.88G [00:02<00:07, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  24% 703M/2.88G [00:03<00:08, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  26% 734M/2.88G [00:03<00:07, 268MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  27% 765M/2.88G [00:03<00:09, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  28% 797M/2.88G [00:03<00:09, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  29% 828M/2.88G [00:03<00:08, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  30% 860M/2.88G [00:03<00:08, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  31% 891M/2.88G [00:03<00:08, 223MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  32% 923M/2.88G [00:04<00:08, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  34% 965M/2.88G [00:04<00:07, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  35% 1.01G/2.88G [00:04<00:06, 294MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  36% 1.04G/2.88G [00:04<00:06, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  37% 1.07G/2.88G [00:04<00:06, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  38% 1.10G/2.88G [00:04<00:06, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  39% 1.13G/2.88G [00:04<00:06, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  41% 1.17G/2.88G [00:04<00:05, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  42% 1.22G/2.88G [00:04<00:05, 316MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  44% 1.26G/2.88G [00:05<00:04, 327MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  45% 1.30G/2.88G [00:05<00:05, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  46% 1.33G/2.88G [00:05<00:05, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  48% 1.37G/2.88G [00:05<00:05, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  49% 1.41G/2.88G [00:05<00:05, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  50% 1.44G/2.88G [00:05<00:05, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  51% 1.47G/2.88G [00:05<00:05, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  52% 1.51G/2.88G [00:06<00:05, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  54% 1.54G/2.88G [00:06<00:05, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  55% 1.57G/2.88G [00:06<00:04, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  56% 1.60G/2.88G [00:06<00:04, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  57% 1.64G/2.88G [00:06<00:04, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  58% 1.67G/2.88G [00:06<00:04, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  59% 1.70G/2.88G [00:06<00:05, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  60% 1.73G/2.88G [00:07<00:05, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  61% 1.76G/2.88G [00:07<00:04, 230MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  63% 1.80G/2.88G [00:07<00:04, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  64% 1.85G/2.88G [00:07<00:03, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  65% 1.88G/2.88G [00:07<00:03, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  66% 1.91G/2.88G [00:07<00:03, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  67% 1.94G/2.88G [00:07<00:03, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  69% 1.97G/2.88G [00:07<00:03, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  70% 2.00G/2.88G [00:08<00:03, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  71% 2.03G/2.88G [00:08<00:03, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  72% 2.08G/2.88G [00:08<00:02, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  74% 2.12G/2.88G [00:08<00:02, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  75% 2.16G/2.88G [00:08<00:02, 314MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  77% 2.20G/2.88G [00:08<00:02, 323MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  78% 2.24G/2.88G [00:08<00:01, 331MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  79% 2.29G/2.88G [00:08<00:01, 351MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  81% 2.33G/2.88G [00:09<00:01, 319MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  82% 2.37G/2.88G [00:09<00:01, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  83% 2.40G/2.88G [00:09<00:01, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  85% 2.43G/2.88G [00:09<00:02, 181MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  86% 2.47G/2.88G [00:09<00:02, 200MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  87% 2.51G/2.88G [00:10<00:02, 182MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  88% 2.53G/2.88G [00:10<00:02, 170MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  89% 2.57G/2.88G [00:10<00:01, 209MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  91% 2.61G/2.88G [00:10<00:01, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  92% 2.65G/2.88G [00:10<00:00, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  93% 2.68G/2.88G [00:10<00:00, 253MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  95% 2.73G/2.88G [00:10<00:00, 268MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  96% 2.76G/2.88G [00:11<00:00, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  97% 2.79G/2.88G [00:11<00:00, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin:  98% 2.83G/2.88G [00:11<00:00, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00010.bin: 100% 2.88G/2.88G [00:11<00:00, 251MB/s]\n",
            "Downloading shards:  20% 2/10 [00:22<01:31, 11.42s/it]\n",
            "Downloading (…)l-00003-of-00010.bin:   0% 0.00/2.99G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   1% 31.5M/2.99G [00:00<00:11, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   2% 73.4M/2.99G [00:00<00:09, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   4% 115M/2.99G [00:00<00:09, 291MB/s] \u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   5% 147M/2.99G [00:00<00:11, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   6% 178M/2.99G [00:00<00:11, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   7% 210M/2.99G [00:00<00:11, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   8% 241M/2.99G [00:00<00:10, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:   9% 273M/2.99G [00:01<00:10, 253MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  10% 304M/2.99G [00:01<00:10, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  12% 346M/2.99G [00:01<00:09, 284MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  13% 377M/2.99G [00:01<00:10, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  14% 409M/2.99G [00:01<00:10, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  15% 440M/2.99G [00:01<00:10, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  16% 482M/2.99G [00:01<00:09, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  17% 514M/2.99G [00:01<00:09, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  19% 556M/2.99G [00:02<00:08, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  20% 587M/2.99G [00:02<00:08, 284MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  21% 619M/2.99G [00:02<00:08, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  22% 650M/2.99G [00:02<00:08, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  23% 682M/2.99G [00:02<00:07, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  24% 713M/2.99G [00:02<00:08, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  25% 744M/2.99G [00:02<00:08, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  26% 776M/2.99G [00:02<00:08, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  27% 818M/2.99G [00:03<00:07, 283MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  28% 849M/2.99G [00:03<00:07, 288MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  30% 891M/2.99G [00:03<00:07, 298MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  31% 923M/2.99G [00:03<00:08, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  32% 965M/2.99G [00:03<00:07, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  33% 996M/2.99G [00:03<00:07, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  34% 1.03G/2.99G [00:03<00:07, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  35% 1.06G/2.99G [00:03<00:07, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  37% 1.10G/2.99G [00:04<00:06, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  38% 1.13G/2.99G [00:04<00:10, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  39% 1.16G/2.99G [00:04<00:10, 180MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  40% 1.18G/2.99G [00:04<00:10, 169MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  40% 1.21G/2.99G [00:04<00:10, 168MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  41% 1.24G/2.99G [00:05<00:09, 191MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  42% 1.27G/2.99G [00:05<00:08, 197MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  43% 1.30G/2.99G [00:05<00:08, 205MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  45% 1.33G/2.99G [00:05<00:07, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  46% 1.36G/2.99G [00:05<00:07, 215MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  47% 1.39G/2.99G [00:05<00:06, 230MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  48% 1.43G/2.99G [00:05<00:07, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  49% 1.47G/2.99G [00:06<00:06, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  50% 1.51G/2.99G [00:06<00:05, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  52% 1.54G/2.99G [00:06<00:05, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  53% 1.57G/2.99G [00:06<00:05, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  54% 1.60G/2.99G [00:06<00:05, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  55% 1.65G/2.99G [00:06<00:04, 292MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  56% 1.68G/2.99G [00:06<00:04, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  58% 1.72G/2.99G [00:06<00:04, 283MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  59% 1.75G/2.99G [00:07<00:04, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  60% 1.78G/2.99G [00:07<00:04, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  61% 1.81G/2.99G [00:07<00:04, 284MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  62% 1.86G/2.99G [00:07<00:03, 294MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  63% 1.89G/2.99G [00:07<00:03, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  65% 1.93G/2.99G [00:07<00:03, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  66% 1.96G/2.99G [00:07<00:03, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  67% 1.99G/2.99G [00:07<00:04, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  68% 2.02G/2.99G [00:08<00:04, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  69% 2.07G/2.99G [00:08<00:03, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  70% 2.10G/2.99G [00:08<00:03, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  71% 2.13G/2.99G [00:08<00:03, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  73% 2.17G/2.99G [00:08<00:02, 290MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  74% 2.20G/2.99G [00:08<00:02, 293MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  75% 2.23G/2.99G [00:08<00:03, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  76% 2.26G/2.99G [00:08<00:02, 254MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  77% 2.30G/2.99G [00:09<00:02, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  78% 2.33G/2.99G [00:09<00:02, 244MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  79% 2.36G/2.99G [00:09<00:02, 229MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  80% 2.39G/2.99G [00:09<00:02, 226MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  81% 2.42G/2.99G [00:09<00:02, 243MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  82% 2.45G/2.99G [00:09<00:02, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  83% 2.50G/2.99G [00:09<00:01, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  84% 2.53G/2.99G [00:09<00:01, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  86% 2.56G/2.99G [00:10<00:01, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  87% 2.59G/2.99G [00:10<00:01, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  88% 2.62G/2.99G [00:10<00:01, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  89% 2.65G/2.99G [00:10<00:01, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  90% 2.69G/2.99G [00:10<00:00, 298MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  91% 2.73G/2.99G [00:10<00:01, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  92% 2.76G/2.99G [00:10<00:00, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  94% 2.80G/2.99G [00:11<00:00, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  95% 2.83G/2.99G [00:11<00:00, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  96% 2.86G/2.99G [00:11<00:00, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  97% 2.89G/2.99G [00:11<00:00, 223MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  98% 2.93G/2.99G [00:11<00:00, 148MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  99% 2.95G/2.99G [00:11<00:00, 152MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin:  99% 2.97G/2.99G [00:12<00:00, 158MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00010.bin: 100% 2.99G/2.99G [00:12<00:00, 242MB/s]\n",
            "Downloading shards:  30% 3/10 [00:35<01:23, 11.98s/it]\n",
            "Downloading (…)l-00004-of-00010.bin:   0% 0.00/2.86G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   1% 21.0M/2.86G [00:00<00:22, 128MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   2% 52.4M/2.86G [00:00<00:15, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   3% 83.9M/2.86G [00:00<00:13, 207MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   4% 115M/2.86G [00:00<00:12, 219MB/s] \u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   5% 147M/2.86G [00:00<00:15, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   6% 168M/2.86G [00:00<00:15, 174MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   7% 189M/2.86G [00:01<00:15, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   7% 210M/2.86G [00:01<00:17, 149MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:   8% 241M/2.86G [00:01<00:14, 178MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  10% 273M/2.86G [00:01<00:12, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  11% 304M/2.86G [00:01<00:12, 211MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  12% 336M/2.86G [00:01<00:10, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  13% 367M/2.86G [00:01<00:10, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  14% 409M/2.86G [00:02<00:13, 179MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  16% 451M/2.86G [00:02<00:11, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  17% 493M/2.86G [00:02<00:09, 244MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  18% 524M/2.86G [00:02<00:09, 243MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  19% 556M/2.86G [00:02<00:09, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  21% 587M/2.86G [00:02<00:10, 210MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  22% 619M/2.86G [00:03<00:12, 180MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  22% 640M/2.86G [00:03<00:13, 160MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  23% 661M/2.86G [00:03<00:13, 168MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  24% 682M/2.86G [00:03<00:13, 158MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  25% 703M/2.86G [00:03<00:14, 144MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  26% 744M/2.86G [00:03<00:10, 197MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  27% 776M/2.86G [00:03<00:09, 211MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  28% 807M/2.86G [00:04<00:09, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  29% 839M/2.86G [00:04<00:09, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  30% 870M/2.86G [00:04<00:08, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  32% 902M/2.86G [00:04<00:07, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  33% 944M/2.86G [00:04<00:06, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  34% 975M/2.86G [00:04<00:06, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  35% 1.01G/2.86G [00:04<00:06, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  37% 1.05G/2.86G [00:04<00:06, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  38% 1.08G/2.86G [00:05<00:07, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  39% 1.12G/2.86G [00:05<00:06, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  40% 1.15G/2.86G [00:05<00:06, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  42% 1.20G/2.86G [00:05<00:05, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  43% 1.23G/2.86G [00:05<00:06, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  44% 1.26G/2.86G [00:05<00:07, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  45% 1.29G/2.86G [00:06<00:06, 228MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  46% 1.32G/2.86G [00:06<00:06, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  47% 1.35G/2.86G [00:06<00:07, 213MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  48% 1.38G/2.86G [00:06<00:06, 230MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  50% 1.42G/2.86G [00:06<00:07, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  51% 1.45G/2.86G [00:06<00:07, 193MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  51% 1.47G/2.86G [00:06<00:07, 192MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  52% 1.50G/2.86G [00:07<00:06, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  54% 1.53G/2.86G [00:07<00:06, 209MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  55% 1.56G/2.86G [00:07<00:05, 217MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  56% 1.59G/2.86G [00:07<00:06, 199MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  57% 1.64G/2.86G [00:07<00:05, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  58% 1.67G/2.86G [00:07<00:04, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  59% 1.70G/2.86G [00:07<00:04, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  61% 1.75G/2.86G [00:07<00:03, 299MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  62% 1.78G/2.86G [00:08<00:03, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  64% 1.82G/2.86G [00:08<00:03, 307MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  65% 1.86G/2.86G [00:08<00:03, 298MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  66% 1.90G/2.86G [00:08<00:03, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  68% 1.93G/2.86G [00:08<00:03, 307MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  69% 1.96G/2.86G [00:08<00:02, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  70% 1.99G/2.86G [00:08<00:02, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  71% 2.02G/2.86G [00:08<00:02, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  72% 2.07G/2.86G [00:09<00:02, 313MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  74% 2.11G/2.86G [00:09<00:02, 295MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  75% 2.14G/2.86G [00:09<00:02, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  76% 2.17G/2.86G [00:09<00:02, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  77% 2.20G/2.86G [00:09<00:02, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  78% 2.23G/2.86G [00:09<00:02, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  79% 2.26G/2.86G [00:09<00:02, 200MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  80% 2.30G/2.86G [00:10<00:02, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  82% 2.34G/2.86G [00:10<00:02, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  83% 2.38G/2.86G [00:10<00:01, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  85% 2.42G/2.86G [00:10<00:01, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  86% 2.45G/2.86G [00:10<00:01, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  87% 2.49G/2.86G [00:10<00:02, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  88% 2.52G/2.86G [00:11<00:01, 199MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  90% 2.56G/2.86G [00:11<00:01, 228MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  91% 2.59G/2.86G [00:11<00:01, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  92% 2.62G/2.86G [00:11<00:00, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  93% 2.66G/2.86G [00:11<00:00, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  94% 2.69G/2.86G [00:11<00:00, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  95% 2.73G/2.86G [00:11<00:00, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  97% 2.76G/2.86G [00:11<00:00, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  98% 2.79G/2.86G [00:12<00:00, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin:  99% 2.82G/2.86G [00:12<00:00, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00010.bin: 100% 2.86G/2.86G [00:12<00:00, 232MB/s]\n",
            "Downloading shards:  40% 4/10 [00:47<01:13, 12.23s/it]\n",
            "Downloading (…)l-00005-of-00010.bin:   0% 0.00/2.88G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   1% 31.5M/2.88G [00:00<00:10, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   2% 62.9M/2.88G [00:00<00:11, 244MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   3% 94.4M/2.88G [00:00<00:10, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   4% 126M/2.88G [00:00<00:10, 250MB/s] \u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   5% 157M/2.88G [00:00<00:13, 195MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   7% 189M/2.88G [00:01<00:18, 146MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   8% 220M/2.88G [00:01<00:15, 170MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   8% 241M/2.88G [00:01<00:15, 171MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:   9% 273M/2.88G [00:01<00:14, 182MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  10% 294M/2.88G [00:01<00:15, 166MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  11% 315M/2.88G [00:01<00:16, 160MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  12% 336M/2.88G [00:01<00:15, 162MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  12% 357M/2.88G [00:01<00:14, 168MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  13% 377M/2.88G [00:02<00:14, 175MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  14% 398M/2.88G [00:02<00:14, 173MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  15% 419M/2.88G [00:02<00:13, 179MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  15% 440M/2.88G [00:02<00:14, 165MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  16% 472M/2.88G [00:02<00:13, 173MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  17% 493M/2.88G [00:02<00:13, 179MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  18% 524M/2.88G [00:02<00:12, 192MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  19% 556M/2.88G [00:03<00:11, 210MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  20% 587M/2.88G [00:03<00:10, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  22% 619M/2.88G [00:03<00:11, 189MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  23% 661M/2.88G [00:03<00:09, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  24% 692M/2.88G [00:03<00:11, 183MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  25% 724M/2.88G [00:03<00:10, 200MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  27% 765M/2.88G [00:04<00:09, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  28% 797M/2.88G [00:04<00:08, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  29% 839M/2.88G [00:04<00:08, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  30% 870M/2.88G [00:04<00:07, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  32% 912M/2.88G [00:04<00:06, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  33% 944M/2.88G [00:04<00:08, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  34% 975M/2.88G [00:04<00:07, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  35% 1.01G/2.88G [00:04<00:07, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  36% 1.04G/2.88G [00:05<00:06, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  37% 1.07G/2.88G [00:05<00:07, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  38% 1.10G/2.88G [00:05<00:07, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  39% 1.13G/2.88G [00:05<00:07, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  40% 1.16G/2.88G [00:05<00:07, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  42% 1.20G/2.88G [00:05<00:06, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  43% 1.23G/2.88G [00:05<00:06, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  44% 1.26G/2.88G [00:05<00:06, 268MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  45% 1.30G/2.88G [00:06<00:05, 275MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  46% 1.33G/2.88G [00:06<00:05, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  48% 1.37G/2.88G [00:06<00:05, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  49% 1.41G/2.88G [00:06<00:05, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  50% 1.44G/2.88G [00:06<00:05, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  51% 1.47G/2.88G [00:06<00:06, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  52% 1.50G/2.88G [00:06<00:06, 229MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  53% 1.53G/2.88G [00:07<00:05, 234MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  54% 1.56G/2.88G [00:07<00:05, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  56% 1.60G/2.88G [00:07<00:04, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  57% 1.65G/2.88G [00:07<00:03, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  59% 1.69G/2.88G [00:07<00:04, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  60% 1.72G/2.88G [00:07<00:04, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  61% 1.75G/2.88G [00:07<00:04, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  62% 1.78G/2.88G [00:07<00:04, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  63% 1.81G/2.88G [00:08<00:03, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  65% 1.86G/2.88G [00:08<00:03, 295MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  66% 1.89G/2.88G [00:08<00:04, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  67% 1.92G/2.88G [00:08<00:04, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  68% 1.96G/2.88G [00:08<00:03, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  69% 1.99G/2.88G [00:08<00:03, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  70% 2.02G/2.88G [00:08<00:03, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  71% 2.06G/2.88G [00:08<00:03, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  73% 2.10G/2.88G [00:09<00:02, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  74% 2.13G/2.88G [00:09<00:03, 189MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  75% 2.16G/2.88G [00:09<00:03, 199MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  76% 2.19G/2.88G [00:09<00:03, 210MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  77% 2.22G/2.88G [00:09<00:02, 228MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  78% 2.25G/2.88G [00:09<00:02, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  79% 2.29G/2.88G [00:10<00:02, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  81% 2.33G/2.88G [00:10<00:02, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  82% 2.36G/2.88G [00:10<00:01, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  83% 2.39G/2.88G [00:10<00:02, 189MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  84% 2.42G/2.88G [00:10<00:02, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  85% 2.45G/2.88G [00:10<00:02, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  86% 2.49G/2.88G [00:10<00:01, 198MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  88% 2.53G/2.88G [00:11<00:01, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  89% 2.56G/2.88G [00:11<00:01, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  90% 2.59G/2.88G [00:11<00:01, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  91% 2.62G/2.88G [00:11<00:01, 196MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  92% 2.65G/2.88G [00:11<00:01, 212MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  93% 2.68G/2.88G [00:11<00:00, 196MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  94% 2.71G/2.88G [00:12<00:00, 179MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  95% 2.75G/2.88G [00:12<00:00, 217MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  97% 2.79G/2.88G [00:12<00:00, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin:  98% 2.83G/2.88G [00:12<00:00, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00010.bin: 100% 2.88G/2.88G [00:12<00:00, 228MB/s]\n",
            "Downloading shards:  50% 5/10 [01:00<01:02, 12.47s/it]\n",
            "Downloading (…)l-00006-of-00010.bin:   0% 0.00/2.97G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   1% 21.0M/2.97G [00:00<00:16, 181MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   2% 62.9M/2.97G [00:00<00:10, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   3% 94.4M/2.97G [00:00<00:12, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   4% 126M/2.97G [00:00<00:12, 221MB/s] \u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   5% 157M/2.97G [00:00<00:12, 218MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   6% 189M/2.97G [00:00<00:13, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   7% 210M/2.97G [00:00<00:13, 207MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   8% 241M/2.97G [00:01<00:12, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:   9% 273M/2.97G [00:01<00:11, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  10% 304M/2.97G [00:01<00:11, 223MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  11% 336M/2.97G [00:01<00:13, 200MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  12% 367M/2.97G [00:01<00:12, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  13% 398M/2.97G [00:01<00:11, 226MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  14% 430M/2.97G [00:01<00:10, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  16% 461M/2.97G [00:02<00:11, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  17% 493M/2.97G [00:02<00:16, 150MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  18% 535M/2.97G [00:02<00:12, 193MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  19% 566M/2.97G [00:02<00:12, 186MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  20% 598M/2.97G [00:02<00:12, 186MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  21% 629M/2.97G [00:03<00:12, 195MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  23% 671M/2.97G [00:03<00:10, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  24% 703M/2.97G [00:03<00:09, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  25% 734M/2.97G [00:03<00:09, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  26% 765M/2.97G [00:03<00:09, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  27% 797M/2.97G [00:03<00:08, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  28% 828M/2.97G [00:03<00:08, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  29% 860M/2.97G [00:03<00:08, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  30% 891M/2.97G [00:04<00:09, 216MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  31% 923M/2.97G [00:04<00:09, 205MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  32% 954M/2.97G [00:04<00:09, 218MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  33% 986M/2.97G [00:04<00:08, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  34% 1.02G/2.97G [00:04<00:08, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  35% 1.05G/2.97G [00:04<00:08, 220MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  36% 1.08G/2.97G [00:04<00:08, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  37% 1.11G/2.97G [00:05<00:08, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  38% 1.14G/2.97G [00:05<00:08, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  40% 1.18G/2.97G [00:05<00:06, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  41% 1.22G/2.97G [00:05<00:08, 216MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  42% 1.25G/2.97G [00:05<00:08, 211MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  43% 1.29G/2.97G [00:05<00:08, 202MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  44% 1.32G/2.97G [00:07<00:30, 53.3MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  46% 1.36G/2.97G [00:07<00:21, 74.2MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  47% 1.38G/2.97G [00:07<00:18, 84.0MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  48% 1.42G/2.97G [00:08<00:14, 104MB/s] \u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  48% 1.44G/2.97G [00:08<00:13, 117MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  49% 1.46G/2.97G [00:08<00:11, 130MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  50% 1.49G/2.97G [00:08<00:09, 151MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  51% 1.52G/2.97G [00:08<00:08, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  52% 1.55G/2.97G [00:08<00:07, 194MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  53% 1.58G/2.97G [00:08<00:06, 211MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  55% 1.63G/2.97G [00:08<00:05, 244MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  56% 1.66G/2.97G [00:09<00:05, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  57% 1.69G/2.97G [00:09<00:05, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  58% 1.72G/2.97G [00:09<00:05, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  59% 1.75G/2.97G [00:09<00:05, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  60% 1.78G/2.97G [00:09<00:04, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  61% 1.81G/2.97G [00:09<00:04, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  62% 1.85G/2.97G [00:09<00:04, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  63% 1.88G/2.97G [00:09<00:04, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  64% 1.91G/2.97G [00:10<00:05, 188MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  65% 1.94G/2.97G [00:10<00:04, 209MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  67% 1.98G/2.97G [00:10<00:04, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  68% 2.01G/2.97G [00:10<00:04, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  69% 2.04G/2.97G [00:10<00:03, 244MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  70% 2.09G/2.97G [00:10<00:03, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  71% 2.12G/2.97G [00:10<00:03, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  72% 2.15G/2.97G [00:11<00:03, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  73% 2.18G/2.97G [00:12<00:11, 67.0MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  75% 2.21G/2.97G [00:12<00:08, 85.3MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  76% 2.24G/2.97G [00:12<00:07, 99.0MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  76% 2.26G/2.97G [00:12<00:06, 104MB/s] \u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  77% 2.29G/2.97G [00:13<00:05, 115MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  78% 2.31G/2.97G [00:13<00:05, 125MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  79% 2.34G/2.97G [00:13<00:04, 156MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  80% 2.37G/2.97G [00:13<00:03, 182MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  81% 2.40G/2.97G [00:13<00:03, 177MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  82% 2.42G/2.97G [00:13<00:03, 181MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  83% 2.45G/2.97G [00:13<00:02, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  84% 2.49G/2.97G [00:13<00:02, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  85% 2.52G/2.97G [00:14<00:01, 234MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  86% 2.55G/2.97G [00:14<00:01, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  87% 2.58G/2.97G [00:14<00:01, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  88% 2.61G/2.97G [00:14<00:01, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  89% 2.65G/2.97G [00:14<00:01, 297MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  91% 2.69G/2.97G [00:14<00:00, 315MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  92% 2.74G/2.97G [00:14<00:00, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  94% 2.78G/2.97G [00:14<00:00, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  95% 2.81G/2.97G [00:15<00:00, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  96% 2.84G/2.97G [00:15<00:00, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  97% 2.88G/2.97G [00:15<00:00, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin:  99% 2.93G/2.97G [00:15<00:00, 315MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00010.bin: 100% 2.97G/2.97G [00:15<00:00, 191MB/s]\n",
            "Downloading shards:  60% 6/10 [01:16<00:54, 13.61s/it]\n",
            "Downloading (…)l-00007-of-00010.bin:   0% 0.00/2.88G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   0% 10.5M/2.88G [00:00<00:36, 78.6MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   1% 31.5M/2.88G [00:00<00:21, 131MB/s] \u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   3% 73.4M/2.88G [00:00<00:11, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   4% 105M/2.88G [00:00<00:10, 258MB/s] \u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   5% 136M/2.88G [00:00<00:10, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   6% 178M/2.88G [00:00<00:08, 310MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   8% 220M/2.88G [00:00<00:08, 316MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:   9% 262M/2.88G [00:00<00:08, 307MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  10% 294M/2.88G [00:01<00:08, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  12% 336M/2.88G [00:01<00:08, 311MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  13% 367M/2.88G [00:01<00:08, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  14% 409M/2.88G [00:01<00:08, 295MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  15% 440M/2.88G [00:01<00:08, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  16% 472M/2.88G [00:01<00:09, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  17% 503M/2.88G [00:01<00:09, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  19% 535M/2.88G [00:02<00:09, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  20% 566M/2.88G [00:02<00:09, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  21% 598M/2.88G [00:02<00:08, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  22% 640M/2.88G [00:02<00:08, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  24% 682M/2.88G [00:02<00:07, 295MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  25% 724M/2.88G [00:02<00:07, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  27% 765M/2.88G [00:02<00:06, 321MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  28% 807M/2.88G [00:02<00:06, 334MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  30% 849M/2.88G [00:02<00:06, 331MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  31% 891M/2.88G [00:03<00:05, 336MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  32% 933M/2.88G [00:03<00:05, 347MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  34% 975M/2.88G [00:03<00:06, 306MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  35% 1.02G/2.88G [00:03<00:06, 294MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  36% 1.05G/2.88G [00:03<00:06, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  38% 1.08G/2.88G [00:04<00:10, 165MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  39% 1.11G/2.88G [00:04<00:12, 141MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  40% 1.14G/2.88G [00:04<00:10, 160MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  41% 1.17G/2.88G [00:04<00:09, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  42% 1.21G/2.88G [00:04<00:08, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  43% 1.24G/2.88G [00:04<00:07, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  44% 1.28G/2.88G [00:04<00:06, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  46% 1.31G/2.88G [00:05<00:06, 228MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  47% 1.35G/2.88G [00:05<00:05, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  48% 1.39G/2.88G [00:05<00:05, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  50% 1.44G/2.88G [00:05<00:05, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  51% 1.47G/2.88G [00:05<00:05, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  52% 1.50G/2.88G [00:05<00:05, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  53% 1.53G/2.88G [00:05<00:05, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  54% 1.56G/2.88G [00:06<00:05, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  56% 1.60G/2.88G [00:06<00:04, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  57% 1.65G/2.88G [00:06<00:04, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  58% 1.68G/2.88G [00:06<00:04, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  60% 1.72G/2.88G [00:06<00:03, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  61% 1.76G/2.88G [00:06<00:03, 318MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  63% 1.80G/2.88G [00:06<00:03, 326MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  64% 1.85G/2.88G [00:06<00:03, 317MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  66% 1.89G/2.88G [00:07<00:03, 311MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  67% 1.92G/2.88G [00:07<00:03, 303MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  68% 1.95G/2.88G [00:07<00:03, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  69% 1.98G/2.88G [00:07<00:03, 283MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  70% 2.01G/2.88G [00:07<00:03, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  71% 2.06G/2.88G [00:07<00:02, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  73% 2.10G/2.88G [00:07<00:02, 323MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  74% 2.14G/2.88G [00:07<00:02, 296MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  76% 2.18G/2.88G [00:08<00:02, 308MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  77% 2.22G/2.88G [00:08<00:02, 314MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  79% 2.26G/2.88G [00:08<00:02, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  80% 2.30G/2.88G [00:08<00:02, 243MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  81% 2.33G/2.88G [00:08<00:02, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  82% 2.37G/2.88G [00:08<00:01, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  84% 2.41G/2.88G [00:08<00:01, 313MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  85% 2.45G/2.88G [00:09<00:01, 337MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  87% 2.50G/2.88G [00:09<00:01, 324MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  88% 2.54G/2.88G [00:09<00:01, 339MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  90% 2.58G/2.88G [00:09<00:00, 317MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  91% 2.62G/2.88G [00:09<00:00, 298MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  92% 2.65G/2.88G [00:09<00:00, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  94% 2.69G/2.88G [00:09<00:00, 294MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  95% 2.74G/2.88G [00:09<00:00, 314MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  97% 2.78G/2.88G [00:10<00:00, 339MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin:  98% 2.82G/2.88G [00:10<00:00, 356MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00010.bin: 100% 2.88G/2.88G [00:10<00:00, 274MB/s]\n",
            "Downloading shards:  70% 7/10 [01:27<00:38, 12.69s/it]\n",
            "Downloading (…)l-00008-of-00010.bin:   0% 0.00/2.99G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   1% 31.5M/2.99G [00:00<00:11, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   2% 62.9M/2.99G [00:00<00:13, 216MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   3% 94.4M/2.99G [00:00<00:12, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   4% 126M/2.99G [00:00<00:11, 243MB/s] \u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   5% 157M/2.99G [00:00<00:11, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   7% 199M/2.99G [00:00<00:09, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   8% 231M/2.99G [00:00<00:09, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:   9% 273M/2.99G [00:00<00:08, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  11% 315M/2.99G [00:01<00:08, 314MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  12% 357M/2.99G [00:01<00:07, 331MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  13% 398M/2.99G [00:01<00:07, 334MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  15% 440M/2.99G [00:01<00:07, 338MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  16% 482M/2.99G [00:01<00:08, 295MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  18% 524M/2.99G [00:01<00:08, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  19% 556M/2.99G [00:01<00:08, 287MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  20% 598M/2.99G [00:02<00:07, 307MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  21% 629M/2.99G [00:02<00:07, 306MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  22% 661M/2.99G [00:02<00:07, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  23% 703M/2.99G [00:02<00:07, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  25% 744M/2.99G [00:02<00:06, 340MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  26% 786M/2.99G [00:02<00:06, 330MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  28% 828M/2.99G [00:02<00:06, 338MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  29% 870M/2.99G [00:02<00:06, 320MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  31% 912M/2.99G [00:03<00:06, 311MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  32% 954M/2.99G [00:03<00:06, 323MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  33% 996M/2.99G [00:03<00:05, 343MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  35% 1.04G/2.99G [00:03<00:05, 345MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  36% 1.08G/2.99G [00:03<00:05, 347MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  38% 1.12G/2.99G [00:03<00:07, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  39% 1.15G/2.99G [00:03<00:07, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  40% 1.18G/2.99G [00:04<00:07, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  41% 1.22G/2.99G [00:04<00:07, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  42% 1.25G/2.99G [00:04<00:07, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  43% 1.29G/2.99G [00:04<00:06, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  45% 1.33G/2.99G [00:04<00:06, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  46% 1.36G/2.99G [00:04<00:05, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  47% 1.41G/2.99G [00:04<00:05, 294MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  48% 1.45G/2.99G [00:04<00:04, 311MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  50% 1.49G/2.99G [00:05<00:05, 293MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  51% 1.52G/2.99G [00:05<00:05, 283MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  52% 1.55G/2.99G [00:05<00:05, 281MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  53% 1.58G/2.99G [00:05<00:05, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  54% 1.61G/2.99G [00:05<00:05, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  55% 1.65G/2.99G [00:05<00:06, 220MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  56% 1.68G/2.99G [00:05<00:05, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  58% 1.72G/2.99G [00:06<00:04, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  59% 1.76G/2.99G [00:06<00:04, 307MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  60% 1.80G/2.99G [00:06<00:03, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  62% 1.85G/2.99G [00:06<00:03, 322MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  63% 1.89G/2.99G [00:06<00:03, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  64% 1.92G/2.99G [00:06<00:03, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  65% 1.95G/2.99G [00:06<00:03, 293MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  66% 1.98G/2.99G [00:06<00:03, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  68% 2.02G/2.99G [00:06<00:03, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  69% 2.07G/2.99G [00:07<00:02, 335MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  70% 2.11G/2.99G [00:07<00:02, 297MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  72% 2.14G/2.99G [00:07<00:02, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  73% 2.18G/2.99G [00:07<00:02, 299MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  74% 2.21G/2.99G [00:07<00:02, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  75% 2.24G/2.99G [00:07<00:02, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  76% 2.29G/2.99G [00:07<00:02, 296MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  78% 2.33G/2.99G [00:08<00:02, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  79% 2.37G/2.99G [00:08<00:01, 331MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  81% 2.41G/2.99G [00:08<00:01, 342MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  82% 2.45G/2.99G [00:08<00:01, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  83% 2.50G/2.99G [00:08<00:01, 348MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  85% 2.54G/2.99G [00:08<00:01, 364MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  86% 2.58G/2.99G [00:08<00:01, 328MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  88% 2.62G/2.99G [00:08<00:01, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  89% 2.66G/2.99G [00:09<00:00, 329MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  90% 2.71G/2.99G [00:09<00:00, 351MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  92% 2.75G/2.99G [00:09<00:00, 327MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  93% 2.79G/2.99G [00:09<00:00, 297MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  94% 2.82G/2.99G [00:09<00:00, 295MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  95% 2.85G/2.99G [00:09<00:00, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  96% 2.88G/2.99G [00:09<00:00, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  97% 2.92G/2.99G [00:09<00:00, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin:  99% 2.96G/2.99G [00:10<00:00, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00010.bin: 100% 2.99G/2.99G [00:10<00:00, 292MB/s]\n",
            "Downloading shards:  80% 8/10 [01:38<00:24, 12.05s/it]\n",
            "Downloading (…)l-00009-of-00010.bin:   0% 0.00/2.86G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   1% 31.5M/2.86G [00:00<00:10, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   2% 62.9M/2.86G [00:00<00:19, 146MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   3% 83.9M/2.86G [00:00<00:17, 159MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   4% 126M/2.86G [00:00<00:12, 226MB/s] \u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   6% 157M/2.86G [00:00<00:10, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   7% 199M/2.86G [00:00<00:10, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   8% 231M/2.86G [00:00<00:09, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:   9% 262M/2.86G [00:01<00:09, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  10% 294M/2.86G [00:01<00:08, 289MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  11% 325M/2.86G [00:01<00:09, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  13% 377M/2.86G [00:01<00:07, 330MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  15% 419M/2.86G [00:01<00:07, 317MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  16% 461M/2.86G [00:01<00:07, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  17% 493M/2.86G [00:01<00:07, 306MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  18% 524M/2.86G [00:01<00:07, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  19% 556M/2.86G [00:02<00:08, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  21% 587M/2.86G [00:02<00:09, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  22% 629M/2.86G [00:02<00:08, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  23% 671M/2.86G [00:02<00:07, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  25% 703M/2.86G [00:02<00:08, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  26% 744M/2.86G [00:02<00:07, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  27% 776M/2.86G [00:03<00:10, 199MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  28% 807M/2.86G [00:03<00:09, 214MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  29% 839M/2.86G [00:03<00:08, 234MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  31% 881M/2.86G [00:03<00:07, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  32% 912M/2.86G [00:03<00:07, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  33% 944M/2.86G [00:03<00:07, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  34% 975M/2.86G [00:03<00:07, 268MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  35% 1.01G/2.86G [00:03<00:06, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  36% 1.04G/2.86G [00:03<00:06, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  37% 1.07G/2.86G [00:04<00:06, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  39% 1.10G/2.86G [00:04<00:06, 275MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  40% 1.13G/2.86G [00:04<00:07, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  41% 1.16G/2.86G [00:04<00:07, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  42% 1.21G/2.86G [00:04<00:06, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  43% 1.24G/2.86G [00:04<00:07, 215MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  44% 1.27G/2.86G [00:05<00:07, 201MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  46% 1.31G/2.86G [00:05<00:06, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  47% 1.34G/2.86G [00:05<00:06, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  48% 1.37G/2.86G [00:05<00:06, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  49% 1.41G/2.86G [00:05<00:06, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  51% 1.45G/2.86G [00:05<00:05, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  52% 1.48G/2.86G [00:05<00:05, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  53% 1.51G/2.86G [00:05<00:05, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  54% 1.54G/2.86G [00:06<00:05, 253MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  55% 1.57G/2.86G [00:06<00:05, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  56% 1.60G/2.86G [00:06<00:07, 162MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  57% 1.63G/2.86G [00:06<00:07, 166MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  58% 1.66G/2.86G [00:06<00:06, 183MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  59% 1.69G/2.86G [00:06<00:05, 210MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  60% 1.72G/2.86G [00:07<00:05, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  62% 1.76G/2.86G [00:07<00:04, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  63% 1.80G/2.86G [00:07<00:04, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  64% 1.84G/2.86G [00:07<00:03, 265MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  65% 1.87G/2.86G [00:07<00:03, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  67% 1.91G/2.86G [00:07<00:03, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  68% 1.94G/2.86G [00:07<00:03, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  69% 1.97G/2.86G [00:07<00:03, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  70% 2.00G/2.86G [00:08<00:03, 244MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  72% 2.04G/2.86G [00:08<00:02, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  73% 2.09G/2.86G [00:08<00:02, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  74% 2.12G/2.86G [00:08<00:02, 275MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  75% 2.15G/2.86G [00:08<00:02, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  76% 2.18G/2.86G [00:08<00:02, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  77% 2.21G/2.86G [00:08<00:02, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  79% 2.25G/2.86G [00:08<00:01, 309MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  80% 2.29G/2.86G [00:09<00:01, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  81% 2.32G/2.86G [00:09<00:01, 288MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  82% 2.35G/2.86G [00:09<00:01, 274MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  84% 2.39G/2.86G [00:09<00:01, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  85% 2.42G/2.86G [00:09<00:01, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  86% 2.45G/2.86G [00:09<00:01, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  87% 2.49G/2.86G [00:09<00:01, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  88% 2.52G/2.86G [00:10<00:01, 229MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  89% 2.55G/2.86G [00:10<00:01, 206MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  91% 2.59G/2.86G [00:10<00:01, 242MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  92% 2.62G/2.86G [00:10<00:01, 174MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  93% 2.64G/2.86G [00:10<00:01, 172MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  94% 2.67G/2.86G [00:10<00:00, 193MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  95% 2.71G/2.86G [00:11<00:00, 217MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  96% 2.74G/2.86G [00:11<00:00, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  97% 2.77G/2.86G [00:11<00:00, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  98% 2.80G/2.86G [00:11<00:00, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin:  99% 2.83G/2.86G [00:11<00:00, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00010.bin: 100% 2.86G/2.86G [00:11<00:00, 244MB/s]\n",
            "Downloading shards:  90% 9/10 [01:50<00:12, 12.02s/it]\n",
            "Downloading (…)l-00010-of-00010.bin:   0% 0.00/705M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:   1% 10.5M/705M [00:00<00:11, 62.4MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:   3% 21.0M/705M [00:00<00:08, 80.9MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:   7% 52.4M/705M [00:00<00:04, 154MB/s] \u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  12% 83.9M/705M [00:00<00:03, 186MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  16% 115M/705M [00:00<00:02, 204MB/s] \u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  19% 136M/705M [00:00<00:02, 204MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  24% 168M/705M [00:00<00:02, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  28% 199M/705M [00:01<00:02, 212MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  33% 231M/705M [00:01<00:02, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  39% 273M/705M [00:01<00:01, 276MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  43% 304M/705M [00:01<00:01, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  49% 346M/705M [00:01<00:01, 302MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  55% 388M/705M [00:01<00:01, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  60% 419M/705M [00:01<00:00, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  65% 461M/705M [00:01<00:00, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  71% 503M/705M [00:01<00:00, 312MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  77% 545M/705M [00:02<00:00, 291MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  82% 577M/705M [00:02<00:00, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  86% 608M/705M [00:02<00:00, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  91% 640M/705M [00:02<00:00, 243MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin:  95% 671M/705M [00:02<00:00, 209MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00010.bin: 100% 705M/705M [00:02<00:00, 239MB/s]\n",
            "Downloading shards: 100% 10/10 [01:53<00:00, 11.34s/it]\n",
            "Loading checkpoint shards: 100% 10/10 [02:14<00:00, 13.45s/it]\n",
            "Downloading (…)neration_config.json: 100% 174/174 [00:00<00:00, 903kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "> \u001b[1mINFO    Using block size 1024\u001b[0m\n",
            "Running tokenizer on train dataset: 100% 480/480 [00:00<00:00, 4321.64 examples/s]\n",
            "Grouping texts in chunks of 1024 (num_proc=4): 100% 480/480 [00:00<00:00, 2300.36 examples/s]\n",
            "> \u001b[1mINFO    creating trainer\u001b[0m\n",
            "  0% 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 2.5282, 'learning_rate': 3e-05, 'epoch': 0.14}\n",
            "{'loss': 1.2342, 'learning_rate': 2.5e-05, 'epoch': 0.29}\n",
            "{'loss': 1.4712, 'learning_rate': 1.9999999999999998e-05, 'epoch': 0.43}\n",
            "{'loss': 1.2892, 'learning_rate': 1.5e-05, 'epoch': 0.57}\n",
            "{'loss': 1.1892, 'learning_rate': 9.999999999999999e-06, 'epoch': 0.71}\n",
            "{'loss': 1.1071, 'learning_rate': 4.9999999999999996e-06, 'epoch': 0.86}\n",
            "{'loss': 1.2284, 'learning_rate': 0.0, 'epoch': 1.0}\n",
            "{'train_runtime': 48.6159, 'train_samples_per_second': 0.267, 'train_steps_per_second': 0.144, 'train_loss': 1.435372335570199, 'epoch': 1.0}\n",
            "100% 7/7 [00:48<00:00,  6.94s/it]\n",
            "> \u001b[1mINFO    Finished training, saving model...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the fine-tune training folder\n",
        "!zip -r /content/llama2-MJ-prompts.zip /content/llama2-MJ-prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMuvkvjkjcd0",
        "outputId": "2209b61a-b329-4616-e52d-7f73d6ecf3ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/llama2-MJ-prompts/ (stored 0%)\n",
            "  adding: content/llama2-MJ-prompts/added_tokens.json (stored 0%)\n",
            "  adding: content/llama2-MJ-prompts/adapter_model.bin (deflated 9%)\n",
            "  adding: content/llama2-MJ-prompts/tokenizer.model (deflated 55%)\n",
            "  adding: content/llama2-MJ-prompts/special_tokens_map.json (deflated 71%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/ (stored 0%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/added_tokens.json (stored 0%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/adapter_model.bin (deflated 9%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/tokenizer.model (deflated 55%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/trainer_state.json (deflated 69%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/special_tokens_map.json (deflated 71%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/rng_state.pth (deflated 25%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/pytorch_model.bin (deflated 65%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/README.md (deflated 67%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/training_args.bin (deflated 50%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/tokenizer.json (deflated 74%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/adapter_config.json (deflated 45%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/optimizer.pt (deflated 7%)\n",
            "  adding: content/llama2-MJ-prompts/checkpoint-7/scheduler.pt (deflated 57%)\n",
            "  adding: content/llama2-MJ-prompts/training_params.json (deflated 56%)\n",
            "  adding: content/llama2-MJ-prompts/README.md (deflated 18%)\n",
            "  adding: content/llama2-MJ-prompts/runs/ (stored 0%)\n",
            "  adding: content/llama2-MJ-prompts/runs/Oct21_09-22-30_f5ea7e9d9d97/ (stored 0%)\n",
            "  adding: content/llama2-MJ-prompts/runs/Oct21_09-22-30_f5ea7e9d9d97/events.out.tfevents.1697880151.f5ea7e9d9d97.2610.0 (deflated 59%)\n",
            "  adding: content/llama2-MJ-prompts/training_args.bin (deflated 50%)\n",
            "  adding: content/llama2-MJ-prompts/tokenizer.json (deflated 74%)\n",
            "  adding: content/llama2-MJ-prompts/tokenizer_config.json (deflated 73%)\n",
            "  adding: content/llama2-MJ-prompts/adapter_config.json (deflated 45%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Issue with the train.csv file\n",
        "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x89 in position 18905: invalid start byte\n"
      ],
      "metadata": {
        "id": "_K5-IyiL6zp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "rtrNvb3s4LJr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv',  encoding='unicode_escape')"
      ],
      "metadata": {
        "id": "4Z31PSIR33kD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('train.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "1oORVry-6hqY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "KAUEgEdh6t9Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "x9zM2ZO6C6I8",
        "outputId": "1f49ebca-929d-4349-f7dd-dbdf6d752a8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'###Human:\\n\\ngenerate a midjourney prompt for A person walking in the rain\\n\\n####Assistant:\\nA young adult wearing a navy-blue raincoat and matching rain boots walks on a wet cobblestone street. Raindrops create ripples in the puddles. They hold a red umbrella that shields them from the pouring rain. Their face is relaxed, enjoying the rainfall.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB:  LINKS:\n",
        "\n",
        "- autotrain: https://huggingface.co/autotrain\n",
        "- autotrain GitHub: https://github.com/huggingface/autotr..."
      ],
      "metadata": {
        "id": "f3hOb4Ed0j_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n"
      ],
      "metadata": {
        "id": "GDxpwEbCGxb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from torch.nn import DataParallel #for multiple gpus"
      ],
      "metadata": {
        "id": "tKLS0rCy0mfc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accessing the newly fine-tuned model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/llama2-MJ-prompts\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/content/llama2-MJ-prompts\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "38ffc54133f24550b855ce22dab2f2c9",
            "7e5d3328cfbd42619e52ab7a757d33fc",
            "5c1fe490c41043a689a0f224d6d0163b",
            "44d460beada142c6a07ab07f9859f993",
            "6bf0acb374f2473dac349f95cbf16a3f",
            "f0a8b99eb7b1480caf16457395c02082",
            "264c05d47d094d0f9a49309de1bc55bd",
            "8b52a39963db42fcb9d53160c81be996",
            "20c53a54020c4afe920e2f0b4d324fc3",
            "4df92777cdd54f03be8bb4474665bb0f",
            "bd8317ef67db421d87729af94e1cc8f1"
          ]
        },
        "id": "JaKhxLXwHnY5",
        "outputId": "ddd849a1-944e-46a8-8758-81806522b4c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38ffc54133f24550b855ce22dab2f2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_context = '''\n",
        "\"###Human:\n",
        "generate a midjourney prompt for a child running in a rain, give a detailed description\n",
        "\n",
        "####Assistant:\n",
        "'''"
      ],
      "metadata": {
        "id": "r8Ech9m_K06T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: the `###Assitant:` is empty because the newly fine-tuned model  will be able to generate the prompt."
      ],
      "metadata": {
        "id": "dxDdBWJUeRJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(input_context, return_tensors='pt')"
      ],
      "metadata": {
        "id": "Db_bkLd_JlLi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids = tokenizer(input_context, return_tensors='pt').input_ids.cuda()"
      ],
      "metadata": {
        "id": "6YnC1tEo1t_P"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output = model.generate(input_ids, max_length=85, temperature=0.3, num_return_sequences=1)"
      ],
      "metadata": {
        "id": "N0eaJ_VBMO54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(input_ids, max_length=100, temperature=0.3, num_return_sequences=1, repetition_penalty=1.1, eos_token_id=tokenizer.eos_token_id )"
      ],
      "metadata": {
        "id": "HRjuX4DPpzqY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text = tokenizer.decode(output[0], skip_special_token=True)"
      ],
      "metadata": {
        "id": "EgFNvzL8KlpR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbh4WefvK34Y",
        "outputId": "88f06e31-97e8-45a6-99ac-47c7e348a018"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> \n",
            "\"###Human:\n",
            "generate a midjourney prompt for a child running in a rain, give a detailed description\n",
            "\n",
            "####Assistant:\n",
            "The child is running in the rain, with a smile on their face. They are wearing a yellow raincoat and blue rain boots. They are holding an umbrella in one hand and a toy in the other. They are laughing and splashing in the puddles.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output = model.generate(inputs=input_ids, do_sample=True, temperature=0.7, max_new_tokens=512)\n",
        "# print(tokenizer.decode(output[0]))"
      ],
      "metadata": {
        "id": "EZGxGAwz15MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#output = model.generate(input_ids, max_length=100, temperature=0.3, num_return_sequences=1, do_sample=False)"
      ],
      "metadata": {
        "id": "taCASy55KAVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(input_context, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, num_beams=4, do_sample=True, max_new_tokens=1024, eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKQg_yF2MFal",
        "outputId": "b871ed81-2fad-4b1a-9f3d-8da71afe3511"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\"###Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant:\n",
            "The castle is on the edge of a cliff, overlooking the sea. It is made of stone and has many towers and turrets.\n",
            "\n",
            "####Human:\n",
            "generate a midjourney prompt for a castle on an edge\n",
            "\n",
            "####Assistant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB:\n",
        "- `**inputs`: Unpacks the tokenized input data.\n",
        "- `num_beams=4`: Beam search with 4 beams. Provides a trade-off between quality and speed.\n",
        "- `do_sample=True`: Sampling is enabled, making the output text more random. It switches the generation mode from deterministic to probabilistic (or stochastic).\n",
        "- `max_new_tokens=1024`: The maximum number of tokens for the generated text."
      ],
      "metadata": {
        "id": "KjG2o-0MtwJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Beam search** is a search algorithm used for finding the most likely sequence of tokens when generating text from a language model. It is  commonly employed in natural language processing tasks like machine translation, text summarization, and text generation."
      ],
      "metadata": {
        "id": "i-BJo1AsuV_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Interface"
      ],
      "metadata": {
        "id": "eDUx8I92Z96a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to fix the absence of utf-8 locale on Colab\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "FmN0XmLBaMWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "FBbuxh89aAFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def predict(prompt):\n",
        "\n",
        "  sequences = pipeline(\n",
        "    prompt,\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    top_p=0.9,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_length=100,\n",
        "  )\n",
        "\n",
        "  response = ''\n",
        "  for seq in sequences:\n",
        "    response += seq['generated_text']\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "SVznXTIFaf5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: The inference code is the same as before, but here we are including our pipeline, configured as usual, inside a function so that it can be called at will to pass us the user’s request via the prompt parameter."
      ],
      "metadata": {
        "id": "wKdMSdF3a3Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "  fn=predict,\n",
        "  inputs=gr.Textbox(label=\"Please, write your request here:\", placeholder=\"example: def fibonacci(\", lines=5),\n",
        "  outputs=gr.Textbox(label=\"Answer (inference):\"),\n",
        "  title='On Premesis Code LLama2 Helper',\n",
        "  description='description',\n",
        "  article='My article on Medium https://medium.com',\n",
        "  examples=[[\"def Fibonacci(\"], [\"function DotProduct(\"], ['springboot profile'], ['write a class for manage shipment']],\n",
        "  allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "rfjTMtp9bCPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: There are three main configurations, and they concern:\n",
        "- fn the interfacing with the underlying model which is done via our function;\n",
        "- input where we customize the text area where we insert the prompt by specifying its title, internal hint and length;\n",
        "- output for the text area of the ai responses, we simply configure the title;"
      ],
      "metadata": {
        "id": "UrFRtiEDbR5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The other configurations allow us to specify a title, an html description, and the list of ready-made examples.\n",
        "\n",
        "Finally, and we have thus come to the end of this presentation, the last command launches the application by returning to the console the address to connect to with the browser to test the application."
      ],
      "metadata": {
        "id": "ruy0o7m7bevF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation\n",
        "**`model.generate`** method is often used with transformers-based models like those provided by the Hugging Face Transformers library. Below are some commonly used arguments for `model.generate`:\n",
        "\n",
        "- **`input_ids`**: Tensor containing the token IDs to be fed into the model.\n",
        "\n",
        "- **`max_length`**: Maximum sequence length for the generated text. The generation will stop once this length is reached.\n",
        "\n",
        "- **`min_length`**: Minimum sequence length for the generated text. The model will continue generating until this length is reached.\n",
        "\n",
        "- **`do_sample`**: Whether to sample the next token randomly based on the distribution of the logits (True) or to take the token with the highest logit (False).\n",
        "\n",
        "- **`temperature`**: Controls the randomness of the token sampling when `do_sample=True`. Higher values make the output more random, while lower values make it more deterministic.\n",
        "\n",
        "- **`top_k`**: Limits the number of highest-probability tokens considered for sampling. Only relevant when `do_sample=True`.\n",
        "\n",
        "- **`top_p`**: Also known as \"nucleus sampling,\" this parameter sets a cumulative probability threshold. Tokens with a cumulative probability above this value are excluded from sampling. Only relevant when `do_sample=True`.\n",
        "\n",
        "- **`num_return_sequences`**: Number of different sequences to generate. Useful for getting multiple outputs for a single input.\n",
        "\n",
        "- **`pad_token_id`**: Token ID used for padding when the generated sequence is shorter than max_length.\n",
        "\n",
        "- **`eos_token_id`**: Token ID signaling the end of a sequence. When this token is generated, the sequence will stop.\n",
        "\n",
        "- **`length_penalty`**: Exponential penalty to apply to the sequence length. Values > 1.0 encourage longer sequences, while values < 1.0 encourage shorter sequences.\n",
        "\n",
        "- **`early_stopping`**: Whether to stop generation as soon as the end-of-sequence token is generated.\n",
        "\n",
        "- **`num_beams`**: Number of beams for beam search. Beam search is a technique that explores multiple possibilities in parallel, aiming to find the most probable sequence. Setting this to a value greater than 1 enables beam search.\n",
        "\n",
        "- **`no_repeat_ngram_size`**: Size of the n-gram window used to prevent repetition of n-grams in the generated text.\n",
        "\n",
        "- **`bad_words_ids`**: List of token IDs that should not appear in the generated text.\n",
        "\n",
        "- **`attention_mask`**: Mask to apply to the attention mechanism, typically to ignore padding tokens.\n",
        "\n",
        "- **`decoder_start_token_id`**:\n",
        "Token ID that should be used as the starting token for decoding in sequence-to-sequence models.\n",
        "\n",
        "Ref.: https://huggingface.co/docs/transformers/main_classes/text_generation"
      ],
      "metadata": {
        "id": "wZNvfAB9MTc0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ressources\n",
        "\n",
        "https://github.com/Zjh-819/LLMDataHub\n",
        "\n",
        "https://www.deepset.ai/blog/llm-finetuning\n",
        "\n",
        "https://colab.research.google.com/github/Tims793/Autotrain_llm/blob/main/Copy_of_AutoTrain_LLM.ipynb#scrollTo=AKQg_yF2MFal\n",
        "\n",
        "https://huggingface.co/docs/transformers/v4.34.1/en/generation_strategies#default-text-generation-configuration\n",
        "\n",
        "https://platform.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model\n",
        "\n",
        "https://huggingface.co/learn/nlp-course/chapter9/1?fw=pt\n"
      ],
      "metadata": {
        "id": "qrTyQh4UgWPj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sfv0XzIPgnNe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}