{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMAnLnNRkhpLGPvj+KNBzlE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7eb37aaa644741098eaa5e897145e07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76210bc343694fd5866242d6deb476fa",
              "IPY_MODEL_b359d33cb1b14af3bbac896f11657a48",
              "IPY_MODEL_17fefd84f3584a4981a20196bd65e378",
              "IPY_MODEL_9207584d534c4108b0a3aec8e73a8b9a"
            ],
            "layout": "IPY_MODEL_7343ce6bc3474aad9ccd92417eb8f69d"
          }
        },
        "91d5f362b9834177b6ab7a5c39b7f03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ede45f9557d4996bdae6d76f5b01d1c",
            "placeholder": "​",
            "style": "IPY_MODEL_b97506ed47db4839b979ef582490618c",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6beb3a79e5854bcab6abd8e1c847a301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c933855ee7c1423e84b19a8116f3eb90",
            "placeholder": "​",
            "style": "IPY_MODEL_0086ad0efa784933a825c0804c1bfd55",
            "value": ""
          }
        },
        "7de8dd20248f484ea2c986aeac022a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e49b41a061ef4ad999f3862b6601f498",
            "style": "IPY_MODEL_a2eb410fb7244516a46f314f3dc275e7",
            "value": true
          }
        },
        "2ec59feeffeb43a28e540be00b515bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_345231f5756c4e38a67f562116046562",
            "style": "IPY_MODEL_1c1c053c991c494ea3dd760f53f00a37",
            "tooltip": ""
          }
        },
        "ce0259b77084455bba18bf0151e754f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2051bda83bf54aacbbf756bf88573e67",
            "placeholder": "​",
            "style": "IPY_MODEL_e152c7f010284a35bab292600cb579be",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7343ce6bc3474aad9ccd92417eb8f69d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "7ede45f9557d4996bdae6d76f5b01d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97506ed47db4839b979ef582490618c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c933855ee7c1423e84b19a8116f3eb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0086ad0efa784933a825c0804c1bfd55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e49b41a061ef4ad999f3862b6601f498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2eb410fb7244516a46f314f3dc275e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "345231f5756c4e38a67f562116046562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1c053c991c494ea3dd760f53f00a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2051bda83bf54aacbbf756bf88573e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e152c7f010284a35bab292600cb579be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aa7237572f7419b8a13a34ed8a6f502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c8db696514d494fbc1e4a68df8938ec",
            "placeholder": "​",
            "style": "IPY_MODEL_487d08ee71ec453c96e82ea33e681060",
            "value": "Connecting..."
          }
        },
        "1c8db696514d494fbc1e4a68df8938ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487d08ee71ec453c96e82ea33e681060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76210bc343694fd5866242d6deb476fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a92bee9864e472a8b644f799187d5fa",
            "placeholder": "​",
            "style": "IPY_MODEL_e345cbbb95d64277b5a03cea549b9a3c",
            "value": "Token is valid (permission: write)."
          }
        },
        "b359d33cb1b14af3bbac896f11657a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_269ad20d0cee476dbf145a998a2d4ce6",
            "placeholder": "​",
            "style": "IPY_MODEL_6e30e4e19aa047b5a05eadb111bc01e8",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "17fefd84f3584a4981a20196bd65e378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_988f64dcb2ab483fa763f62e376a4924",
            "placeholder": "​",
            "style": "IPY_MODEL_f87d4d0c43904a29ab526b989cadb255",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "9207584d534c4108b0a3aec8e73a8b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768ea5bb771c4be9aab9e81284f2b0be",
            "placeholder": "​",
            "style": "IPY_MODEL_bf391842bbc24243b69d4b0ea5db1453",
            "value": "Login successful"
          }
        },
        "7a92bee9864e472a8b644f799187d5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e345cbbb95d64277b5a03cea549b9a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "269ad20d0cee476dbf145a998a2d4ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e30e4e19aa047b5a05eadb111bc01e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "988f64dcb2ab483fa763f62e376a4924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87d4d0c43904a29ab526b989cadb255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "768ea5bb771c4be9aab9e81284f2b0be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf391842bbc24243b69d4b0ea5db1453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/HuggingFace/blob/main/amr_fine_tuning_with_axolotl_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is based on the following blog post by Mlabonne https://mlabonne.github.io/blog/posts/A_Beginners_Guide_to_LLM_Finetuning.html\n"
      ],
      "metadata": {
        "id": "JiLlL3y1EPKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the Github repository axolotl\n",
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl\n",
        "%cd axolotl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDTv1N26HX6A",
        "outputId": "83238ac9-4a5f-4459-bd3e-5f553bc56b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'axolotl'...\n",
            "remote: Enumerating objects: 6975, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 6975 (delta 32), reused 63 (delta 29), pack-reused 6900\u001b[K\n",
            "Receiving objects: 100% (6975/6975), 2.14 MiB | 28.83 MiB/s, done.\n",
            "Resolving deltas: 100% (4452/4452), done.\n",
            "/content/axolotl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "YIFiktAUHdq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q -U transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "# !pip install -q datasets bitsandbytes einops wandb"
      ],
      "metadata": {
        "id": "abkG0rSKHqR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install packaging\n",
        "#pip install -e '.[flash-attn,deepspeed]'\n",
        "!pip install -e .'[flash-attn]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "trWZMAkTRdoP",
        "outputId": "44312df0-8676-4d2c-869c-e1a942903650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n",
            "Obtaining file:///content/axolotl\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting peft@ git+https://github.com/huggingface/peft.git (from axolotl==0.3.0)\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-install-qparl251/peft_f1baf948af3d4f7691d9400f6d96a494\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-install-qparl251/peft_f1baf948af3d4f7691d9400f6d96a494\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 0c16918c347bf32ad9532823068441f5fb76197a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@bd6205919aad4d3a2300a39a98a642f1cc3a5348 (from axolotl==0.3.0)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision bd6205919aad4d3a2300a39a98a642f1cc3a5348) to /tmp/pip-install-qparl251/transformers_940f19cc2f5b47d2ab5fa84f5f924112\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-qparl251/transformers_940f19cc2f5b47d2ab5fa84f5f924112\n",
            "  Running command git rev-parse -q --verify 'sha^bd6205919aad4d3a2300a39a98a642f1cc3a5348'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git bd6205919aad4d3a2300a39a98a642f1cc3a5348\n",
            "  Running command git checkout -q bd6205919aad4d3a2300a39a98a642f1cc3a5348\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit bd6205919aad4d3a2300a39a98a642f1cc3a5348\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate@ git+https://github.com/huggingface/accelerate@80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9 (from axolotl==0.3.0)\n",
            "  Cloning https://github.com/huggingface/accelerate (to revision 80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9) to /tmp/pip-install-qparl251/accelerate_1fdd4e3a77d14238989bf3fc3b30a7ea\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-install-qparl251/accelerate_1fdd4e3a77d14238989bf3fc3b30a7ea\n",
            "  Running command git rev-parse -q --verify 'sha^80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9'\n",
            "  Running command git fetch -q https://github.com/huggingface/accelerate 80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9\n",
            "  Running command git checkout -q 80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9\n",
            "  Resolved https://github.com/huggingface/accelerate to commit 80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (2.0.1+cu118)\n",
            "Collecting auto-gptq (from axolotl==0.3.0)\n",
            "  Downloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (23.2)\n",
            "Collecting bitsandbytes>=0.41.1 (from axolotl==0.3.0)\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from axolotl==0.3.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting fire (from axolotl==0.3.0)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (6.0.1)\n",
            "Collecting datasets (from axolotl==0.3.0)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from axolotl==0.3.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from axolotl==0.3.0)\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from axolotl==0.3.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers (from axolotl==0.3.0)\n",
            "  Downloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl (211.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum (from axolotl==0.3.0)\n",
            "  Downloading optimum-1.13.2.tar.gz (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hf_transfer (from axolotl==0.3.0)\n",
            "  Downloading hf_transfer-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from axolotl==0.3.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (0.56.4)\n",
            "Collecting numpy>=1.24.4 (from axolotl==0.3.0)\n",
            "  Downloading numpy-1.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bert-score==0.3.13 (from axolotl==0.3.0)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.4.0 (from axolotl==0.3.0)\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score==0.1.2 (from axolotl==0.3.0)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (1.2.2)\n",
            "Collecting pynvml (from axolotl==0.3.0)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting art (from axolotl==0.3.0)\n",
            "  Downloading art-6.1-py3-none-any.whl (599 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.8/599.8 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fschat==0.2.29 (from axolotl==0.3.0)\n",
            "  Downloading fschat-0.2.29-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flash-attn>=2.2.1 (from axolotl==0.3.0)\n",
            "  Downloading flash_attn-2.3.2.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (3.7.1)\n",
            "Collecting dill (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.3.0) (2023.6.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.29->axolotl==0.3.0) (3.8.5)\n",
            "Collecting fastapi (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown2[all] (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading markdown2-2.4.10-py2.py3-none-any.whl (39 kB)\n",
            "Collecting nh3 (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.29->axolotl==0.3.0) (3.0.39)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.29->axolotl==0.3.0) (1.10.13)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.29->axolotl==0.3.0) (13.6.0)\n",
            "Collecting shortuuid (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting tiktoken (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.3.0) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.3.0) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl==0.3.0) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->axolotl==0.3.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->axolotl==0.3.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->axolotl==0.3.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->axolotl==0.3.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->axolotl==0.3.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->axolotl==0.3.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->axolotl==0.3.0) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->axolotl==0.3.0) (17.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->axolotl==0.3.0) (9.0.0)\n",
            "Collecting ninja (from flash-attn>=2.2.1->axolotl==0.3.0)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git@bd6205919aad4d3a2300a39a98a642f1cc3a5348->axolotl==0.3.0) (2023.6.3)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers@ git+https://github.com/huggingface/transformers.git@bd6205919aad4d3a2300a39a98a642f1cc3a5348->axolotl==0.3.0)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers@ git+https://github.com/huggingface/transformers.git@bd6205919aad4d3a2300a39a98a642f1cc3a5348->axolotl==0.3.0)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate@ git+https://github.com/huggingface/accelerate@80da9cfb09bb3cc9f1b385cb55d6b90d025a5fd9->axolotl==0.3.0) (5.9.5)\n",
            "Collecting rouge (from auto-gptq->axolotl==0.3.0)\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl==0.3.0) (2.3.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl==0.3.0) (0.39.1)\n",
            "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numba (from axolotl==0.3.0)\n",
            "  Downloading numba-0.58.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.42,>=0.41.0dev0 (from numba->axolotl==0.3.0)\n",
            "  Downloading llvmlite-0.41.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.24.4 (from axolotl==0.3.0)\n",
            "  Downloading numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from optimum->axolotl==0.3.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.3.0) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.3.0)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.3.0)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.3.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb->axolotl==0.3.0)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb->axolotl==0.3.0)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.3.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.3.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.3.0) (3.20.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.3.0)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.3.0) (2023.3.post1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat==0.2.29->axolotl==0.3.0) (0.2.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.3.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.3.0) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.3.0) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.29->axolotl==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.29->axolotl==0.3.0) (2.16.1)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum->axolotl==0.3.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->fschat==0.2.29->axolotl==0.3.0) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat==0.2.29->axolotl==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->axolotl==0.3.0) (2.1.3)\n",
            "Collecting wavedrom (from markdown2[all]->fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (3.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->axolotl==0.3.0) (1.3.0)\n",
            "Collecting h11>=0.8 (from uvicorn->fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->fschat==0.2.29->axolotl==0.3.0) (1.1.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.3.0)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.29->axolotl==0.3.0) (0.1.2)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.29->axolotl==0.3.0)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score, flash-attn, transformers, accelerate, fire, optimum, peft, pathtools, wavedrom\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=430cee52102470486fd62353b3249843f2281c82ecb6320fab3b88513476288e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.2-cp310-cp310-linux_x86_64.whl size=57037626 sha256=bdd150bed5326c8b042aef739d87a7dfbb45fa9395f4ad43756ea782524dd8d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/2a/7d/13ada26139195be2a5eb874c79d79d0d5afcc791bb08ca2052\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.35.0.dev0-py3-none-any.whl size=7748537 sha256=debbcaf9540c84ed10858f52e35ec4d70ac1a9d6c6415210c170ba520b413b18\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/fc/b4/f93daa357ccf26673c527f65eaf5a9f0b4d77dfc3d23b49c83\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.24.0.dev0-py3-none-any.whl size=258139 sha256=2b8fef628569b9bce8e26ba2cfe99c1e9e86685ea6499d3cead861f0deb8ba4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/75/6c/84e669fa4e2c2f2ced29ff8a976efb9229b63f5ce4b25b5c1b\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=5fbb5adad09a640132ab06f4e8b094b1b8d7527f1bd871a9f9f7eacdfdc6989c\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=46d36a7f48de68251b8a18e795e725d1a4599142f668e7bb9d3c35a1372ebe32\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=123877 sha256=e8f1036db588d9a74a3415b9df86680330d8f1dacc0fc6828dc024e897e3b8fa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vjnw12hg/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=0afef7c5b74d33029331d9d85e2493448295c9a262229f7a036b7bf4efca14db\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=c752919f6adc70ca2644dfa5d82ab1ee125d62ca25c74f7bf48d7e19014d3497\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built rouge-score flash-attn transformers accelerate fire optimum peft pathtools wavedrom\n",
            "Installing collected packages: sentencepiece, pathtools, ninja, nh3, bitsandbytes, addict, xxhash, svgwrite, smmap, shortuuid, setproctitle, sentry-sdk, safetensors, rouge, pynvml, numpy, markdown2, llvmlite, humanfriendly, hf_transfer, h11, fire, einops, docker-pycreds, dill, colorama, art, wavedrom, uvicorn, tiktoken, starlette, rouge-score, responses, numba, multiprocess, huggingface-hub, httpcore, gitdb, coloredlogs, tokenizers, httpx, GitPython, fastapi, wandb, transformers, fschat, datasets, evaluate, accelerate, peft, xformers, optimum, bert-score, auto-gptq, flash-attn, axolotl\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Running setup.py develop for axolotl\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.37 accelerate-0.24.0.dev0 addict-2.4.0 art-6.1 auto-gptq-0.4.2 axolotl-0.3.0 bert-score-0.3.13 bitsandbytes-0.41.1 colorama-0.4.6 coloredlogs-15.0.1 datasets-2.14.5 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 evaluate-0.4.0 fastapi-0.103.2 fire-0.5.0 flash-attn-2.3.2 fschat-0.2.29 gitdb-4.0.10 h11-0.14.0 hf_transfer-0.1.3 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 humanfriendly-10.0 llvmlite-0.41.0 markdown2-2.4.10 multiprocess-0.70.15 nh3-0.2.14 ninja-1.11.1.1 numba-0.58.0 numpy-1.25.2 optimum-1.13.2 pathtools-0.1.2 peft-0.6.0.dev0 pynvml-11.5.0 responses-0.18.0 rouge-1.0.1 rouge-score-0.1.2 safetensors-0.4.0 sentencepiece-0.1.99 sentry-sdk-1.31.0 setproctitle-1.3.3 shortuuid-1.0.11 smmap-5.0.1 starlette-0.27.0 svgwrite-1.4.3 tiktoken-0.5.1 tokenizers-0.14.1 transformers-4.35.0.dev0 uvicorn-0.23.2 wandb-0.15.12 wavedrom-2.0.3.post3 xformers-0.0.22 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w9GE9B1hVzd",
        "outputId": "8a4e1c35-0e25-4b74-8491-94d12dcc8c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.25.2\n",
            "Uninstalling numpy-1.25.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.10\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy-1.25.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-5007b62f.3.23.dev.so\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.10/dist-packages/numpy/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled numpy-1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "b-oAv6dehhYJ",
        "outputId": "9060d1e2-e8a7-494e-f7e9-3f3414af35dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "axolotl 0.3.0 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging to the HF hub to get access to the authentication token\n",
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "HX5Vx7YpHloz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "7eb37aaa644741098eaa5e897145e07c",
            "91d5f362b9834177b6ab7a5c39b7f03a",
            "6beb3a79e5854bcab6abd8e1c847a301",
            "7de8dd20248f484ea2c986aeac022a42",
            "2ec59feeffeb43a28e540be00b515bf7",
            "ce0259b77084455bba18bf0151e754f8",
            "7343ce6bc3474aad9ccd92417eb8f69d",
            "7ede45f9557d4996bdae6d76f5b01d1c",
            "b97506ed47db4839b979ef582490618c",
            "c933855ee7c1423e84b19a8116f3eb90",
            "0086ad0efa784933a825c0804c1bfd55",
            "e49b41a061ef4ad999f3862b6601f498",
            "a2eb410fb7244516a46f314f3dc275e7",
            "345231f5756c4e38a67f562116046562",
            "1c1c053c991c494ea3dd760f53f00a37",
            "2051bda83bf54aacbbf756bf88573e67",
            "e152c7f010284a35bab292600cb579be",
            "0aa7237572f7419b8a13a34ed8a6f502",
            "1c8db696514d494fbc1e4a68df8938ec",
            "487d08ee71ec453c96e82ea33e681060",
            "76210bc343694fd5866242d6deb476fa",
            "b359d33cb1b14af3bbac896f11657a48",
            "17fefd84f3584a4981a20196bd65e378",
            "9207584d534c4108b0a3aec8e73a8b9a",
            "7a92bee9864e472a8b644f799187d5fa",
            "e345cbbb95d64277b5a03cea549b9a3c",
            "269ad20d0cee476dbf145a998a2d4ce6",
            "6e30e4e19aa047b5a05eadb111bc01e8",
            "988f64dcb2ab483fa763f62e376a4924",
            "f87d4d0c43904a29ab526b989cadb255",
            "768ea5bb771c4be9aab9e81284f2b0be",
            "bf391842bbc24243b69d4b0ea5db1453"
          ]
        },
        "outputId": "ccfe3149-8929-43bc-a004-1d67a9f35901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7eb37aaa644741098eaa5e897145e07c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning Llama model with Axolotl\n",
        "The growing interest in Large Language Models (LLMs) has led to a surge in tools and wrappers designed to streamline their training process.\n",
        "\n",
        "Popular options include FastChat from LMSYS (used to train Vicuna) and Hugging Face’s transformers/**trl** libraries (used in my last fine-tuning session).\n",
        "\n",
        "For this fine-tuning step we are going to use a tool called **Axolotl**, which has been created by the **OpenAccess AI Collective**. We will use it to fine-tune a Code Llama 7b model on an evol-instruct dataset comprised of 1,000 samples of Python code.\n",
        "\n",
        "## Why Axolotl\n",
        "\n",
        "The main appeal of **Axolotl** is that it provides a one-stop solution, which includes numerous features, model architectures, and an active community. Here’s a quick list of my favorite things about it:\n",
        "\n",
        "**Configuration**: All parameters used to train an LLM are neatly stored in a yaml config file. This makes it convenient for sharing and reproducing models. You can see an example for Llama 2 here.\n",
        "\n",
        "**Dataset Flexibility**: Axolotl allows the specification of multiple datasets with varied prompt formats such as alpaca ({\"instruction\": \"...\", \"input\": \"...\", \"output\": \"...\"}), sharegpt:chat ({\"conversations\": [{\"from\": \"...\", \"value\": \"...\"}]}), and raw completion ({\"text\": \"...\"}). Combining datasets is seamless, and the hassle of unifying the prompt format is eliminated.\n",
        "\n",
        "**Features**: Axolotl is packed with SOTA techniques such as FSDP, deepspeed, LoRA, QLoRA, ReLoRA, sample packing, GPTQ, FlashAttention, xformers, and rope scaling.\n",
        "\n",
        "**Utilities**: There are numerous user-friendly utilities integrated, including the addition or alteration of special tokens, or a custom wandb configuration."
      ],
      "metadata": {
        "id": "w0nSrQw2En1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIwKZ6v5CeZQ",
        "outputId": "12b35f3c-a6f5-4f3b-f16d-4905fd25fd91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-10-10 12:27:05--  https://gist.githubusercontent.com/mlabonne/8055f6335e2b85f082c8c75561321a66/raw/e02351e171db5fc2fe3d55121cf2ef13d3717e1e/EvolCodeLlama-7b.yaml\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1250 (1.2K) [text/plain]\n",
            "Saving to: ‘EvolCodeLlama-7b.yaml’\n",
            "\n",
            "EvolCodeLlama-7b.ya 100%[===================>]   1.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-10 12:27:05 (108 MB/s) - ‘EvolCodeLlama-7b.yaml’ saved [1250/1250]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# getting the configuration file\n",
        "%cd /content\n",
        "!wget https://gist.githubusercontent.com/mlabonne/8055f6335e2b85f082c8c75561321a66/raw/e02351e171db5fc2fe3d55121cf2ef13d3717e1e/EvolCodeLlama-7b.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: modify the yaml file to make sure that this value is updated: `tf32: true`."
      ],
      "metadata": {
        "id": "IHwQ0ZfKiGK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start training our model, I want to introduce a few parameters that are important to understand:\n",
        "\n",
        "**QLoRA**: We’re using QLoRA for fine-tuning, which is why we’re loading the base model in 4-bit precision (NF4 format). You can check this article from Benjamin Marie to know more about QLoRA.\n",
        "\n",
        "**Gradient checkpointing**: It lowers the VRAM requirements by removing some activations that are re-computed on demand during the backward pass. It also slows down training by about 20%, according to Hugging Face’s documentation.\n",
        "\n",
        "**FlashAttention**: This implements the FlashAttentionmechanism, which improves the speed and memory efficiency of our model thanks to a clever fusion of GPU operations (learn more about it in this article from Aleksa Gordiç).\n",
        "\n",
        "**Sample packing**: Smart way of creating batches with as little padding as possible, by reorganizing the order of the samples (bin packing problem). As a result, we need fewer batches to train the model on the same dataset. It was inspired by the Multipack Sampler (see my note) and Krell et al.\n",
        "\n",
        "You can find FlashAttention in some other tools, but sample packing is relatively new. As far as I know, OpenChatwas the first project to use sample packing during fine-tuning. Thanks to Axolotl, we’ll use these techniques for free."
      ],
      "metadata": {
        "id": "WJpaVk-SD89w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune Code Llama\n",
        "Now that the config file is ready, we can launch the training."
      ],
      "metadata": {
        "id": "o7MPfNbxGE0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!accelerate launch /content/axolotl/scripts/finetune.py EvolCodeLlama-7b.yaml\n",
        "!accelerate launch -m axolotl.cli.train /content/EvolCodeLlama-7b.yaml"
      ],
      "metadata": {
        "id": "qARO_OyBHPO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87201cf2-3817-464b-d3e6-23e214d4ab33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-10-10 12:27:57.616448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "                              dP            dP   dP \n",
            "                              88            88   88 \n",
            "   .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "   88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "   88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "   `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                    \n",
            "                                                    \n",
            "\n",
            "\u001b[33m[2023-10-10 12:28:00,736] [WARNING] [axolotl.validate_config:148] [PID:2766] [RANK:0] `pad_to_sequence_len: true` is recommended when using sample_packing\u001b[39m\n",
            "\u001b[33m[2023-10-10 12:28:00,736] [WARNING] [axolotl.validate_config:163] [PID:2766] [RANK:0] eval_batch_size != micro_batch_size. This can lead to VRAM instability.\u001b[39m\n",
            "Downloading (…)lve/main/config.json: 100% 637/637 [00:00<00:00, 2.85MB/s]\n",
            "[2023-10-10 12:28:01,345] [INFO] [axolotl.normalize_config:122] [PID:2766] [RANK:0] GPU memory usage baseline: 0.000GB (+0.439GB misc)\u001b[39m\n",
            "Downloading (…)okenizer_config.json: 100% 749/749 [00:00<00:00, 4.17MB/s]\n",
            "Downloading tokenizer.model: 100% 500k/500k [00:00<00:00, 57.8MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 411/411 [00:00<00:00, 2.18MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 7.74MB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "[2023-10-10 12:28:04,421] [DEBUG] [axolotl.load_tokenizer:75] [PID:2766] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2023-10-10 12:28:04,421] [DEBUG] [axolotl.load_tokenizer:76] [PID:2766] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2023-10-10 12:28:04,421] [DEBUG] [axolotl.load_tokenizer:77] [PID:2766] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2023-10-10 12:28:04,421] [DEBUG] [axolotl.load_tokenizer:78] [PID:2766] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2023-10-10 12:28:04,563] [INFO] [axolotl.load_tokenized_prepared_datasets:130] [PID:2766] [RANK:0] Unable to find prepared dataset in last_run_prepared/ae22f11f26ed6e9c8c2575edb688327f\u001b[39m\n",
            "[2023-10-10 12:28:04,564] [INFO] [axolotl.load_tokenized_prepared_datasets:131] [PID:2766] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "[2023-10-10 12:28:04,564] [INFO] [axolotl.load_tokenized_prepared_datasets:136] [PID:2766] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Downloading readme: 100% 756/756 [00:00<00:00, 5.67MB/s]\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/2.32M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data: 100% 2.32M/2.32M [00:01<00:00, 1.68MB/s]\n",
            "Downloading data files: 100% 1/1 [00:01<00:00,  1.39s/it]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 1689.21it/s]\n",
            "Generating train split: 100% 1000/1000 [00:00<00:00, 19939.07 examples/s]\n",
            "Map (num_proc=12): 100% 1000/1000 [00:01<00:00, 615.98 examples/s]\n",
            "[2023-10-10 12:28:15,038] [INFO] [axolotl.load_tokenized_prepared_datasets:354] [PID:2766] [RANK:0] merging datasets\u001b[39m\n",
            "[2023-10-10 12:28:15,041] [INFO] [axolotl.load_tokenized_prepared_datasets:361] [PID:2766] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/ae22f11f26ed6e9c8c2575edb688327f\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 1000/1000 [00:00<00:00, 30814.41 examples/s]\n",
            "Filter (num_proc=12): 100% 980/980 [00:00<00:00, 1946.79 examples/s]\n",
            "Filter (num_proc=12): 100% 20/20 [00:00<00:00, 117.91 examples/s]\n",
            "Map (num_proc=12): 100% 966/966 [00:00<00:00, 2647.97 examples/s]\n",
            "Map (num_proc=12): 100% 20/20 [00:00<00:00, 113.13 examples/s]\n",
            "[2023-10-10 12:28:16,906] [INFO] [axolotl.calculate_total_num_steps:438] [PID:2766] [RANK:0] calculating total_num_tokens\u001b[39m\n",
            "[2023-10-10 12:28:16,916] [INFO] [axolotl.calculate_total_num_steps:445] [PID:2766] [RANK:0] total_num_tokens: 1479985\u001b[39m\n",
            "[2023-10-10 12:28:16,937] [INFO] [axolotl.calculate_total_num_steps:455] [PID:2766] [RANK:0] `total_supervised_tokens: 1041272`\u001b[39m\n",
            "[2023-10-10 12:28:16,942] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:28:16,954] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 89bb87f75b59dd087fb9c1dae85437e3a11b299b798edb5d16575cf6eb66ac32\u001b[39m\n",
            "[2023-10-10 12:28:22,469] [INFO] [axolotl.utils.dataloader.len_w_stats:295] [PID:2766] [RANK:0] packing_efficiency_estimate: 1.0 actual packing efficiency: 0.950853849712171\u001b[39m\n",
            "[2023-10-10 12:28:22,469] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 1479985\u001b[39m\n",
            "[2023-10-10 12:28:22,470] [INFO] [axolotl.calculate_total_num_steps:504] [PID:2766] [RANK:0] data_loader_len: 70\u001b[39m\n",
            "[2023-10-10 12:28:22,470] [INFO] [axolotl.calc_sample_packing_eff_est:510] [PID:2766] [RANK:0] sample_packing_eff_est across ranks: [0.950853849712171]\u001b[39m\n",
            "[2023-10-10 12:28:22,470] [INFO] [axolotl.calculate_total_num_steps:521] [PID:2766] [RANK:0] sample_packing_eff_est: 0.96\u001b[39m\n",
            "[2023-10-10 12:28:22,470] [INFO] [axolotl.calculate_total_num_steps:526] [PID:2766] [RANK:0] total_num_steps: 210\u001b[39m\n",
            "[2023-10-10 12:28:22,470] [INFO] [axolotl.train.train:48] [PID:2766] [RANK:0] loading tokenizer... codellama/CodeLlama-7b-hf\u001b[39m\n",
            "[2023-10-10 12:28:22,889] [DEBUG] [axolotl.load_tokenizer:75] [PID:2766] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2023-10-10 12:28:22,889] [DEBUG] [axolotl.load_tokenizer:76] [PID:2766] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2023-10-10 12:28:22,889] [DEBUG] [axolotl.load_tokenizer:77] [PID:2766] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2023-10-10 12:28:22,889] [DEBUG] [axolotl.load_tokenizer:78] [PID:2766] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2023-10-10 12:28:23,037] [INFO] [axolotl.train.train:56] [PID:2766] [RANK:0] loading model and (optionally) peft_config...\u001b[39m\n",
            "[2023-10-10 12:28:23,312] [INFO] [axolotl.load_model:145] [PID:2766] [RANK:0] patching with flash attention for sample packing\u001b[39m\n",
            "[2023-10-10 12:28:23,313] [INFO] [axolotl.load_model:198] [PID:2766] [RANK:0] patching _expand_mask\u001b[39m\n",
            "Downloading (…)fetensors.index.json: 100% 25.1k/25.1k [00:00<00:00, 84.6MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "Downloading (…)of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   0% 31.5M/9.98G [00:00<00:40, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   1% 62.9M/9.98G [00:00<00:49, 202MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   1% 83.9M/9.98G [00:00<00:49, 201MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   1% 115M/9.98G [00:00<00:45, 214MB/s] \u001b[A\n",
            "Downloading (…)of-00002.safetensors:   1% 147M/9.98G [00:00<00:42, 233MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   2% 178M/9.98G [00:00<00:43, 223MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   2% 210M/9.98G [00:00<00:41, 237MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   2% 241M/9.98G [00:01<00:39, 246MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   3% 273M/9.98G [00:01<00:40, 237MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   3% 304M/9.98G [00:01<00:38, 252MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   3% 336M/9.98G [00:01<00:38, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   4% 367M/9.98G [00:01<00:39, 242MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   4% 398M/9.98G [00:01<00:38, 246MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   4% 430M/9.98G [00:01<00:39, 244MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   5% 472M/9.98G [00:01<00:34, 278MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   5% 503M/9.98G [00:02<00:33, 282MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   5% 535M/9.98G [00:02<00:34, 272MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   6% 566M/9.98G [00:02<00:34, 271MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   6% 598M/9.98G [00:02<00:38, 245MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   6% 629M/9.98G [00:02<00:38, 243MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   7% 661M/9.98G [00:02<00:45, 204MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   7% 692M/9.98G [00:02<00:48, 191MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   7% 724M/9.98G [00:03<00:43, 211MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   8% 755M/9.98G [00:03<00:42, 218MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   8% 797M/9.98G [00:03<00:37, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   8% 839M/9.98G [00:03<00:34, 266MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   9% 881M/9.98G [00:03<00:31, 286MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   9% 912M/9.98G [00:03<00:32, 279MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   9% 944M/9.98G [00:03<00:34, 265MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  10% 975M/9.98G [00:03<00:32, 275MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  10% 1.02G/9.98G [00:04<00:30, 299MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  11% 1.05G/9.98G [00:04<00:31, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  11% 1.09G/9.98G [00:04<00:29, 299MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  11% 1.12G/9.98G [00:04<00:30, 292MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  12% 1.15G/9.98G [00:04<00:31, 284MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  12% 1.20G/9.98G [00:04<00:29, 299MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  12% 1.23G/9.98G [00:04<00:29, 301MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  13% 1.26G/9.98G [00:04<00:29, 296MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  13% 1.30G/9.98G [00:05<00:28, 300MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  13% 1.33G/9.98G [00:05<00:29, 298MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  14% 1.36G/9.98G [00:05<00:29, 288MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  14% 1.39G/9.98G [00:05<00:29, 286MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  14% 1.43G/9.98G [00:05<00:29, 292MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  15% 1.46G/9.98G [00:05<00:29, 285MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  15% 1.49G/9.98G [00:05<00:31, 272MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  15% 1.53G/9.98G [00:05<00:29, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  16% 1.56G/9.98G [00:05<00:29, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  16% 1.60G/9.98G [00:06<00:31, 265MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  16% 1.64G/9.98G [00:06<00:33, 252MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  17% 1.67G/9.98G [00:06<00:33, 248MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  17% 1.70G/9.98G [00:06<00:32, 256MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  17% 1.73G/9.98G [00:06<00:34, 242MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  18% 1.77G/9.98G [00:06<00:30, 268MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  18% 1.81G/9.98G [00:06<00:28, 283MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  19% 1.86G/9.98G [00:07<00:27, 292MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  19% 1.90G/9.98G [00:07<00:26, 300MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  19% 1.93G/9.98G [00:07<00:29, 274MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  20% 1.97G/9.98G [00:07<00:27, 290MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  20% 2.00G/9.98G [00:07<00:32, 248MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  20% 2.04G/9.98G [00:07<00:29, 272MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  21% 2.08G/9.98G [00:07<00:28, 282MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  21% 2.11G/9.98G [00:08<00:29, 265MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  21% 2.14G/9.98G [00:08<00:32, 242MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  22% 2.17G/9.98G [00:08<00:30, 258MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  22% 2.20G/9.98G [00:08<00:30, 255MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  22% 2.24G/9.98G [00:08<00:26, 292MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  23% 2.29G/9.98G [00:08<00:23, 320MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  23% 2.33G/9.98G [00:08<00:25, 297MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  24% 2.36G/9.98G [00:08<00:25, 299MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  24% 2.39G/9.98G [00:08<00:25, 303MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  24% 2.42G/9.98G [00:09<00:25, 296MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  25% 2.46G/9.98G [00:09<00:24, 303MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  25% 2.51G/9.98G [00:09<00:23, 315MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  26% 2.55G/9.98G [00:09<00:25, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  26% 2.58G/9.98G [00:09<00:25, 290MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  26% 2.61G/9.98G [00:09<00:27, 265MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  26% 2.64G/9.98G [00:09<00:27, 264MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  27% 2.67G/9.98G [00:10<00:27, 264MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  27% 2.72G/9.98G [00:10<00:24, 294MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  28% 2.77G/9.98G [00:10<00:21, 335MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  28% 2.81G/9.98G [00:10<00:21, 327MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  29% 2.85G/9.98G [00:10<00:25, 275MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  29% 2.88G/9.98G [00:10<00:26, 269MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  29% 2.93G/9.98G [00:10<00:24, 284MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  30% 2.96G/9.98G [00:10<00:26, 268MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  30% 3.00G/9.98G [00:11<00:24, 291MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  30% 3.03G/9.98G [00:11<00:23, 295MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  31% 3.06G/9.98G [00:11<00:24, 283MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  31% 3.09G/9.98G [00:11<00:24, 279MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  31% 3.14G/9.98G [00:11<00:23, 291MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  32% 3.17G/9.98G [00:11<00:24, 284MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  32% 3.20G/9.98G [00:11<00:23, 283MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  32% 3.23G/9.98G [00:11<00:26, 259MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  33% 3.26G/9.98G [00:12<00:28, 235MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  33% 3.29G/9.98G [00:12<00:29, 230MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  33% 3.32G/9.98G [00:12<00:27, 239MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  34% 3.36G/9.98G [00:12<00:26, 248MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  34% 3.40G/9.98G [00:12<00:24, 269MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  34% 3.44G/9.98G [00:12<00:22, 285MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  35% 3.47G/9.98G [00:12<00:22, 288MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  35% 3.50G/9.98G [00:12<00:22, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  35% 3.53G/9.98G [00:13<00:22, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  36% 3.57G/9.98G [00:13<00:25, 255MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  36% 3.60G/9.98G [00:13<00:24, 259MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  36% 3.63G/9.98G [00:13<00:24, 257MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  37% 3.66G/9.98G [00:13<00:24, 262MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  37% 3.69G/9.98G [00:13<00:22, 276MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  37% 3.72G/9.98G [00:13<00:23, 263MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  38% 3.75G/9.98G [00:13<00:24, 252MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  38% 3.79G/9.98G [00:14<00:28, 214MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  38% 3.82G/9.98G [00:14<00:32, 189MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  39% 3.85G/9.98G [00:14<00:28, 212MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  39% 3.88G/9.98G [00:14<00:26, 228MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  39% 3.91G/9.98G [00:14<00:26, 225MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  40% 3.94G/9.98G [00:14<00:24, 242MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  40% 3.97G/9.98G [00:15<00:34, 176MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  40% 4.01G/9.98G [00:15<00:30, 195MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  40% 4.04G/9.98G [00:15<00:39, 150MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  41% 4.08G/9.98G [00:15<00:32, 182MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  41% 4.11G/9.98G [00:15<00:29, 197MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  42% 4.14G/9.98G [00:16<00:29, 195MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  42% 4.17G/9.98G [00:16<00:33, 172MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  42% 4.19G/9.98G [00:16<00:32, 177MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  42% 4.22G/9.98G [00:16<00:32, 178MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  43% 4.25G/9.98G [00:16<00:29, 196MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  43% 4.28G/9.98G [00:16<00:27, 209MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  43% 4.31G/9.98G [00:16<00:25, 218MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  44% 4.35G/9.98G [00:17<00:22, 254MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  44% 4.39G/9.98G [00:17<00:19, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  44% 4.42G/9.98G [00:17<00:20, 270MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  45% 4.46G/9.98G [00:17<00:19, 278MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  45% 4.49G/9.98G [00:17<00:19, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  45% 4.52G/9.98G [00:17<00:20, 271MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  46% 4.55G/9.98G [00:17<00:21, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  46% 4.59G/9.98G [00:17<00:19, 272MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  46% 4.62G/9.98G [00:17<00:18, 282MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  47% 4.66G/9.98G [00:18<00:18, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  47% 4.69G/9.98G [00:18<00:18, 285MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  47% 4.72G/9.98G [00:18<00:19, 273MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  48% 4.75G/9.98G [00:18<00:21, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  48% 4.79G/9.98G [00:18<00:18, 274MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  48% 4.82G/9.98G [00:18<00:18, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  49% 4.85G/9.98G [00:18<00:18, 284MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  49% 4.89G/9.98G [00:18<00:17, 290MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  49% 4.92G/9.98G [00:19<00:17, 289MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  50% 4.95G/9.98G [00:19<00:17, 289MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  50% 4.98G/9.98G [00:19<00:21, 228MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  50% 5.01G/9.98G [00:19<00:20, 243MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  51% 5.05G/9.98G [00:19<00:17, 276MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  51% 5.10G/9.98G [00:19<00:16, 292MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  51% 5.13G/9.98G [00:19<00:16, 294MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  52% 5.16G/9.98G [00:19<00:17, 275MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  52% 5.19G/9.98G [00:20<00:17, 278MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  53% 5.24G/9.98G [00:20<00:14, 324MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  53% 5.28G/9.98G [00:20<00:14, 331MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  53% 5.33G/9.98G [00:20<00:14, 322MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  54% 5.37G/9.98G [00:20<00:15, 298MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  54% 5.40G/9.98G [00:20<00:15, 291MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  54% 5.43G/9.98G [00:20<00:15, 293MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  55% 5.46G/9.98G [00:20<00:15, 294MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  55% 5.49G/9.98G [00:21<00:17, 255MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  55% 5.53G/9.98G [00:21<00:17, 257MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  56% 5.56G/9.98G [00:21<00:18, 244MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  56% 5.60G/9.98G [00:21<00:16, 267MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  56% 5.63G/9.98G [00:21<00:17, 249MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  57% 5.66G/9.98G [00:21<00:18, 237MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  57% 5.69G/9.98G [00:21<00:18, 236MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  57% 5.73G/9.98G [00:22<00:17, 245MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  58% 5.76G/9.98G [00:22<00:17, 239MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  58% 5.79G/9.98G [00:22<00:17, 241MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  58% 5.83G/9.98G [00:22<00:14, 284MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  59% 5.87G/9.98G [00:22<00:13, 308MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  59% 5.91G/9.98G [00:22<00:12, 325MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  60% 5.96G/9.98G [00:22<00:11, 344MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  60% 6.00G/9.98G [00:22<00:11, 338MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  61% 6.04G/9.98G [00:23<00:12, 306MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  61% 6.08G/9.98G [00:23<00:13, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  61% 6.11G/9.98G [00:23<00:13, 289MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  62% 6.14G/9.98G [00:23<00:14, 270MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  62% 6.18G/9.98G [00:23<00:14, 260MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  62% 6.21G/9.98G [00:23<00:14, 260MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  63% 6.24G/9.98G [00:23<00:14, 267MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  63% 6.27G/9.98G [00:23<00:15, 236MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  63% 6.30G/9.98G [00:24<00:15, 235MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  63% 6.33G/9.98G [00:24<00:17, 212MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  64% 6.36G/9.98G [00:24<00:16, 221MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  64% 6.40G/9.98G [00:24<00:15, 238MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  65% 6.44G/9.98G [00:24<00:13, 269MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  65% 6.47G/9.98G [00:24<00:13, 257MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  65% 6.50G/9.98G [00:24<00:13, 259MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  65% 6.53G/9.98G [00:24<00:12, 272MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  66% 6.56G/9.98G [00:25<00:16, 206MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  66% 6.60G/9.98G [00:25<00:16, 210MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  66% 6.63G/9.98G [00:25<00:17, 192MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  67% 6.65G/9.98G [00:25<00:18, 181MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  67% 6.67G/9.98G [00:25<00:20, 162MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  67% 6.70G/9.98G [00:26<00:17, 186MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  67% 6.72G/9.98G [00:26<00:17, 190MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  68% 6.75G/9.98G [00:26<00:16, 201MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  68% 6.78G/9.98G [00:26<00:20, 158MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  68% 6.83G/9.98G [00:26<00:15, 205MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  69% 6.86G/9.98G [00:26<00:15, 196MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  69% 6.89G/9.98G [00:26<00:14, 215MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  69% 6.92G/9.98G [00:27<00:14, 214MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  70% 6.95G/9.98G [00:27<00:13, 221MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  70% 6.98G/9.98G [00:27<00:13, 215MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  70% 7.01G/9.98G [00:27<00:12, 229MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  71% 7.05G/9.98G [00:27<00:12, 229MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  71% 7.08G/9.98G [00:27<00:12, 242MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  71% 7.11G/9.98G [00:27<00:12, 231MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  72% 7.14G/9.98G [00:28<00:11, 246MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  72% 7.17G/9.98G [00:28<00:10, 260MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  72% 7.20G/9.98G [00:28<00:10, 266MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  73% 7.24G/9.98G [00:28<00:09, 275MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  73% 7.28G/9.98G [00:28<00:09, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  73% 7.31G/9.98G [00:28<00:09, 276MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  74% 7.35G/9.98G [00:28<00:09, 280MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  74% 7.38G/9.98G [00:28<00:09, 266MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  74% 7.41G/9.98G [00:29<00:10, 244MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  75% 7.44G/9.98G [00:29<00:11, 225MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  75% 7.48G/9.98G [00:29<00:10, 232MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  75% 7.51G/9.98G [00:29<00:10, 239MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  76% 7.54G/9.98G [00:29<00:09, 248MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  76% 7.57G/9.98G [00:29<00:09, 250MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  76% 7.61G/9.98G [00:29<00:08, 274MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  77% 7.64G/9.98G [00:29<00:08, 269MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  77% 7.68G/9.98G [00:30<00:08, 262MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  77% 7.71G/9.98G [00:30<00:12, 183MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  78% 7.74G/9.98G [00:30<00:11, 194MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  78% 7.77G/9.98G [00:30<00:10, 214MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  78% 7.80G/9.98G [00:30<00:10, 211MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  79% 7.83G/9.98G [00:30<00:10, 206MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  79% 7.87G/9.98G [00:31<00:08, 241MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  79% 7.93G/9.98G [00:31<00:07, 286MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  80% 7.97G/9.98G [00:31<00:06, 302MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  80% 8.01G/9.98G [00:31<00:06, 288MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  81% 8.04G/9.98G [00:31<00:06, 291MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  81% 8.07G/9.98G [00:31<00:06, 282MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  81% 8.11G/9.98G [00:31<00:06, 285MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  82% 8.14G/9.98G [00:31<00:07, 256MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  82% 8.17G/9.98G [00:32<00:06, 262MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  82% 8.20G/9.98G [00:32<00:06, 257MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  83% 8.23G/9.98G [00:32<00:06, 252MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  83% 8.26G/9.98G [00:32<00:08, 206MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  83% 8.29G/9.98G [00:32<00:08, 191MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  83% 8.33G/9.98G [00:32<00:07, 209MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  84% 8.36G/9.98G [00:33<00:08, 194MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  84% 8.39G/9.98G [00:33<00:07, 207MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  84% 8.42G/9.98G [00:33<00:07, 219MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  85% 8.46G/9.98G [00:33<00:06, 239MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  85% 8.49G/9.98G [00:33<00:06, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  85% 8.52G/9.98G [00:33<00:05, 258MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  86% 8.57G/9.98G [00:33<00:04, 288MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  86% 8.60G/9.98G [00:33<00:04, 278MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  86% 8.63G/9.98G [00:34<00:04, 270MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  87% 8.66G/9.98G [00:34<00:04, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  87% 8.70G/9.98G [00:34<00:04, 308MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  88% 8.75G/9.98G [00:34<00:03, 330MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  88% 8.79G/9.98G [00:34<00:03, 338MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  88% 8.83G/9.98G [00:34<00:03, 330MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  89% 8.87G/9.98G [00:34<00:03, 307MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  89% 8.91G/9.98G [00:34<00:03, 313MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  90% 8.95G/9.98G [00:35<00:03, 297MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  90% 8.99G/9.98G [00:35<00:03, 294MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  90% 9.03G/9.98G [00:35<00:03, 309MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  91% 9.06G/9.98G [00:35<00:04, 224MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  91% 9.09G/9.98G [00:35<00:03, 232MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  91% 9.12G/9.98G [00:35<00:04, 205MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  92% 9.15G/9.98G [00:36<00:04, 198MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  92% 9.19G/9.98G [00:36<00:04, 197MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  92% 9.21G/9.98G [00:36<00:04, 180MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  93% 9.24G/9.98G [00:36<00:03, 195MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  93% 9.27G/9.98G [00:36<00:03, 199MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  93% 9.29G/9.98G [00:36<00:03, 196MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  93% 9.31G/9.98G [00:36<00:03, 189MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  94% 9.33G/9.98G [00:36<00:03, 193MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  94% 9.36G/9.98G [00:37<00:03, 199MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  94% 9.40G/9.98G [00:37<00:02, 215MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  94% 9.43G/9.98G [00:37<00:02, 224MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  95% 9.46G/9.98G [00:37<00:02, 222MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  95% 9.49G/9.98G [00:37<00:02, 182MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  95% 9.52G/9.98G [00:37<00:02, 204MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  96% 9.55G/9.98G [00:38<00:02, 199MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  96% 9.58G/9.98G [00:38<00:01, 213MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  96% 9.62G/9.98G [00:38<00:01, 225MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  97% 9.65G/9.98G [00:38<00:01, 246MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  97% 9.68G/9.98G [00:38<00:01, 250MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  97% 9.71G/9.98G [00:38<00:01, 234MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  98% 9.74G/9.98G [00:38<00:01, 223MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  98% 9.77G/9.98G [00:38<00:00, 242MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  98% 9.80G/9.98G [00:39<00:00, 244MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  99% 9.84G/9.98G [00:39<00:00, 232MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  99% 9.87G/9.98G [00:39<00:00, 238MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  99% 9.90G/9.98G [00:39<00:00, 233MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors: 100% 9.93G/9.98G [00:39<00:00, 247MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors: 100% 9.98G/9.98G [00:39<00:00, 251MB/s]\n",
            "Downloading shards:  50% 1/2 [00:39<00:39, 40.00s/it]\n",
            "Downloading (…)of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   1% 31.5M/3.50G [00:00<00:13, 251MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   2% 83.9M/3.50G [00:00<00:09, 366MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   4% 126M/3.50G [00:00<00:09, 370MB/s] \u001b[A\n",
            "Downloading (…)of-00002.safetensors:   5% 168M/3.50G [00:00<00:08, 373MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   6% 210M/3.50G [00:00<00:08, 369MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   7% 252M/3.50G [00:00<00:08, 380MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:   8% 294M/3.50G [00:00<00:08, 374MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  10% 336M/3.50G [00:01<00:12, 256MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  10% 367M/3.50G [00:01<00:13, 237MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  11% 398M/3.50G [00:01<00:14, 217MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  12% 430M/3.50G [00:01<00:14, 217MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  13% 461M/3.50G [00:01<00:14, 203MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  14% 493M/3.50G [00:01<00:14, 203MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  15% 524M/3.50G [00:02<00:13, 216MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  16% 556M/3.50G [00:02<00:13, 224MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  17% 598M/3.50G [00:02<00:10, 264MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  18% 629M/3.50G [00:02<00:10, 270MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  19% 661M/3.50G [00:02<00:10, 262MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  20% 692M/3.50G [00:02<00:10, 268MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  21% 724M/3.50G [00:02<00:10, 272MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  22% 765M/3.50G [00:02<00:09, 280MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  23% 797M/3.50G [00:03<00:11, 238MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  24% 828M/3.50G [00:03<00:11, 232MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  25% 860M/3.50G [00:03<00:11, 238MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  25% 891M/3.50G [00:03<00:12, 201MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  26% 923M/3.50G [00:03<00:11, 219MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  28% 965M/3.50G [00:03<00:10, 253MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  28% 996M/3.50G [00:03<00:09, 254MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  29% 1.03G/3.50G [00:03<00:09, 266MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  31% 1.07G/3.50G [00:04<00:08, 288MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  31% 1.10G/3.50G [00:04<00:08, 292MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  32% 1.13G/3.50G [00:04<00:08, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  33% 1.16G/3.50G [00:04<00:08, 289MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  34% 1.20G/3.50G [00:04<00:07, 290MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  35% 1.23G/3.50G [00:04<00:07, 287MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  36% 1.27G/3.50G [00:04<00:07, 295MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  37% 1.31G/3.50G [00:04<00:06, 318MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  39% 1.35G/3.50G [00:05<00:07, 304MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  40% 1.38G/3.50G [00:05<00:06, 303MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  41% 1.43G/3.50G [00:05<00:06, 317MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  42% 1.47G/3.50G [00:05<00:06, 325MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  43% 1.51G/3.50G [00:05<00:06, 316MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  44% 1.55G/3.50G [00:05<00:06, 317MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  46% 1.59G/3.50G [00:05<00:06, 302MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  46% 1.63G/3.50G [00:05<00:06, 289MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  48% 1.67G/3.50G [00:06<00:05, 308MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  49% 1.70G/3.50G [00:06<00:05, 302MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  49% 1.73G/3.50G [00:06<00:10, 172MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  50% 1.76G/3.50G [00:06<00:09, 188MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  51% 1.79G/3.50G [00:06<00:08, 210MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  52% 1.82G/3.50G [00:06<00:07, 223MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  53% 1.86G/3.50G [00:07<00:07, 235MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  54% 1.89G/3.50G [00:07<00:06, 235MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  55% 1.92G/3.50G [00:07<00:07, 210MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  56% 1.95G/3.50G [00:07<00:06, 228MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  57% 1.99G/3.50G [00:07<00:05, 262MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  58% 2.02G/3.50G [00:07<00:05, 269MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  59% 2.06G/3.50G [00:07<00:06, 237MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  60% 2.09G/3.50G [00:07<00:05, 252MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  61% 2.12G/3.50G [00:08<00:05, 243MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  61% 2.15G/3.50G [00:08<00:05, 226MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  62% 2.18G/3.50G [00:08<00:05, 221MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  63% 2.21G/3.50G [00:08<00:06, 193MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  64% 2.23G/3.50G [00:08<00:06, 184MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  65% 2.26G/3.50G [00:08<00:06, 187MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  65% 2.29G/3.50G [00:09<00:06, 184MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  66% 2.31G/3.50G [00:09<00:06, 187MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  67% 2.33G/3.50G [00:09<00:06, 190MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  67% 2.35G/3.50G [00:09<00:05, 193MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  68% 2.39G/3.50G [00:09<00:04, 232MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  69% 2.42G/3.50G [00:09<00:04, 228MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  70% 2.46G/3.50G [00:09<00:03, 263MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  72% 2.51G/3.50G [00:09<00:03, 276MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  73% 2.55G/3.50G [00:10<00:03, 297MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  74% 2.59G/3.50G [00:10<00:02, 316MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  75% 2.63G/3.50G [00:10<00:02, 296MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  76% 2.66G/3.50G [00:10<00:02, 298MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  77% 2.69G/3.50G [00:10<00:02, 274MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  78% 2.73G/3.50G [00:10<00:02, 268MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  79% 2.76G/3.50G [00:10<00:02, 274MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  80% 2.79G/3.50G [00:10<00:02, 273MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  81% 2.83G/3.50G [00:11<00:02, 297MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  82% 2.87G/3.50G [00:11<00:01, 319MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  83% 2.92G/3.50G [00:11<00:01, 339MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  84% 2.96G/3.50G [00:11<00:01, 330MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  86% 3.00G/3.50G [00:11<00:01, 325MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  87% 3.04G/3.50G [00:11<00:01, 335MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  88% 3.08G/3.50G [00:11<00:01, 305MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  89% 3.11G/3.50G [00:11<00:01, 274MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  90% 3.15G/3.50G [00:12<00:01, 283MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  91% 3.19G/3.50G [00:12<00:01, 290MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  92% 3.22G/3.50G [00:12<00:01, 279MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  93% 3.26G/3.50G [00:12<00:00, 299MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  94% 3.29G/3.50G [00:12<00:00, 281MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  95% 3.32G/3.50G [00:12<00:00, 265MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  96% 3.36G/3.50G [00:12<00:00, 271MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  97% 3.39G/3.50G [00:12<00:00, 264MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  98% 3.42G/3.50G [00:13<00:00, 256MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors:  99% 3.45G/3.50G [00:13<00:00, 269MB/s]\u001b[A\n",
            "Downloading (…)of-00002.safetensors: 100% 3.50G/3.50G [00:13<00:00, 259MB/s]\n",
            "Downloading shards: 100% 2/2 [00:53<00:00, 26.89s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:20<00:00, 10.36s/it]\n",
            "Downloading (…)neration_config.json: 100% 116/116 [00:00<00:00, 734kB/s]\n",
            "[2023-10-10 12:29:41,282] [INFO] [axolotl.load_model:376] [PID:2766] [RANK:0] GPU memory usage after model load: 3.873GB (+0.120GB cache, +1.736GB misc)\u001b[39m\n",
            "[2023-10-10 12:29:41,290] [INFO] [axolotl.load_model:393] [PID:2766] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2023-10-10 12:29:41,294] [INFO] [axolotl.load_model:404] [PID:2766] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
            "[2023-10-10 12:29:41,298] [INFO] [axolotl.load_lora:509] [PID:2766] [RANK:0] found linear modules: ['gate_proj', 'up_proj', 'k_proj', 'o_proj', 'v_proj', 'down_proj', 'q_proj']\u001b[39m\n",
            "trainable params: 79,953,920 || all params: 6,818,500,608 || trainable%: 1.172602667310637\n",
            "[2023-10-10 12:30:32,598] [INFO] [axolotl.load_model:440] [PID:2766] [RANK:0] GPU memory usage after adapters: 4.175GB (+0.969GB cache, +1.736GB misc)\u001b[39m\n",
            "[2023-10-10 12:30:32,875] [INFO] [axolotl.train.train:84] [PID:2766] [RANK:0] Pre-saving adapter config to ./qlora-out\u001b[39m\n",
            "[2023-10-10 12:30:32,877] [INFO] [axolotl.train.train:108] [PID:2766] [RANK:0] Starting trainer...\u001b[39m\n",
            "[2023-10-10 12:30:33,167] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "[2023-10-10 12:30:33,167] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20231010_123338-svf8jtvr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcomfy-plant-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/royam0820/axolotl\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/royam0820/axolotl/runs/svf8jtvr\u001b[0m\n",
            "  0% 0/219 [00:00<?, ?it/s][2023-10-10 12:33:39,327] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "[2023-10-10 12:33:39,327] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:33:39,329] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 7930bab254c1b30145737258adbbf7bff75252b6b8ece3aca7dac56f2d173cb4\u001b[39m\n",
            "[2023-10-10 12:33:39,331] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "{'loss': 0.4271, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.01}\n",
            "  0% 1/219 [00:09<35:55,  9.89s/it][2023-10-10 12:33:49,219] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:33:49,227] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:33:49,227] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:33:49,228] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:33:51,006] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:33:51,006] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:33:51,739] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5533787608146667, 'eval_runtime': 2.541, 'eval_samples_per_second': 7.871, 'eval_steps_per_second': 0.787, 'epoch': 0.01}\n",
            "  0% 1/219 [00:12<35:55,  9.89s/it]\n",
            "2it [00:00,  2.73it/s]\u001b[A\n",
            "                      \u001b[A[2023-10-10 12:33:58,056] [INFO] [axolotl.callbacks.on_step_end:122] [PID:2766] [RANK:0] GPU memory usage while training: 4.250GB (+22.681GB cache, +2.847GB misc)\u001b[39m\n",
            "{'loss': 0.5038, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.03}\n",
            "{'loss': 0.3577, 'learning_rate': 6e-06, 'epoch': 0.04}\n",
            "  1% 3/219 [00:24<28:10,  7.83s/it][2023-10-10 12:34:04,163] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:04,170] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:34:04,171] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:34:04,171] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:05,953] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:05,954] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:34:06,680] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5534071922302246, 'eval_runtime': 2.5375, 'eval_samples_per_second': 7.882, 'eval_steps_per_second': 0.788, 'epoch': 0.04}\n",
            "  1% 3/219 [00:27<28:10,  7.83s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3449, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.05}\n",
            "{'loss': 0.3622, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
            "{'loss': 0.407, 'learning_rate': 1.2e-05, 'epoch': 0.08}\n",
            "  3% 6/219 [00:45<24:41,  6.96s/it][2023-10-10 12:34:24,977] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:24,984] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:34:24,984] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:34:24,985] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:26,768] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:26,769] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:34:27,495] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5531011819839478, 'eval_runtime': 2.5391, 'eval_samples_per_second': 7.877, 'eval_steps_per_second': 0.788, 'epoch': 0.08}\n",
            "  3% 6/219 [00:48<24:41,  6.96s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.4009, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.1}\n",
            "{'loss': 0.5035, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.11}\n",
            "{'loss': 0.4411, 'learning_rate': 1.8e-05, 'epoch': 0.12}\n",
            "  4% 9/219 [01:06<24:04,  6.88s/it][2023-10-10 12:34:46,239] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:46,246] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:34:46,246] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:34:46,247] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:48,037] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:34:48,037] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:34:48,763] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.5524589419364929, 'eval_runtime': 2.5455, 'eval_samples_per_second': 7.857, 'eval_steps_per_second': 0.786, 'epoch': 0.12}\n",
            "  4% 9/219 [01:09<24:04,  6.88s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.39, 'learning_rate': 2e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3727, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.15}\n",
            "{'loss': 0.4104, 'learning_rate': 2.4e-05, 'epoch': 0.16}\n",
            "  5% 12/219 [01:28<23:22,  6.78s/it][2023-10-10 12:35:07,414] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:07,421] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:35:07,421] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:35:07,422] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:09,208] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:09,209] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:35:09,936] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5516754388809204, 'eval_runtime': 2.5426, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 0.16}\n",
            "  5% 12/219 [01:30<23:22,  6.78s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.4042, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.18}\n",
            "{'loss': 0.3252, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.19}\n",
            "{'loss': 0.4336, 'learning_rate': 3e-05, 'epoch': 0.21}\n",
            "  7% 15/219 [01:49<23:07,  6.80s/it][2023-10-10 12:35:28,750] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:28,757] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:35:28,757] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:35:28,757] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:30,542] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:30,542] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:35:31,269] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5494909286499023, 'eval_runtime': 2.5401, 'eval_samples_per_second': 7.874, 'eval_steps_per_second': 0.787, 'epoch': 0.21}\n",
            "  7% 15/219 [01:51<23:07,  6.80s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.4435, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.22}\n",
            "{'loss': 0.4803, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.23}\n",
            "{'loss': 0.3577, 'learning_rate': 3.6e-05, 'epoch': 0.25}\n",
            "  8% 18/219 [02:10<23:07,  6.90s/it][2023-10-10 12:35:50,236] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:50,243] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:35:50,244] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:35:50,244] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:52,029] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:35:52,030] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:35:52,755] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5451678037643433, 'eval_runtime': 2.54, 'eval_samples_per_second': 7.874, 'eval_steps_per_second': 0.787, 'epoch': 0.25}\n",
            "  8% 18/219 [02:13<23:07,  6.90s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.4157, 'learning_rate': 3.8e-05, 'epoch': 0.26}\n",
            "{'loss': 0.3881, 'learning_rate': 4e-05, 'epoch': 0.27}\n",
            "{'loss': 0.4469, 'learning_rate': 4.2e-05, 'epoch': 0.29}\n",
            " 10% 21/219 [02:31<22:18,  6.76s/it][2023-10-10 12:36:10,997] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:11,005] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:36:11,005] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:36:11,005] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:12,796] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:12,796] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:36:13,524] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.5376065969467163, 'eval_runtime': 2.5469, 'eval_samples_per_second': 7.853, 'eval_steps_per_second': 0.785, 'epoch': 0.29}\n",
            " 10% 21/219 [02:34<22:18,  6.76s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.428, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.3}\n",
            "{'loss': 0.3858, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.32}\n",
            "{'loss': 0.4312, 'learning_rate': 4.8e-05, 'epoch': 0.33}\n",
            " 11% 24/219 [02:52<21:59,  6.77s/it][2023-10-10 12:36:32,078] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:32,085] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:36:32,085] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:36:32,086] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:33,871] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:33,871] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:36:34,597] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.524061381816864, 'eval_runtime': 2.5406, 'eval_samples_per_second': 7.872, 'eval_steps_per_second': 0.787, 'epoch': 0.33}\n",
            " 11% 24/219 [02:55<21:59,  6.77s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.3528, 'learning_rate': 5e-05, 'epoch': 0.34}\n",
            "{'loss': 0.5003, 'learning_rate': 5.2000000000000004e-05, 'epoch': 0.36}\n",
            "{'loss': 0.3224, 'learning_rate': 5.4000000000000005e-05, 'epoch': 0.37}\n",
            " 12% 27/219 [03:14<22:00,  6.88s/it][2023-10-10 12:36:53,725] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:53,732] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:36:53,733] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:36:53,733] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:55,519] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:36:55,520] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:36:56,245] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.506426215171814, 'eval_runtime': 2.5412, 'eval_samples_per_second': 7.87, 'eval_steps_per_second': 0.787, 'epoch': 0.37}\n",
            " 12% 27/219 [03:16<22:00,  6.88s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.4034, 'learning_rate': 5.6000000000000006e-05, 'epoch': 0.38}\n",
            "{'loss': 0.3873, 'learning_rate': 5.8e-05, 'epoch': 0.4}\n",
            "{'loss': 0.3277, 'learning_rate': 6e-05, 'epoch': 0.41}\n",
            " 14% 30/219 [03:35<21:21,  6.78s/it][2023-10-10 12:37:14,747] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:14,754] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:37:14,755] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:37:14,755] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:16,543] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:16,543] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:37:17,269] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.48772162199020386, 'eval_runtime': 2.5425, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 0.41}\n",
            " 14% 30/219 [03:37<21:21,  6.78s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.3136, 'learning_rate': 6.2e-05, 'epoch': 0.42}\n",
            "{'loss': 0.458, 'learning_rate': 6.400000000000001e-05, 'epoch': 0.44}\n",
            "{'loss': 0.393, 'learning_rate': 6.6e-05, 'epoch': 0.45}\n",
            " 15% 33/219 [03:56<21:06,  6.81s/it][2023-10-10 12:37:35,961] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:35,968] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:37:35,968] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:37:35,969] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:37,754] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:37,755] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:37:38,480] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.47120529413223267, 'eval_runtime': 2.5405, 'eval_samples_per_second': 7.872, 'eval_steps_per_second': 0.787, 'epoch': 0.45}\n",
            " 15% 33/219 [03:59<21:06,  6.81s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.3064, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.47}\n",
            "{'loss': 0.2896, 'learning_rate': 7e-05, 'epoch': 0.48}\n",
            "{'loss': 0.3481, 'learning_rate': 7.2e-05, 'epoch': 0.49}\n",
            " 16% 36/219 [04:17<20:34,  6.75s/it][2023-10-10 12:37:56,996] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:57,003] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:37:57,003] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:37:57,004] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:58,789] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:37:58,789] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:37:59,515] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.45629066228866577, 'eval_runtime': 2.5403, 'eval_samples_per_second': 7.873, 'eval_steps_per_second': 0.787, 'epoch': 0.49}\n",
            " 16% 36/219 [04:20<20:34,  6.75s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2749, 'learning_rate': 7.4e-05, 'epoch': 0.51}\n",
            "{'loss': 0.3064, 'learning_rate': 7.6e-05, 'epoch': 0.52}\n",
            "{'loss': 0.4016, 'learning_rate': 7.800000000000001e-05, 'epoch': 0.53}\n",
            " 18% 39/219 [04:38<20:16,  6.76s/it][2023-10-10 12:38:18,078] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:38:18,085] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:38:18,086] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:38:18,086] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:38:19,871] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:38:19,871] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:38:20,598] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4434221386909485, 'eval_runtime': 2.5404, 'eval_samples_per_second': 7.873, 'eval_steps_per_second': 0.787, 'epoch': 0.53}\n",
            " 18% 39/219 [04:41<20:16,  6.76s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3204, 'learning_rate': 8e-05, 'epoch': 0.55}\n",
            "{'loss': 0.3697, 'learning_rate': 8.2e-05, 'epoch': 0.56}\n",
            "{'loss': 0.2559, 'learning_rate': 8.4e-05, 'epoch': 0.58}\n",
            " 19% 42/219 [05:00<20:01,  6.79s/it][2023-10-10 12:38:39,395] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:38:39,402] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:38:39,402] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:38:39,403] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:38:41,189] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:38:41,190] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:38:41,916] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4350705146789551, 'eval_runtime': 2.5423, 'eval_samples_per_second': 7.867, 'eval_steps_per_second': 0.787, 'epoch': 0.58}\n",
            " 19% 42/219 [05:02<20:01,  6.79s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3579, 'learning_rate': 8.6e-05, 'epoch': 0.59}\n",
            "{'loss': 0.2854, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.6}\n",
            "{'loss': 0.381, 'learning_rate': 9e-05, 'epoch': 0.62}\n",
            " 21% 45/219 [05:21<19:38,  6.78s/it][2023-10-10 12:39:00,439] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:00,446] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:39:00,446] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:39:00,447] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:02,236] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:02,237] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:39:02,963] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4288090765476227, 'eval_runtime': 2.5445, 'eval_samples_per_second': 7.86, 'eval_steps_per_second': 0.786, 'epoch': 0.62}\n",
            " 21% 45/219 [05:23<19:38,  6.78s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2664, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.63}\n",
            "{'loss': 0.2061, 'learning_rate': 9.4e-05, 'epoch': 0.64}\n",
            "{'loss': 0.2916, 'learning_rate': 9.6e-05, 'epoch': 0.66}\n",
            " 22% 48/219 [05:42<19:10,  6.73s/it][2023-10-10 12:39:21,356] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:21,363] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:39:21,363] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:39:21,364] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:23,150] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:23,151] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:39:23,878] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4246935248374939, 'eval_runtime': 2.5425, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 0.66}\n",
            " 22% 48/219 [05:44<19:10,  6.73s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3864, 'learning_rate': 9.8e-05, 'epoch': 0.67}\n",
            "{'loss': 0.3182, 'learning_rate': 0.0001, 'epoch': 0.68}\n",
            "{'loss': 0.3279, 'learning_rate': 0.00010200000000000001, 'epoch': 0.7}\n",
            " 23% 51/219 [06:03<19:05,  6.82s/it][2023-10-10 12:39:42,800] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:42,807] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:39:42,807] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:39:42,808] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:44,595] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:39:44,596] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:39:45,322] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.41983065009117126, 'eval_runtime': 2.5426, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 0.7}\n",
            " 23% 51/219 [06:06<19:05,  6.82s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2916, 'learning_rate': 0.00010400000000000001, 'epoch': 0.71}\n",
            "{'loss': 0.2716, 'learning_rate': 0.00010600000000000002, 'epoch': 0.73}\n",
            "{'loss': 0.2873, 'learning_rate': 0.00010800000000000001, 'epoch': 0.74}\n",
            " 25% 54/219 [06:24<18:37,  6.78s/it][2023-10-10 12:40:03,733] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:03,740] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:40:03,740] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:40:03,741] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:05,527] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:05,528] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:40:06,253] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4147277772426605, 'eval_runtime': 2.5412, 'eval_samples_per_second': 7.87, 'eval_steps_per_second': 0.787, 'epoch': 0.74}\n",
            " 25% 54/219 [06:26<18:37,  6.78s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.348, 'learning_rate': 0.00011000000000000002, 'epoch': 0.75}\n",
            "{'loss': 0.3249, 'learning_rate': 0.00011200000000000001, 'epoch': 0.77}\n",
            "{'loss': 0.2408, 'learning_rate': 0.00011399999999999999, 'epoch': 0.78}\n",
            " 26% 57/219 [06:45<18:18,  6.78s/it][2023-10-10 12:40:24,989] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:24,996] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:40:24,996] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:40:24,997] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:26,783] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:26,784] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:40:27,510] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.41192373633384705, 'eval_runtime': 2.5419, 'eval_samples_per_second': 7.868, 'eval_steps_per_second': 0.787, 'epoch': 0.78}\n",
            " 26% 57/219 [06:48<18:18,  6.78s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2306, 'learning_rate': 0.000116, 'epoch': 0.79}\n",
            "{'loss': 0.3457, 'learning_rate': 0.000118, 'epoch': 0.81}\n",
            "{'loss': 0.2981, 'learning_rate': 0.00012, 'epoch': 0.82}\n",
            " 27% 60/219 [07:06<17:56,  6.77s/it][2023-10-10 12:40:46,039] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:46,047] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:40:46,047] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:40:46,048] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:47,833] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:40:47,833] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:40:48,561] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4106983542442322, 'eval_runtime': 2.5431, 'eval_samples_per_second': 7.864, 'eval_steps_per_second': 0.786, 'epoch': 0.82}\n",
            " 27% 60/219 [07:09<17:56,  6.77s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2591, 'learning_rate': 0.000122, 'epoch': 0.84}\n",
            "{'loss': 0.3413, 'learning_rate': 0.000124, 'epoch': 0.85}\n",
            "{'loss': 0.3541, 'learning_rate': 0.000126, 'epoch': 0.86}\n",
            " 29% 63/219 [07:27<17:28,  6.72s/it][2023-10-10 12:41:06,943] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:06,950] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:41:06,951] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:41:06,951] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:08,738] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:08,739] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:41:09,466] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.40779566764831543, 'eval_runtime': 2.543, 'eval_samples_per_second': 7.865, 'eval_steps_per_second': 0.786, 'epoch': 0.86}\n",
            " 29% 63/219 [07:30<17:28,  6.72s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3222, 'learning_rate': 0.00012800000000000002, 'epoch': 0.88}\n",
            "{'loss': 0.2617, 'learning_rate': 0.00013000000000000002, 'epoch': 0.89}\n",
            "{'loss': 0.3408, 'learning_rate': 0.000132, 'epoch': 0.9}\n",
            " 30% 66/219 [07:48<17:01,  6.68s/it][2023-10-10 12:41:27,762] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:27,769] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:41:27,769] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:41:27,770] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:29,556] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:29,557] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:41:30,283] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4062672257423401, 'eval_runtime': 2.5419, 'eval_samples_per_second': 7.868, 'eval_steps_per_second': 0.787, 'epoch': 0.9}\n",
            " 30% 66/219 [07:50<17:01,  6.68s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2902, 'learning_rate': 0.000134, 'epoch': 0.92}\n",
            "{'loss': 0.315, 'learning_rate': 0.00013600000000000003, 'epoch': 0.93}\n",
            "{'loss': 0.2803, 'learning_rate': 0.000138, 'epoch': 0.95}\n",
            " 32% 69/219 [08:09<16:53,  6.76s/it][2023-10-10 12:41:48,928] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:48,936] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:41:48,936] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:41:48,937] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:50,729] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:41:50,730] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:41:51,456] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.40511950850486755, 'eval_runtime': 2.5484, 'eval_samples_per_second': 7.848, 'eval_steps_per_second': 0.785, 'epoch': 0.95}\n",
            " 32% 69/219 [08:12<16:53,  6.76s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2745, 'learning_rate': 0.00014, 'epoch': 0.96}\n",
            "{'loss': 0.217, 'learning_rate': 0.000142, 'epoch': 0.97}\n",
            "{'loss': 0.3029, 'learning_rate': 0.000144, 'epoch': 0.99}\n",
            " 33% 72/219 [08:30<16:33,  6.76s/it][2023-10-10 12:42:10,089] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:10,096] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:42:10,096] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:42:10,097] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:11,882] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:11,883] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:42:12,609] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.40323272347450256, 'eval_runtime': 2.5404, 'eval_samples_per_second': 7.873, 'eval_steps_per_second': 0.787, 'epoch': 0.99}\n",
            " 33% 72/219 [08:33<16:33,  6.76s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2346, 'learning_rate': 0.000146, 'epoch': 1.0}\n",
            " 33% 73/219 [08:39<17:46,  7.30s/it][2023-10-10 12:42:20,323] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "[2023-10-10 12:42:20,323] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:42:20,326] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 8df1b34c215e40e3a2228690a8059a32b9f287cc445d338f0e6a37fa75e32fdc\u001b[39m\n",
            "[2023-10-10 12:42:20,327] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "{'loss': 0.1951, 'learning_rate': 0.000148, 'epoch': 1.01}\n",
            "{'loss': 0.2505, 'learning_rate': 0.00015000000000000001, 'epoch': 1.03}\n",
            " 34% 75/219 [08:53<16:56,  7.06s/it][2023-10-10 12:42:32,641] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:32,650] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:42:32,650] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:42:32,651] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:34,439] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:34,440] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:42:35,166] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.4002296030521393, 'eval_runtime': 2.5455, 'eval_samples_per_second': 7.857, 'eval_steps_per_second': 0.786, 'epoch': 1.03}\n",
            " 34% 75/219 [08:55<16:56,  7.06s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3458, 'learning_rate': 0.000152, 'epoch': 1.04}\n",
            "{'loss': 0.2701, 'learning_rate': 0.000154, 'epoch': 1.05}\n",
            "{'loss': 0.2952, 'learning_rate': 0.00015600000000000002, 'epoch': 1.07}\n",
            " 36% 78/219 [09:14<16:04,  6.84s/it][2023-10-10 12:42:53,661] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:53,669] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:42:53,669] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:42:53,670] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:55,455] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:42:55,456] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:42:56,186] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.3984909653663635, 'eval_runtime': 2.5452, 'eval_samples_per_second': 7.858, 'eval_steps_per_second': 0.786, 'epoch': 1.07}\n",
            " 36% 78/219 [09:16<16:04,  6.84s/it]\n",
            "2it [00:00,  2.74it/s]\u001b[A\n",
            "{'loss': 0.2674, 'learning_rate': 0.00015800000000000002, 'epoch': 1.08}\n",
            "{'loss': 0.3174, 'learning_rate': 0.00016, 'epoch': 1.1}\n",
            "{'loss': 0.2435, 'learning_rate': 0.000162, 'epoch': 1.11}\n",
            " 37% 81/219 [09:35<15:29,  6.73s/it][2023-10-10 12:43:14,699] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:14,707] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:43:14,708] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:43:14,708] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:16,498] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:16,499] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:43:17,226] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.3966957926750183, 'eval_runtime': 2.5471, 'eval_samples_per_second': 7.852, 'eval_steps_per_second': 0.785, 'epoch': 1.11}\n",
            " 37% 81/219 [09:37<15:29,  6.73s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2506, 'learning_rate': 0.000164, 'epoch': 1.12}\n",
            "{'loss': 0.3297, 'learning_rate': 0.000166, 'epoch': 1.14}\n",
            "{'loss': 0.2602, 'learning_rate': 0.000168, 'epoch': 1.15}\n",
            " 38% 84/219 [09:56<15:06,  6.72s/it][2023-10-10 12:43:35,720] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:35,728] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:43:35,728] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:43:35,729] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:37,514] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:37,515] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:43:38,241] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.39546817541122437, 'eval_runtime': 2.5416, 'eval_samples_per_second': 7.869, 'eval_steps_per_second': 0.787, 'epoch': 1.15}\n",
            " 38% 84/219 [09:58<15:06,  6.72s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2299, 'learning_rate': 0.00017, 'epoch': 1.16}\n",
            "{'loss': 0.342, 'learning_rate': 0.000172, 'epoch': 1.18}\n",
            "{'loss': 0.2597, 'learning_rate': 0.000174, 'epoch': 1.19}\n",
            " 40% 87/219 [10:17<14:54,  6.78s/it][2023-10-10 12:43:56,933] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:56,940] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:43:56,940] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:43:56,941] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:58,727] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:43:58,728] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:43:59,454] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.393771231174469, 'eval_runtime': 2.5416, 'eval_samples_per_second': 7.869, 'eval_steps_per_second': 0.787, 'epoch': 1.19}\n",
            " 40% 87/219 [10:20<14:54,  6.78s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2375, 'learning_rate': 0.00017600000000000002, 'epoch': 1.21}\n",
            "{'loss': 0.2352, 'learning_rate': 0.00017800000000000002, 'epoch': 1.22}\n",
            "{'loss': 0.2282, 'learning_rate': 0.00018, 'epoch': 1.23}\n",
            " 41% 90/219 [10:38<14:29,  6.74s/it][2023-10-10 12:44:17,947] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:44:17,955] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:44:17,956] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:44:17,956] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:44:19,745] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:44:19,746] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:44:20,472] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.3928694725036621, 'eval_runtime': 2.5454, 'eval_samples_per_second': 7.857, 'eval_steps_per_second': 0.786, 'epoch': 1.23}\n",
            " 41% 90/219 [10:41<14:29,  6.74s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2372, 'learning_rate': 0.000182, 'epoch': 1.25}\n",
            "{'loss': 0.2712, 'learning_rate': 0.00018400000000000003, 'epoch': 1.26}\n",
            "{'loss': 0.2208, 'learning_rate': 0.00018600000000000002, 'epoch': 1.27}\n",
            " 42% 93/219 [10:59<14:06,  6.72s/it][2023-10-10 12:44:38,897] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:44:38,905] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:44:38,906] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:44:38,906] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:44:40,695] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:44:40,695] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:44:41,422] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.392780601978302, 'eval_runtime': 2.5451, 'eval_samples_per_second': 7.858, 'eval_steps_per_second': 0.786, 'epoch': 1.27}\n",
            " 42% 93/219 [11:02<14:06,  6.72s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2473, 'learning_rate': 0.000188, 'epoch': 1.29}\n",
            "{'loss': 0.2716, 'learning_rate': 0.00019, 'epoch': 1.3}\n",
            "{'loss': 0.1872, 'learning_rate': 0.000192, 'epoch': 1.32}\n",
            " 44% 96/219 [11:20<13:57,  6.81s/it][2023-10-10 12:45:00,210] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:00,218] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:45:00,218] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:45:00,219] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:02,008] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:02,009] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:45:02,734] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.3928011357784271, 'eval_runtime': 2.544, 'eval_samples_per_second': 7.861, 'eval_steps_per_second': 0.786, 'epoch': 1.32}\n",
            " 44% 96/219 [11:23<13:57,  6.81s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2429, 'learning_rate': 0.000194, 'epoch': 1.33}\n",
            "{'loss': 0.2391, 'learning_rate': 0.000196, 'epoch': 1.34}\n",
            "{'loss': 0.2512, 'learning_rate': 0.00019800000000000002, 'epoch': 1.36}\n",
            " 45% 99/219 [11:41<13:19,  6.66s/it][2023-10-10 12:45:20,902] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:20,909] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:45:20,909] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:45:20,910] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:22,699] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:22,700] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:45:23,426] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.39304378628730774, 'eval_runtime': 2.5448, 'eval_samples_per_second': 7.859, 'eval_steps_per_second': 0.786, 'epoch': 1.36}\n",
            " 45% 99/219 [11:44<13:19,  6.66s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2638, 'learning_rate': 0.0002, 'epoch': 1.37}\n",
            "{'loss': 0.2156, 'learning_rate': 0.0001999651541868849, 'epoch': 1.38}\n",
            "{'loss': 0.3321, 'learning_rate': 0.00019986064103215339, 'epoch': 1.4}\n",
            " 47% 102/219 [12:03<13:18,  6.82s/it][2023-10-10 12:45:42,466] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:42,475] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:45:42,476] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:45:42,476] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:44,262] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:45:44,262] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:45:44,989] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.39060401916503906, 'eval_runtime': 2.5433, 'eval_samples_per_second': 7.864, 'eval_steps_per_second': 0.786, 'epoch': 1.4}\n",
            " 47% 102/219 [12:05<13:18,  6.82s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2452, 'learning_rate': 0.00019968653337272261, 'epoch': 1.41}\n",
            "{'loss': 0.2196, 'learning_rate': 0.00019944295254705185, 'epoch': 1.42}\n",
            "{'loss': 0.2664, 'learning_rate': 0.00019913006831057969, 'epoch': 1.44}\n",
            " 48% 105/219 [12:24<12:56,  6.81s/it][2023-10-10 12:46:03,765] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:03,772] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:46:03,772] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:46:03,773] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:05,561] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:05,561] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:46:06,287] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3896406590938568, 'eval_runtime': 2.543, 'eval_samples_per_second': 7.865, 'eval_steps_per_second': 0.786, 'epoch': 1.44}\n",
            " 48% 105/219 [12:26<12:56,  6.81s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.238, 'learning_rate': 0.00019874809871741876, 'epoch': 1.45}\n",
            "{'loss': 0.2844, 'learning_rate': 0.0001982973099683902, 'epoch': 1.47}\n",
            "{'loss': 0.2352, 'learning_rate': 0.00019777801622550408, 'epoch': 1.48}\n",
            " 49% 108/219 [12:45<12:32,  6.78s/it][2023-10-10 12:46:25,023] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:25,031] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:46:25,031] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:46:25,032] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:26,821] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:26,822] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:46:27,551] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38924217224121094, 'eval_runtime': 2.5488, 'eval_samples_per_second': 7.847, 'eval_steps_per_second': 0.785, 'epoch': 1.48}\n",
            " 49% 108/219 [12:48<12:32,  6.78s/it]\n",
            "2it [00:00,  2.74it/s]\u001b[A\n",
            "{'loss': 0.2622, 'learning_rate': 0.00019719057939301477, 'epoch': 1.49}\n",
            "{'loss': 0.3372, 'learning_rate': 0.00019653540886520386, 'epoch': 1.51}\n",
            "{'loss': 0.3056, 'learning_rate': 0.0001958129612410668, 'epoch': 1.52}\n",
            " 51% 111/219 [13:07<12:21,  6.87s/it][2023-10-10 12:46:46,541] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:46,548] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:46:46,548] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:46:46,549] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:48,338] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:46:48,339] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:46:49,065] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38802042603492737, 'eval_runtime': 2.5453, 'eval_samples_per_second': 7.858, 'eval_steps_per_second': 0.786, 'epoch': 1.52}\n",
            " 51% 111/219 [13:09<12:21,  6.87s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3363, 'learning_rate': 0.00019502374000610151, 'epoch': 1.53}\n",
            "{'loss': 0.1969, 'learning_rate': 0.00019416829518142118, 'epoch': 1.55}\n",
            "{'loss': 0.2062, 'learning_rate': 0.00019324722294043558, 'epoch': 1.56}\n",
            " 52% 114/219 [13:28<11:55,  6.81s/it][2023-10-10 12:47:07,684] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:07,691] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:47:07,691] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:47:07,692] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:09,480] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:09,481] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:47:10,207] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38760894536972046, 'eval_runtime': 2.5441, 'eval_samples_per_second': 7.861, 'eval_steps_per_second': 0.786, 'epoch': 1.56}\n",
            " 52% 114/219 [13:30<11:55,  6.81s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2755, 'learning_rate': 0.0001922611651933683, 'epoch': 1.58}\n",
            "{'loss': 0.2505, 'learning_rate': 0.0001912108091398988, 'epoch': 1.59}\n",
            "{'loss': 0.1879, 'learning_rate': 0.0001900968867902419, 'epoch': 1.6}\n",
            " 53% 117/219 [13:49<11:35,  6.82s/it][2023-10-10 12:47:29,099] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:29,106] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:47:29,107] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:47:29,107] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:30,895] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:30,896] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:47:31,622] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3877156674861908, 'eval_runtime': 2.5437, 'eval_samples_per_second': 7.863, 'eval_steps_per_second': 0.786, 'epoch': 1.6}\n",
            " 53% 117/219 [13:52<11:35,  6.82s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3528, 'learning_rate': 0.0001889201744549981, 'epoch': 1.62}\n",
            "{'loss': 0.2146, 'learning_rate': 0.0001876814922041299, 'epoch': 1.63}\n",
            "{'loss': 0.2425, 'learning_rate': 0.00018638170329544164, 'epoch': 1.64}\n",
            " 55% 120/219 [14:10<11:03,  6.70s/it][2023-10-10 12:47:49,932] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:49,940] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:47:49,940] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:47:49,941] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:51,725] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:47:51,726] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:47:52,452] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3882879614830017, 'eval_runtime': 2.5401, 'eval_samples_per_second': 7.874, 'eval_steps_per_second': 0.787, 'epoch': 1.64}\n",
            " 55% 120/219 [14:13<11:03,  6.70s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2426, 'learning_rate': 0.00018502171357296144, 'epoch': 1.66}\n",
            "{'loss': 0.2696, 'learning_rate': 0.00018360247083564342, 'epoch': 1.67}\n",
            "{'loss': 0.3351, 'learning_rate': 0.00018212496417683137, 'epoch': 1.68}\n",
            " 56% 123/219 [14:31<10:48,  6.76s/it][2023-10-10 12:48:11,259] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:11,266] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:48:11,266] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:48:11,267] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:13,055] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:13,056] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:48:13,783] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38769346475601196, 'eval_runtime': 2.5446, 'eval_samples_per_second': 7.86, 'eval_steps_per_second': 0.786, 'epoch': 1.68}\n",
            " 56% 123/219 [14:34<10:48,  6.76s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2348, 'learning_rate': 0.0001805902232949435, 'epoch': 1.7}\n",
            "{'loss': 0.2323, 'learning_rate': 0.00017899931777585882, 'epoch': 1.71}\n",
            "{'loss': 0.2797, 'learning_rate': 0.00017735335634750532, 'epoch': 1.73}\n",
            " 58% 126/219 [14:53<10:30,  6.78s/it][2023-10-10 12:48:32,367] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:32,374] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:48:32,374] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:48:32,375] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:34,162] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:34,163] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:48:34,891] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3867691159248352, 'eval_runtime': 2.5456, 'eval_samples_per_second': 7.857, 'eval_steps_per_second': 0.786, 'epoch': 1.73}\n",
            " 58% 126/219 [14:55<10:30,  6.78s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2867, 'learning_rate': 0.0001756534861071696, 'epoch': 1.74}\n",
            "{'loss': 0.2433, 'learning_rate': 0.00017390089172206592, 'epoch': 1.75}\n",
            "{'loss': 0.2, 'learning_rate': 0.0001720967946037225, 'epoch': 1.77}\n",
            " 59% 129/219 [15:13<10:02,  6.70s/it][2023-10-10 12:48:53,225] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:53,233] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:48:53,233] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:48:53,234] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:55,021] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:48:55,021] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:48:55,749] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3849751055240631, 'eval_runtime': 2.5449, 'eval_samples_per_second': 7.859, 'eval_steps_per_second': 0.786, 'epoch': 1.77}\n",
            " 59% 129/219 [15:16<10:02,  6.70s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.3111, 'learning_rate': 0.00017024245205675986, 'epoch': 1.78}\n",
            "{'loss': 0.2794, 'learning_rate': 0.00016833915640265484, 'epoch': 1.79}\n",
            "{'loss': 0.2933, 'learning_rate': 0.00016638823407910084, 'epoch': 1.81}\n",
            " 60% 132/219 [15:34<09:39,  6.66s/it][2023-10-10 12:49:14,006] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:14,013] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:49:14,013] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:49:14,014] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:15,799] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:15,800] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:49:16,526] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38454222679138184, 'eval_runtime': 2.5409, 'eval_samples_per_second': 7.871, 'eval_steps_per_second': 0.787, 'epoch': 1.81}\n",
            " 60% 132/219 [15:37<09:39,  6.66s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.3194, 'learning_rate': 0.00016439104471559156, 'epoch': 1.82}\n",
            "{'loss': 0.2465, 'learning_rate': 0.00016234898018587337, 'epoch': 1.84}\n",
            "{'loss': 0.1992, 'learning_rate': 0.00016026346363792567, 'epoch': 1.85}\n",
            " 62% 135/219 [15:55<09:20,  6.67s/it][2023-10-10 12:49:34,891] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:34,899] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:49:34,899] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:49:34,900] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:36,687] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:36,688] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:49:37,415] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38369813561439514, 'eval_runtime': 2.5441, 'eval_samples_per_second': 7.861, 'eval_steps_per_second': 0.786, 'epoch': 1.85}\n",
            " 62% 135/219 [15:58<09:20,  6.67s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2807, 'learning_rate': 0.000158135948502146, 'epoch': 1.86}\n",
            "{'loss': 0.2583, 'learning_rate': 0.0001559679174784308, 'epoch': 1.88}\n",
            "{'loss': 0.3402, 'learning_rate': 0.00015376088150285773, 'epoch': 1.89}\n",
            " 63% 138/219 [16:16<09:05,  6.74s/it][2023-10-10 12:49:56,095] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:56,102] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:49:56,102] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:49:56,103] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:57,889] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:49:57,890] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:49:58,616] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3834901750087738, 'eval_runtime': 2.542, 'eval_samples_per_second': 7.868, 'eval_steps_per_second': 0.787, 'epoch': 1.89}\n",
            " 63% 138/219 [16:19<09:05,  6.74s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2922, 'learning_rate': 0.0001515163786946896, 'epoch': 1.9}\n",
            "{'loss': 0.2331, 'learning_rate': 0.00014923597328443422, 'epoch': 1.92}\n",
            "{'loss': 0.2495, 'learning_rate': 0.00014692125452370663, 'epoch': 1.93}\n",
            " 64% 141/219 [16:38<08:51,  6.81s/it][2023-10-10 12:50:17,579] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:50:17,587] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:50:17,587] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:50:17,588] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:50:19,376] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:50:19,377] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:50:20,103] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.381955087184906, 'eval_runtime': 2.5442, 'eval_samples_per_second': 7.861, 'eval_steps_per_second': 0.786, 'epoch': 1.93}\n",
            " 64% 141/219 [16:40<08:51,  6.81s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2983, 'learning_rate': 0.00014457383557765386, 'epoch': 1.95}\n",
            "{'loss': 0.2248, 'learning_rate': 0.00014219535240071377, 'epoch': 1.96}\n",
            "{'loss': 0.3188, 'learning_rate': 0.00013978746259649209, 'epoch': 1.97}\n",
            " 66% 144/219 [16:59<08:34,  6.86s/it][2023-10-10 12:50:39,055] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:50:39,062] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:50:39,063] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:50:39,063] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:50:40,852] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:50:40,853] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:50:41,586] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38024821877479553, 'eval_runtime': 2.551, 'eval_samples_per_second': 7.84, 'eval_steps_per_second': 0.784, 'epoch': 1.97}\n",
            " 66% 144/219 [17:02<08:34,  6.86s/it]\n",
            "2it [00:00,  2.73it/s]\u001b[A\n",
            "{'loss': 0.1813, 'learning_rate': 0.00013735184426255117, 'epoch': 1.99}\n",
            "{'loss': 0.3835, 'learning_rate': 0.0001348901948209167, 'epoch': 2.0}\n",
            " 67% 146/219 [17:14<08:28,  6.96s/it][2023-10-10 12:50:55,315] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "[2023-10-10 12:50:55,316] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:50:55,317] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 335f1c120f4c31c4c3328df5dabbc7d3ff92a32238aaf932013326e5c7b4168c\u001b[39m\n",
            "[2023-10-10 12:50:55,319] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 1479985\u001b[39m\n",
            "{'loss': 0.2728, 'learning_rate': 0.0001324042298351166, 'epoch': 2.01}\n",
            " 67% 147/219 [17:22<08:47,  7.33s/it][2023-10-10 12:51:01,841] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:01,849] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:51:01,849] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:51:01,850] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:03,636] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:03,637] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:51:04,363] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38005736470222473, 'eval_runtime': 2.5433, 'eval_samples_per_second': 7.864, 'eval_steps_per_second': 0.786, 'epoch': 2.01}\n",
            " 67% 147/219 [17:25<08:47,  7.33s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2494, 'learning_rate': 0.00012989568181457704, 'epoch': 2.03}\n",
            "{'loss': 0.2041, 'learning_rate': 0.0001273662990072083, 'epoch': 2.04}\n",
            "{'loss': 0.1757, 'learning_rate': 0.00012481784418102242, 'epoch': 2.05}\n",
            " 68% 150/219 [17:43<07:53,  6.87s/it][2023-10-10 12:51:22,709] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:22,716] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:51:22,716] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:51:22,717] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:24,501] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:24,502] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:51:25,228] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3837604820728302, 'eval_runtime': 2.5405, 'eval_samples_per_second': 7.873, 'eval_steps_per_second': 0.787, 'epoch': 2.05}\n",
            " 68% 150/219 [17:45<07:53,  6.87s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2218, 'learning_rate': 0.00012225209339563145, 'epoch': 2.07}\n",
            "{'loss': 0.1759, 'learning_rate': 0.00011967083476448282, 'epoch': 2.08}\n",
            "{'loss': 0.225, 'learning_rate': 0.00011707586720869374, 'epoch': 2.1}\n",
            " 70% 153/219 [18:04<07:22,  6.70s/it][2023-10-10 12:51:43,401] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:43,408] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:51:43,408] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:51:43,409] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:45,198] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:51:45,199] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:51:45,926] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3964657485485077, 'eval_runtime': 2.546, 'eval_samples_per_second': 7.855, 'eval_steps_per_second': 0.786, 'epoch': 2.1}\n",
            " 70% 153/219 [18:06<07:22,  6.70s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2515, 'learning_rate': 0.00011446899920335405, 'epoch': 2.11}\n",
            "{'loss': 0.2229, 'learning_rate': 0.00011185204751717029, 'epoch': 2.12}\n",
            "{'loss': 0.1987, 'learning_rate': 0.00010922683594633021, 'epoch': 2.14}\n",
            " 71% 156/219 [18:24<06:58,  6.64s/it][2023-10-10 12:52:04,041] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:04,048] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:52:04,048] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:52:04,049] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:05,833] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:05,834] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:52:06,569] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3932475447654724, 'eval_runtime': 2.5496, 'eval_samples_per_second': 7.844, 'eval_steps_per_second': 0.784, 'epoch': 2.14}\n",
            " 71% 156/219 [18:27<06:58,  6.64s/it]\n",
            "2it [00:00,  2.72it/s]\u001b[A\n",
            "{'loss': 0.4301, 'learning_rate': 0.00010659519404346954, 'epoch': 2.15}\n",
            "{'loss': 0.209, 'learning_rate': 0.00010395895584262696, 'epoch': 2.16}\n",
            "{'loss': 0.1779, 'learning_rate': 0.00010131995858107591, 'epoch': 2.18}\n",
            " 73% 159/219 [18:46<06:45,  6.76s/it][2023-10-10 12:52:25,406] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:25,413] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:52:25,413] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:52:25,414] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:27,199] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:27,200] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:52:27,927] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38848966360092163, 'eval_runtime': 2.5413, 'eval_samples_per_second': 7.87, 'eval_steps_per_second': 0.787, 'epoch': 2.18}\n",
            " 73% 159/219 [18:48<06:45,  6.76s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2298, 'learning_rate': 9.868004141892411e-05, 'epoch': 2.19}\n",
            "{'loss': 0.1834, 'learning_rate': 9.604104415737308e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2906, 'learning_rate': 9.340480595653047e-05, 'epoch': 2.22}\n",
            " 74% 162/219 [19:07<06:26,  6.78s/it][2023-10-10 12:52:46,714] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:46,721] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:52:46,721] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:52:46,722] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:48,510] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:52:48,511] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:52:49,239] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3858141601085663, 'eval_runtime': 2.5463, 'eval_samples_per_second': 7.854, 'eval_steps_per_second': 0.785, 'epoch': 2.22}\n",
            " 74% 162/219 [19:09<06:26,  6.78s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2837, 'learning_rate': 9.077316405366981e-05, 'epoch': 2.23}\n",
            "{'loss': 0.3374, 'learning_rate': 8.814795248282974e-05, 'epoch': 2.25}\n",
            "{'loss': 0.1858, 'learning_rate': 8.553100079664598e-05, 'epoch': 2.26}\n",
            " 75% 165/219 [19:27<05:59,  6.65s/it][2023-10-10 12:53:07,281] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:07,288] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:53:07,288] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:53:07,289] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:09,077] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:09,078] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:53:09,805] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3842129111289978, 'eval_runtime': 2.5443, 'eval_samples_per_second': 7.861, 'eval_steps_per_second': 0.786, 'epoch': 2.26}\n",
            " 75% 165/219 [19:30<05:59,  6.65s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.1812, 'learning_rate': 8.292413279130624e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2319, 'learning_rate': 8.03291652355172e-05, 'epoch': 2.29}\n",
            "{'loss': 0.2003, 'learning_rate': 7.774790660436858e-05, 'epoch': 2.3}\n",
            " 77% 168/219 [19:49<05:46,  6.79s/it][2023-10-10 12:53:28,616] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:28,623] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:53:28,623] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:53:28,624] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:30,411] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:30,411] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:53:31,140] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3851277828216553, 'eval_runtime': 2.5444, 'eval_samples_per_second': 7.86, 'eval_steps_per_second': 0.786, 'epoch': 2.3}\n",
            " 77% 168/219 [19:51<05:46,  6.79s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2176, 'learning_rate': 7.518215581897763e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2023, 'learning_rate': 7.263370099279172e-05, 'epoch': 2.33}\n",
            "{'loss': 0.1534, 'learning_rate': 7.010431818542297e-05, 'epoch': 2.34}\n",
            " 78% 171/219 [20:10<05:25,  6.79s/it][2023-10-10 12:53:49,792] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:49,800] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:53:49,800] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:53:49,801] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:51,590] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:53:51,590] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:53:52,317] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3875464200973511, 'eval_runtime': 2.5457, 'eval_samples_per_second': 7.856, 'eval_steps_per_second': 0.786, 'epoch': 2.34}\n",
            " 78% 171/219 [20:13<05:25,  6.79s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2278, 'learning_rate': 6.759577016488343e-05, 'epoch': 2.36}\n",
            "{'loss': 0.1818, 'learning_rate': 6.510980517908334e-05, 'epoch': 2.37}\n",
            "{'loss': 0.2383, 'learning_rate': 6.264815573744884e-05, 'epoch': 2.38}\n",
            " 79% 174/219 [20:31<05:05,  6.78s/it][2023-10-10 12:54:10,916] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:10,923] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:54:10,923] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:54:10,924] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:12,709] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:12,710] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:54:13,435] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3891325294971466, 'eval_runtime': 2.54, 'eval_samples_per_second': 7.874, 'eval_steps_per_second': 0.787, 'epoch': 2.38}\n",
            " 79% 174/219 [20:34<05:05,  6.78s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.1996, 'learning_rate': 6.021253740350793e-05, 'epoch': 2.4}\n",
            "{'loss': 0.2179, 'learning_rate': 5.780464759928623e-05, 'epoch': 2.41}\n",
            "{'loss': 0.1909, 'learning_rate': 5.542616442234618e-05, 'epoch': 2.42}\n",
            " 81% 177/219 [20:52<04:45,  6.79s/it][2023-10-10 12:54:32,247] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:32,254] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:54:32,254] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:54:32,255] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:34,042] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:34,042] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:54:34,769] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3878543972969055, 'eval_runtime': 2.543, 'eval_samples_per_second': 7.865, 'eval_steps_per_second': 0.786, 'epoch': 2.42}\n",
            " 81% 177/219 [20:55<04:45,  6.79s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.1863, 'learning_rate': 5.307874547629339e-05, 'epoch': 2.44}\n",
            "{'loss': 0.2092, 'learning_rate': 5.0764026715565785e-05, 'epoch': 2.45}\n",
            "{'loss': 0.1587, 'learning_rate': 4.848362130531039e-05, 'epoch': 2.47}\n",
            " 82% 180/219 [21:14<04:25,  6.80s/it][2023-10-10 12:54:53,422] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:53,429] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:54:53,429] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:54:53,430] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:55,215] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:54:55,216] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:54:55,942] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3859304189682007, 'eval_runtime': 2.541, 'eval_samples_per_second': 7.871, 'eval_steps_per_second': 0.787, 'epoch': 2.47}\n",
            " 82% 180/219 [21:16<04:25,  6.80s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2156, 'learning_rate': 4.6239118497142256e-05, 'epoch': 2.48}\n",
            "{'loss': 0.2347, 'learning_rate': 4.403208252156921e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2065, 'learning_rate': 4.186405149785403e-05, 'epoch': 2.51}\n",
            " 84% 183/219 [21:35<04:05,  6.82s/it][2023-10-10 12:55:14,692] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:14,699] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:55:14,699] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:55:14,700] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:16,486] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:16,487] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:55:17,213] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38572239875793457, 'eval_runtime': 2.5421, 'eval_samples_per_second': 7.867, 'eval_steps_per_second': 0.787, 'epoch': 2.51}\n",
            " 84% 183/219 [21:37<04:05,  6.82s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.1603, 'learning_rate': 3.973653636207437e-05, 'epoch': 2.52}\n",
            "{'loss': 0.165, 'learning_rate': 3.7651019814126654e-05, 'epoch': 2.53}\n",
            "{'loss': 0.1852, 'learning_rate': 3.5608955284408443e-05, 'epoch': 2.55}\n",
            " 85% 186/219 [21:56<03:46,  6.86s/it][2023-10-10 12:55:36,141] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:36,149] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:55:36,149] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:55:36,150] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:37,940] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:37,940] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:55:38,666] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38559648394584656, 'eval_runtime': 2.5454, 'eval_samples_per_second': 7.857, 'eval_steps_per_second': 0.786, 'epoch': 2.55}\n",
            " 85% 186/219 [21:59<03:46,  6.86s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.279, 'learning_rate': 3.361176592089919e-05, 'epoch': 2.56}\n",
            "{'loss': 0.1926, 'learning_rate': 3.1660843597345135e-05, 'epoch': 2.58}\n",
            "{'loss': 0.1867, 'learning_rate': 2.975754794324015e-05, 'epoch': 2.59}\n",
            " 86% 189/219 [22:17<03:23,  6.77s/it][2023-10-10 12:55:57,233] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:57,240] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:55:57,241] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:55:57,241] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:59,028] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:55:59,029] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:55:59,755] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3861457407474518, 'eval_runtime': 2.5427, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 2.59}\n",
            " 86% 189/219 [22:20<03:23,  6.77s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.171, 'learning_rate': 2.7903205396277542e-05, 'epoch': 2.6}\n",
            "{'loss': 0.1885, 'learning_rate': 2.6099108277934103e-05, 'epoch': 2.62}\n",
            "{'loss': 0.2468, 'learning_rate': 2.4346513892830423e-05, 'epoch': 2.63}\n",
            " 88% 192/219 [22:39<03:04,  6.82s/it][2023-10-10 12:56:18,609] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:56:18,617] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:56:18,617] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:56:18,618] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:56:20,407] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:56:20,408] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:56:21,134] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38658827543258667, 'eval_runtime': 2.5456, 'eval_samples_per_second': 7.857, 'eval_steps_per_second': 0.786, 'epoch': 2.63}\n",
            " 88% 192/219 [22:41<03:04,  6.82s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2184, 'learning_rate': 2.2646643652494692e-05, 'epoch': 2.64}\n",
            "{'loss': 0.2187, 'learning_rate': 2.100068222414121e-05, 'epoch': 2.66}\n",
            "{'loss': 0.2104, 'learning_rate': 1.9409776705056516e-05, 'epoch': 2.67}\n",
            " 89% 195/219 [23:00<02:45,  6.88s/it][2023-10-10 12:56:40,199] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:56:40,207] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:56:40,207] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:56:40,207] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:56:41,996] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:56:41,997] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:56:42,722] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3870141804218292, 'eval_runtime': 2.5434, 'eval_samples_per_second': 7.863, 'eval_steps_per_second': 0.786, 'epoch': 2.67}\n",
            " 89% 195/219 [23:03<02:45,  6.88s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.1894, 'learning_rate': 1.787503582316864e-05, 'epoch': 2.68}\n",
            "{'loss': 0.2827, 'learning_rate': 1.6397529164356606e-05, 'epoch': 2.7}\n",
            "{'loss': 0.1982, 'learning_rate': 1.4978286427038601e-05, 'epoch': 2.71}\n",
            " 90% 198/219 [23:22<02:24,  6.88s/it][2023-10-10 12:57:01,698] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:01,705] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:57:01,705] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:57:01,705] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:03,491] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:03,492] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:57:04,218] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38701480627059937, 'eval_runtime': 2.5412, 'eval_samples_per_second': 7.87, 'eval_steps_per_second': 0.787, 'epoch': 2.71}\n",
            " 90% 198/219 [23:24<02:24,  6.88s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.186, 'learning_rate': 1.3618296704558364e-05, 'epoch': 2.73}\n",
            "{'loss': 0.2868, 'learning_rate': 1.2318507795870138e-05, 'epoch': 2.74}\n",
            "{'loss': 0.1971, 'learning_rate': 1.1079825545001888e-05, 'epoch': 2.75}\n",
            " 92% 201/219 [23:43<02:02,  6.82s/it][2023-10-10 12:57:22,948] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:22,955] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:57:22,955] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:57:22,956] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:24,742] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:24,742] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:57:25,470] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3868495523929596, 'eval_runtime': 2.5433, 'eval_samples_per_second': 7.864, 'eval_steps_per_second': 0.786, 'epoch': 2.75}\n",
            " 92% 201/219 [23:46<02:02,  6.82s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.1912, 'learning_rate': 9.903113209758096e-06, 'epoch': 2.77}\n",
            "{'loss': 0.1849, 'learning_rate': 8.789190860101225e-06, 'epoch': 2.78}\n",
            "{'loss': 0.1704, 'learning_rate': 7.738834806631711e-06, 'epoch': 2.79}\n",
            " 93% 204/219 [24:04<01:40,  6.71s/it][2023-10-10 12:57:43,889] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:43,896] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:57:43,896] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:57:43,897] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:45,684] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:57:45,685] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:57:46,411] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3865852952003479, 'eval_runtime': 2.5431, 'eval_samples_per_second': 7.864, 'eval_steps_per_second': 0.786, 'epoch': 2.79}\n",
            " 93% 204/219 [24:07<01:40,  6.71s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2208, 'learning_rate': 6.75277705956443e-06, 'epoch': 2.81}\n",
            "{'loss': 0.2479, 'learning_rate': 5.831704818578843e-06, 'epoch': 2.82}\n",
            "{'loss': 0.1978, 'learning_rate': 4.976259993898502e-06, 'epoch': 2.84}\n",
            " 95% 207/219 [24:26<01:21,  6.82s/it][2023-10-10 12:58:05,356] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:05,364] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:58:05,364] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:58:05,365] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:07,150] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:07,151] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:58:07,877] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38632458448410034, 'eval_runtime': 2.541, 'eval_samples_per_second': 7.871, 'eval_steps_per_second': 0.787, 'epoch': 2.84}\n",
            " 95% 207/219 [24:28<01:21,  6.82s/it]\n",
            "2it [00:00,  2.76it/s]\u001b[A\n",
            "{'loss': 0.2367, 'learning_rate': 4.187038758933204e-06, 'epoch': 2.85}\n",
            "{'loss': 0.1432, 'learning_rate': 3.4645911347961357e-06, 'epoch': 2.86}\n",
            "{'loss': 0.1885, 'learning_rate': 2.809420606985236e-06, 'epoch': 2.88}\n",
            " 96% 210/219 [24:47<01:01,  6.87s/it][2023-10-10 12:58:26,845] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:26,852] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:58:26,852] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:58:26,853] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:28,639] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:28,640] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:58:29,366] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3861902058124542, 'eval_runtime': 2.5427, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 2.88}\n",
            " 96% 210/219 [24:50<01:01,  6.87s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.1739, 'learning_rate': 2.2219837744959283e-06, 'epoch': 2.89}\n",
            "{'loss': 0.2206, 'learning_rate': 1.7026900316098215e-06, 'epoch': 2.9}\n",
            "{'loss': 0.1748, 'learning_rate': 1.2519012825812804e-06, 'epoch': 2.92}\n",
            " 97% 213/219 [25:08<00:41,  6.85s/it][2023-10-10 12:58:48,170] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:48,177] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:58:48,177] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:58:48,178] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:49,964] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:58:49,964] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:58:50,699] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38633984327316284, 'eval_runtime': 2.5494, 'eval_samples_per_second': 7.845, 'eval_steps_per_second': 0.785, 'epoch': 2.92}\n",
            " 97% 213/219 [25:11<00:41,  6.85s/it]\n",
            "2it [00:00,  2.72it/s]\u001b[A\n",
            "{'loss': 0.2503, 'learning_rate': 8.699316894203224e-07, 'epoch': 2.93}\n",
            "{'loss': 0.2105, 'learning_rate': 5.570474529481562e-07, 'epoch': 2.95}\n",
            "{'loss': 0.1957, 'learning_rate': 3.134666272774034e-07, 'epoch': 2.96}\n",
            " 99% 216/219 [25:29<00:20,  6.76s/it][2023-10-10 12:59:09,218] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:59:09,225] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:59:09,226] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:59:09,226] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:59:11,012] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:59:11,013] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:59:11,739] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3863707482814789, 'eval_runtime': 2.5421, 'eval_samples_per_second': 7.867, 'eval_steps_per_second': 0.787, 'epoch': 2.96}\n",
            " 99% 216/219 [25:32<00:20,  6.76s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'loss': 0.2291, 'learning_rate': 1.393589678466367e-07, 'epoch': 2.97}\n",
            "{'loss': 0.1575, 'learning_rate': 3.484581311511414e-08, 'epoch': 2.99}\n",
            "{'loss': 0.2858, 'learning_rate': 0.0, 'epoch': 3.0}\n",
            "100% 219/219 [25:50<00:00,  6.68s/it][2023-10-10 12:59:29,963] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:59:29,971] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:2766] [RANK:0] generating packed batches\u001b[39m\n",
            "[2023-10-10 12:59:29,971] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:2766] [RANK:0] 0309058c71626f624864fe0a6b1d7bbb52a0712fb39841fc02e499e97eefc0f4\u001b[39m\n",
            "[2023-10-10 12:59:29,971] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:59:31,758] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "[2023-10-10 12:59:31,759] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A[2023-10-10 12:59:32,485] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:2766] [RANK:0] packing_efficiency_estimate: 0.96 total_num_tokens per device: 25740\u001b[39m\n",
            "\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.38662996888160706, 'eval_runtime': 2.5426, 'eval_samples_per_second': 7.866, 'eval_steps_per_second': 0.787, 'epoch': 3.0}\n",
            "100% 219/219 [25:53<00:00,  6.68s/it]\n",
            "2it [00:00,  2.75it/s]\u001b[A\n",
            "{'train_runtime': 1740.9229, 'train_samples_per_second': 1.665, 'train_steps_per_second': 0.126, 'train_loss': 0.27532713754808524, 'epoch': 3.0}\n",
            "100% 219/219 [25:54<00:00,  7.10s/it]\n",
            "[2023-10-10 13:00:09,631] [INFO] [axolotl.train.train:120] [PID:2766] [RANK:0] Training Completed!!! Saving pre-trained model to ./qlora-out\u001b[39m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ████▇▆▅▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▃▁▅▂▆▃▃▃▃▄▃▄▃▃▅▃▃▅▅▄▅▄▅▅▃▃█▃▇▆▅▂▄▃▄▄▄▃▇▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▆█▄▇▃▆▆▇▆▅▆▅▆▇▄▆▆▄▄▅▄▅▄▄▆▆▁▇▂▃▄▇▅▆▅▅▅▆▂▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▆█▅▆▃▆▆▆▆▆▆▅▆▆▅▆▆▅▅▅▅▅▅▅▆▆▁▆▁▃▅▆▅▆▆▅▅▆▃▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ▁▁▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇█████▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▆▅▇▆▄▄▃▄▄▅▄▂▄▃▂▂▃▃▅▅▃▃▃▃▆▁▂▄▂▂▂▁▁▂▄▃▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.38663\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 2.5426\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 7.866\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 3.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 219\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2858\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.732619803510702e+17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.27533\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 1740.9229\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1.665\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.126\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcomfy-plant-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/royam0820/axolotl/runs/svf8jtvr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231010_123338-svf8jtvr/logs\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsgHbC2mp7C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "YddiQUh3qWdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# amr\n",
        "!accelerate launch -m axolotl.cli.inference /content/EvolCodeLlama-7b.yaml \\\n",
        "    --lora_model_dir=\"./lora-out\""
      ],
      "metadata": {
        "id": "-wzPzf-OMtqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0ef24b-6c13-4609-ca59-6840ee55fcd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2023-10-10 13:01:05.548187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "                              dP            dP   dP \n",
            "                              88            88   88 \n",
            "   .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "   88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "   88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "   `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                    \n",
            "                                                    \n",
            "\n",
            "\u001b[33m[2023-10-10 13:01:08,077] [WARNING] [axolotl.validate_config:148] [PID:11396] [RANK:0] `pad_to_sequence_len: true` is recommended when using sample_packing\u001b[39m\n",
            "\u001b[33m[2023-10-10 13:01:08,077] [WARNING] [axolotl.validate_config:163] [PID:11396] [RANK:0] eval_batch_size != micro_batch_size. This can lead to VRAM instability.\u001b[39m\n",
            "[2023-10-10 13:01:08,420] [INFO] [axolotl.normalize_config:122] [PID:11396] [RANK:0] GPU memory usage baseline: 0.000GB (+0.439GB misc)\u001b[39m\n",
            "[2023-10-10 13:01:08,422] [INFO] [axolotl.common.cli.load_model_and_tokenizer:38] [PID:11396] [RANK:0] loading tokenizer... codellama/CodeLlama-7b-hf\u001b[39m\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "[2023-10-10 13:01:08,835] [DEBUG] [axolotl.load_tokenizer:75] [PID:11396] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2023-10-10 13:01:08,835] [DEBUG] [axolotl.load_tokenizer:76] [PID:11396] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2023-10-10 13:01:08,835] [DEBUG] [axolotl.load_tokenizer:77] [PID:11396] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2023-10-10 13:01:08,835] [DEBUG] [axolotl.load_tokenizer:78] [PID:11396] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2023-10-10 13:01:08,982] [INFO] [axolotl.common.cli.load_model_and_tokenizer:40] [PID:11396] [RANK:0] loading model and (optionally) peft_config...\u001b[39m\n",
            "Loading checkpoint shards: 100% 2/2 [00:16<00:00,  8.03s/it]\n",
            "[2023-10-10 13:01:27,146] [INFO] [axolotl.load_model:376] [PID:11396] [RANK:0] GPU memory usage after model load: 3.873GB (+0.120GB cache, +1.736GB misc)\u001b[39m\n",
            "[2023-10-10 13:01:27,153] [INFO] [axolotl.load_model:393] [PID:11396] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2023-10-10 13:01:27,157] [INFO] [axolotl.load_model:404] [PID:11396] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
            "[2023-10-10 13:01:27,161] [INFO] [axolotl.load_lora:509] [PID:11396] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'v_proj', 'o_proj', 'up_proj', 'k_proj', 'q_proj']\u001b[39m\n",
            "[2023-10-10 13:01:27,161] [DEBUG] [axolotl.load_lora:524] [PID:11396] [RANK:0] Loading pretained PEFT - LoRA\u001b[39m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/peft/config.py\", line 185, in _get_peft_type\n",
            "    config_file = hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 110, in _inner_fn\n",
            "    validate_repo_id(arg_value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 164, in validate_repo_id\n",
            "    raise HFValidationError(\n",
            "huggingface_hub.utils._validators.HFValidationError: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './lora-out'.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/axolotl/src/axolotl/cli/inference.py\", line 27, in <module>\n",
            "    fire.Fire(do_cli)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 475, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"/content/axolotl/src/axolotl/cli/inference.py\", line 23, in do_cli\n",
            "    do_inference(cfg=parsed_cfg, cli_args=parsed_cli_args)\n",
            "  File \"/content/axolotl/src/axolotl/cli/__init__.py\", line 88, in do_inference\n",
            "    model, tokenizer = load_model_and_tokenizer(cfg=cfg, cli_args=cli_args)\n",
            "  File \"/content/axolotl/src/axolotl/common/cli.py\", line 41, in load_model_and_tokenizer\n",
            "    model, _ = load_model(cfg, tokenizer, inference=cli_args.inference)\n",
            "  File \"/content/axolotl/src/axolotl/utils/models.py\", line 412, in load_model\n",
            "    model, lora_config = load_adapter(model, cfg, cfg.adapter)\n",
            "  File \"/content/axolotl/src/axolotl/utils/models.py\", line 454, in load_adapter\n",
            "    return load_lora(model, cfg, inference=inference)\n",
            "  File \"/content/axolotl/src/axolotl/utils/models.py\", line 525, in load_lora\n",
            "    model = PeftModel.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 267, in from_pretrained\n",
            "    PeftConfig._get_peft_type(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/peft/config.py\", line 191, in _get_peft_type\n",
            "    raise ValueError(f\"Can't find '{CONFIG_NAME}' at '{model_id}'\")\n",
            "ValueError: Can't find 'adapter_config.json' at './lora-out'\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 986, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 628, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.inference', '/content/EvolCodeLlama-7b.yaml', '--lora_model_dir=./lora-out']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae6a579c-086e-46e4-a184-de5b71f4d80b"
      },
      "outputs": [],
      "source": [
        "# testing the train dictionary\n",
        "tst = dict(**trn[3])\n",
        "tst['question'] = 'Get the count of competition hosts by theme.'\n",
        "tst"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt format\n",
        "fmt = \"\"\"SYSTEM: Use the following contextual information to concisely answer the question.\n",
        "\n",
        "USER: {}\n",
        "===\n",
        "{}\n",
        "ASSISTANT:\"\"\""
      ],
      "metadata": {
        "id": "-u7CZ5DrqgKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRW-djqFqoBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feca892e-64f0-48d2-832e-0d8ceb9855d2"
      },
      "outputs": [],
      "source": [
        "# sql prompt information\n",
        "def sql_prompt(d): return fmt.format(d[\"context\"], d[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "058b0f4a-8fe0-4612-8584-451e8d04fe2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f681bab-5e1c-436f-f290-c7180392799e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SYSTEM: Use the following contextual information to concisely answer the question.\n",
            "\n",
            "USER: CREATE TABLE farm_competition (Hosts VARCHAR, Theme VARCHAR)\n",
            "===\n",
            "Get the count of competition hosts by theme.\n",
            "ASSISTANT:\n"
          ]
        }
      ],
      "source": [
        "# printing the result\n",
        "print(sql_prompt(tst))"
      ]
    }
  ]
}